{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b995c6-765b-408a-ad9e-6e6f3d475453",
   "metadata": {},
   "source": [
    "### learning-AI101 : topic4_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19390b-d1dd-4886-8407-374d942f1c59",
   "metadata": {},
   "source": [
    "#### RNN 구현 : 작곡 AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461891e0-6f73-428f-8798-393de0b2c739",
   "metadata": {},
   "source": [
    "(복습) 인공지능 구축하는 법\n",
    "- 0) 데이터 전처리, 데이터 준비하기\n",
    "  1) 모델링\n",
    "  2) compile\n",
    "  3) fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19043218-c8de-4153-a454-1d35bc2f956c",
   "metadata": {},
   "source": [
    "#### 0. 데이터 전처리, 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc548670-8d55-40e9-bac6-0bee38c60c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\"G\"d2B\"D\"A3/2B/2c\"G\"B2G\"D\"A2e\"G\"d2B\"D\"A3/2B/2c:2/4\"F\"BF:3/4\"G\"G2e:\"C\"g2e\"Bb\"f2d\"F\"c2AF2e\"C\"g2e\"Bb\"f\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 파일 열기\n",
    "data = open('../data/pianoabc/pianoabc.txt', 'r').read()\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab5dd2-01bd-44a7-9d89-4c551f10fece",
   "metadata": {},
   "source": [
    "**위에 보니깐 코드랑 숫자 등이 있음 <-- 느낌 상 abc notation 악보일 가능성이 높음**  \n",
    "- compile, fit하기 위해서 문자나 숫자로 치환하여야 함\n",
    "- 악보에 abc notation을 적용하여 음악을 숫자나 문자로 치환하였음\n",
    "- 숫자는 음표의 길이 / 영어는 CDEFGABC (도레미파솔라시)\n",
    "- pianoabc.txt는 abc notation으로 짜여진 클래식 악보 몇개를 이어붙인 파일이다\n",
    "- 따옴표 : 주석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d44acf-1f42-4454-989d-460001a3c3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', \"'\", ',', '/', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', 'A', 'B', 'C', 'D', 'E', 'F', 'G', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'z']\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# 문자로 되어있으니 숫자로 바꾸어야 한다 (학습하려면) -> bag of words 만들기\n",
    "# bag of words : 특정 파일에서 문자가 무엇무엇이 있는지, 숫자가 무엇무엇이 있는지\n",
    "# a는 1, b는 2... 이런 식으로 문자를 숫자로 치환\n",
    "\n",
    "bag_of_words = list(set(data)) # set을 이용하여 bag of words 만들기\n",
    "bag_of_words.sort() # 뒤죽박죽인 set을 위해 sort()처리를 한번 함\n",
    "print (bag_of_words)\n",
    "print (len(bag_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d92f5b1c-e739-4251-812a-d4b41dacddb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\"': 0, \"'\": 1, ',': 2, '/': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, ':': 13, 'A': 14, 'B': 15, 'C': 16, 'D': 17, 'E': 18, 'F': 19, 'G': 20, '^': 21, '_': 22, 'a': 23, 'b': 24, 'c': 25, 'd': 26, 'e': 27, 'f': 28, 'g': 29, 'z': 30}\n"
     ]
    }
   ],
   "source": [
    "# bag of words를 이용해서 data_table을 만들어보자\n",
    "\n",
    "digital_data = data\n",
    "\n",
    "data_table = {}\n",
    "numbering = 0\n",
    "\n",
    "for i in bag_of_words :\n",
    "    data_table[bag_of_words[numbering]] = numbering\n",
    "    numbering += 1\n",
    "\n",
    "print (data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27d4640d-8e0a-4dac-a150-b789c8cc47ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 0, 20, 0, 26, 5, 15, 0, 17, 0]\n"
     ]
    }
   ],
   "source": [
    "# data를 숫자화하여 digital_data 저장하기\n",
    "digital_data = []\n",
    "\n",
    "for i in data : \n",
    "    digital_data.append(data_table[i])\n",
    "    \n",
    "print (digital_data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b09083-58af-4f00-8e27-824d8b6d72a6",
   "metadata": {},
   "source": [
    "결론\n",
    "- digital_data : data를 수치화함\n",
    "- bag_of_words : data에 있는 모든 문자와 숫자\n",
    "- 그러면 trainX, trianY를 어떻게 만드는가?\n",
    "  - 만약 [27, 0, 20, 0, 26]이라는 데이터가 있을 때\n",
    "  - RNN의 목적은 그 다음 걸 예측하는 것이기 때문에,\n",
    "  - trainX가 [27, 0]이라면 trainY는 [20]\n",
    "  - trainX가 [27, 0, 20, 0]이라면 trainY는 26이다. X 다음 값이 당연히 Y가 된다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd5bf9e-6e54-46d8-9c5b-d447d6810b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292022\n",
      "25 11680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 15, 0, 20, 0, 20, 5, 20, 20, 5, 17, 0, 18, 0, 20, 5, 18, 0, 20, 0, 20, 6]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainX와 trainY 만들기\n",
    "# trainX가 25개일때, trainY가 1개이도록 만들기\n",
    "length = len(digital_data)\n",
    "print (length)\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "num = 0\n",
    "\n",
    "while True :\n",
    "    try : \n",
    "        train_X.append(digital_data[num : num + 25])\n",
    "        train_Y.append(digital_data[num + 25])\n",
    "        num += 25\n",
    "\n",
    "    except IndexError :\n",
    "        break\n",
    "\n",
    "print (len(train_X[0]), len(train_Y))\n",
    "train_X.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8733a1e-62a9-4d63-8498-8f95e7dd9f54",
   "metadata": {},
   "source": [
    "**np.array를 이용해서 shape을 확인해보자**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8192b4-57d6-4e68-802d-37173c7391c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 17:36:55.559987: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a7890-d64a-4ed9-bfda-d4f19179a349",
   "metadata": {},
   "source": [
    "**원핫인코딩을 하여 학습효율을 높이자**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1aab3b1-c0ae-406b-9689-c1df5b875002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(2, 25, 31), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_X = tf.one_hot(train_X, 31)\n",
    "train_Y = tf.one_hot(train_Y, 31)\n",
    "print(train_X[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab0507-15f2-4e0b-9806-69cfb9c6b1a6",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152fb57-8ebb-432e-b83e-49f6116b545c",
   "metadata": {},
   "source": [
    "#### 1. 모델링 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ca827a0-14c6-40e5-82fa-c4d2c448b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # LSTM 레이어를 통해 RNN을 구성하자\n",
    "    tf.keras.layers.LSTM(100, input_shape=(25, 31)),\n",
    "    # 문자 31개 중 마지막에 올 문자를 예측하는 문자와 같음 -> 따라서 softmax + categorical_crossentropy를 사용\n",
    "    tf.keras.layers.Dense(31, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# LSTM 레이어를 사용할 땐 activation을 중간에 넣을 필요가 없다\n",
    "# LSTM 레이어를 사용할 땐 epochs를 엄청 많이 돌려야한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0bbe85-215f-4e56-8355-7b2582a16f34",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1924f466-2344-4061-a470-ddae2f52dc6d",
   "metadata": {},
   "source": [
    "#### 2. fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aab19558-b873-4129-86e4-853a03e214bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "183/183 [==============================] - 4s 10ms/step - loss: 2.6572\n",
      "Epoch 2/50\n",
      "183/183 [==============================] - 2s 14ms/step - loss: 2.2418\n",
      "Epoch 3/50\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 1.9373\n",
      "Epoch 4/50\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 1.7647\n",
      "Epoch 5/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 1.6843\n",
      "Epoch 6/50\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 1.6329\n",
      "Epoch 7/50\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 1.5915\n",
      "Epoch 8/50\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 1.5501\n",
      "Epoch 9/50\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 1.5207\n",
      "Epoch 10/50\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 1.4900\n",
      "Epoch 11/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 1.4615\n",
      "Epoch 12/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 1.4361\n",
      "Epoch 13/50\n",
      "183/183 [==============================] - 6s 30ms/step - loss: 1.4115\n",
      "Epoch 14/50\n",
      "183/183 [==============================] - 5s 29ms/step - loss: 1.3907\n",
      "Epoch 15/50\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 1.3714\n",
      "Epoch 16/50\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 1.3468\n",
      "Epoch 17/50\n",
      "183/183 [==============================] - 5s 27ms/step - loss: 1.3241\n",
      "Epoch 18/50\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 1.3008\n",
      "Epoch 19/50\n",
      "183/183 [==============================] - 5s 27ms/step - loss: 1.2781\n",
      "Epoch 20/50\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 1.2551\n",
      "Epoch 21/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 1.2327\n",
      "Epoch 22/50\n",
      "183/183 [==============================] - 5s 29ms/step - loss: 1.2091\n",
      "Epoch 23/50\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 1.1829\n",
      "Epoch 24/50\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 1.1534\n",
      "Epoch 25/50\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 1.1290\n",
      "Epoch 26/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 1.1041\n",
      "Epoch 27/50\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 1.0757\n",
      "Epoch 28/50\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 1.0425\n",
      "Epoch 29/50\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 1.0135\n",
      "Epoch 30/50\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.9898\n",
      "Epoch 31/50\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.9555\n",
      "Epoch 32/50\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 0.9258\n",
      "Epoch 33/50\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 0.8966\n",
      "Epoch 34/50\n",
      "183/183 [==============================] - 5s 29ms/step - loss: 0.8654\n",
      "Epoch 35/50\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.8357\n",
      "Epoch 36/50\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.8073\n",
      "Epoch 37/50\n",
      "183/183 [==============================] - 5s 30ms/step - loss: 0.7780\n",
      "Epoch 38/50\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.7506\n",
      "Epoch 39/50\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.7187\n",
      "Epoch 40/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 0.6925\n",
      "Epoch 41/50\n",
      "183/183 [==============================] - 5s 30ms/step - loss: 0.6620\n",
      "Epoch 42/50\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 0.6350\n",
      "Epoch 43/50\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.6057\n",
      "Epoch 44/50\n",
      "183/183 [==============================] - 7s 38ms/step - loss: 0.5811\n",
      "Epoch 45/50\n",
      "183/183 [==============================] - 5s 29ms/step - loss: 0.5569\n",
      "Epoch 46/50\n",
      "183/183 [==============================] - 5s 27ms/step - loss: 0.5296\n",
      "Epoch 47/50\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 0.5028\n",
      "Epoch 48/50\n",
      "183/183 [==============================] - 5s 27ms/step - loss: 0.4732\n",
      "Epoch 49/50\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 0.4484\n",
      "Epoch 50/50\n",
      "183/183 [==============================] - 7s 38ms/step - loss: 0.4261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x141f32590>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba88580-104f-40b2-a33d-0a3114c4453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100)               52800     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 31)                3131      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55931 (218.48 KB)\n",
      "Trainable params: 55931 (218.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcade888-6c09-4fef-80ad-0f7eca0d5e5b",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1afd78-ba58-45fe-8a0e-d114923d24e1",
   "metadata": {},
   "source": [
    "#### 여태까지 했던거 정리\n",
    "- LSTM 레이어를 이용하여 작곡 AI를 만듦\n",
    "    - train_X, train_Y로 학습시켰다. (각각 25개, 11680개씩)\n",
    "- 만든 모델\n",
    "    - input : 25개의 문자를 입력한다면\n",
    "    - output : 다음 문자를 예측해주는 프로그램 (일종의 코드)\n",
    "    - 따라서 model.predict([25개 문자])를 하면 한 글자만 예측하게 되니 반복문을 통해 여러번 반복시켜준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "617eb519-8dee-4617-800e-17d856f23b77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=int64)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ind \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(digital_data)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m26\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdigital_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m:\u001b[49m\u001b[43mind\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 무작위 25개 데이터 리스트를 넣어줌 \u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/__autograph_generated_filegsm0_qa8.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=int64)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# digital_data : 원본 데이터를 수치화한 것\n",
    "# 여기서 랜덤으로 25개 뽑아서 predict에 넣어보자\n",
    "\n",
    "import random\n",
    "ind = random.randint(1, len(digital_data)-26)\n",
    "test_X = digital_data[ind:ind+25]\n",
    "test_X = tf.one_hot(test_X, 31)\n",
    "model.predict(test_) # 무작위 25개 데이터 리스트를 넣어줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ba7fb-acaa-4b70-a41d-ab451a791591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
