머신러닝의 정의

머신러닝이란 기계학습으로, 명시적 프로그래밍 없이 컴퓨터가 스스로 데이터에 의해 학습 능력을 부여하는 연구 분야이다. 이전에 전통적인 프로그래밍에서는 문제를 연구하고, 그를 통해 문제 해결을 위한 규칙을 작성하고, 평가를 진행하여 만약 오차가 있으면 오차 분석을 통해 다시 문제를 연구하였고 만약 오차가 없다면 론칭하는 방식을 택하였다. 하지만 만약 규칙이 많아지면 시스템이 복잡해진다는 단점과 함께 만약 새로운 규칙이 추가된다면 프로그램을 다시 작성해야 한다는 문제점이 공존하였다. 따라서 데이터가 새로히 추가되어도 즉각적으로 학습하는 online 방식의 머신러닝 프로그래밍이 등장하였다.

-----

전통적인 프로그래밍 vs 머신러닝 프로그래밍

전통적 프로그래밍에서는 코드가 길고 복잡해진다. 왜냐하면 당연히 규칙이 많아지기 때문에 이로 인해서 작성해야 할 코드의 양은 기하급수적으로 많아진다. 그리고 전통적 프로그래밍에서는 새로운 규칙이 발생 시 모든 코드를 다시 수정하여야 한다는 큰 문제점으로 인해서, 새로운 것에 대한 대처를 위한 머신러닝 프로그래밍이 등장하였다. 머신러닝 프로그래밍은 automation이 가능하며, 자동적으로 규칙을 찾아내고 변화에 적응 가능한 알고리즘이다. 강점 분야로는 유동적 환경일 때, 기존의 규칙이 너무 복잡할 때, 기존의 전통적인 프로그래밍으로는 해결이 불가능한 상황일 때 유리하다.

-----

머신러닝의 종류

머신러닝의 종류는 크게 아래와 같이 구분 가능하다.

- 훈련 방식 : 지도, 비지도, 자기지도, 강화, 준지도
- 전체 데이터를 학습하여 gradient 조정? : 온라인, 오프라인(배치)
- 데이터를 기억? : 사례기반, 모델기반

지도 학습이란 레이블이 있는 데이터를 이용하여 학습을 하는 것으로, 크게는 클래스를 예측하는 분류와 특정 값을 예측하는 회귀로 구성된다. 비지도학습은 레이블이 주어져 있지 않아 데이터 사이의 상관관계 및 유사도를 파악하여 그들을 군집화, 시각화, 차원축소 등을 하는 것으로, 시스템이 스스로 데이터를 보고 학습을 하여야 한다. 비지도학습에서 계층 군집 알고리즘은 기존의 군집에서 더욱 세분화하여 군집을 찾는 알고리즘으로 이상치 탐지 및 특이치 탐지가 이에 속한다. 

준지도 학습이란 지도학습과 비지도학습을 융합한 학습으로, 먼저 비지도학습을 통하여 속한 군집을 찾고, 레이블이 있는 데이터를 사용하여 지도학습을 하는 것이다. 이러면 훨씬 더 효율적으로 원하는 데이터에 접근이 가능하다. 자기지도학습이란 레이블이 없는 데이터로부터 레이블이 있는 데이터로 복원하는 학습을 의미한다. 그에 대한 예시로 마스킹 학습이 있다. 이때 마스크를 입힌 데이터(이미지)를 입력 feature로 마스크를 입히지 않은 원본 데이터(이미지)를 출력 target으로 두어서 데이터를 복원하는 능력을 가지게끔 학습을 하는 것이다. 

강화학습이란 agent가 보상을 받는 방향으로 학습하도록 하는 것이다. 환경을 세팅하고, 환경을 관찰해가면서 agent에게 상벌을 내린다. 관찰 -> policy에 맞는 행동 -> 상벌 -> policy 수정을 반복해가는데, 여기서 policy 수정을 통하여 상을 받는 방향으로 agent가 학습하는 것이다. 

오프라인(배치) 학습이란 매 epoch마다 전체 데이터셋을 사용하여 gradient를 구하는 방식인데, 이때 모든 데이터를 사용하기 때문에 굉장히 많은 시간과 자원이 소모가 되고, 이래서 offline으로 학습을 하는 것이다. 배치 학습의 가장 큰 문제점은 model rot, 모델 부패인데, 데이터가 시간에 따라서 변할 때 생기는 통계적 문제점이다. 계속 데이터는 변하는데 배치 학습은 새로운 데이터를 반영하지 못하기 때문에 변화에 적응할 수 없다. 하지만 주기적으로 재학습을 하면 되겠지만, 이는 시간이 너무 오래 걸린다. 결국에는 점진적으로 학습을 하여야 하는 것이다.

따라서 온라인 학습은 전체 데이터셋이 아닌 minibatch라고 하는 데이터의 작은 묶음으로 모델에 주입하여 모델을 학습시킨다. 적은 데이터를 사용하기 때문에 한정적인 자원을 가진 환경에서 학습이 유리하며, 실시간적으로 새로운 데이터를 반영할 수 있기 때문에 모델이 변화에 적응할 수 있다. 학습율은 온라인 학습에서 얼마나 데이터에 잘 적응할 것인가를 의미하는 지표로써, 학습율이 높다면 빨리 적응하지만 이전 정보를 빨리 잊고, 학습율이 낮다면 느리게 학습하지만 노이즈에 덜 민감하다. 온라인 학습의 단점은 이상치에 굉장히 민감하다는 것이다. 만약에 성능 감소가 감지되면 학습을 중지해야 한다.

sample을 단순히 기억하여 sample사이의 유사도를 측정하는 방식은 사례기반학습이라고 한다. 보통은 KNN, KNR이 이에 해당된다. sample을 모델에 대입하여 학습하는 것을 모델기반학습이라고 한다. 모델기반에서 model selection의 지표는 효용 함수와 비용 함수이다. 효용 함수는 모델이 얼마나 좋은지, 비용 함수는 모델이 얼마나 나쁜지를 평가한다.

------

머신러닝의 도전 과제

머신러닝의 도전 과제는 데이터 부분에서는 4가지, 알고리즘 부분에서는 1가지이다. 데이터 부분에서의 도전과제는, 첫째, 데이터의 양이다. 만약에 데이터의 양이 충분치 않다면 모델을 학습하는 것이 곤란할 수 있다. 둘째, 대표성 없는 데이터이다. 만약에 적은 양이라면 샘플링 잡음, 혹은 표본 추출이 잘못되었다면 샘플링 편향이 일어날 수도 있다. 셋째, 품질이 좋지 않은 데이터이다. 이런 데이터는 전처리가 필요한데, 이상한 데이터가 있는 행을 없애거나 아니면 median, mean 등의 기초통계량을 이용하여 이를 채울 수도 있다. 넷째, 불필요한 특성이 있는 데이터이다. 이럴 때는 feature engineering을 이용한다. feature extraction이란 feature들을 조합하여 유의미한 새로운 특성을 만드는 것이다. feature selection이란 feature 중 학습에 도움이 되는 특성만을 뽑아 학습하는 것으로, 보통의 지표는 corr이다. (상관계수)

알고리즘 부분에서의 도전 과제는 overfitting과 underfitting이다. overfitting은 train data에만 잘 학습이 되어 일반화가 되어 있지 않은 상태를 말한다. 이를 해결하는 방법은 학습 데이터를 늘려서 다양성을 반영시키거나, 노이즈를 줄이거나, 규제를 추가하면 된다. 규제는 총 L2, L1 규제가 있으며, 각각 ridge, lasso라고 한다. ridge는 feature 값을 최대한 0에 가깝게 만드는 제곱항 규제이며, lasso는 feature 값을 가능한 한 0으로 하는 절댓값 규제이다. underfitting은 train data 조차도 제대로 학습되지 않아 score가 낮은 상황을 말한다. 이에 대한 해결책은 규제의 양을 줄이거나, 모델 파라미터가 더 많은 모델을 선택하거나, 노이즈를 없애거나, feature engineering을 적용하는 것이 있겠다.

------

테스트와 검증

보통 train set, test set, val set의 비율을 6 : 2 : 2 혹은 8 : 1 : 1로 둔다. train set은 학습을 위해, test set은 일반성을 테스트하기 위해, val set은 검증을 위해 사용한다. 

검증은 2가지가 있는데, 홀드아웃 검증과 교차 검증이 있다. 홀드아웃 검증은 train set에서 일부를 val set으로 두어서 각 모델을 평가하고, 가장 좋은 성능의 모델을 다시 train+val set으로 학습시켜서 test set으로 일반성을 평가하는 작업이다. 교차 검증은 폴드라고 하는 중복되지 않은 랜덤한 구역으로 가지어 하나는 검증을 위해, 다른 하나는 학습을 위해 사용하는 것을 말한다. 이때 당연히 val set의 갯수가 곧 훈련 시간이다.

다른 하나는 데이터 불일치인데, 훈련-개발 세트로 데이터 불일치를 평가한다. 훈련 개발 세트가 좋으면 val set으로 평가가 가능한 것이고, 성능이 좋지 않으면 데이터 불일치 혹은 과적합 문제인 것이다.

------

회귀 종류 & 회귀에서 많이 사용하는 손실함수

회귀에는 종류가 있다. 회귀는 지도학습의 일종으로 특정 값을 예측하는 방식이다. 회귀에서 feature가 하나인 것을 단일 회귀, 여러 개의 feature인 것은 다중 회귀, 여러 target을 출력하는 것을 다변량 회귀, 한 target을 출력하는 것을 단변량 회귀라고 한다. 

회귀에서 많이 사용하는 손실함수는 RMSE와 MAE이다. MAE는 이상치가 많은 데이터에 사용되면 좋으며, RMSE와 같은 결과를 내면서 계산량이 적은 MSE도 있다. RMSE나 MAE	는 둘 다 예측값과 타깃값의 거리를 재는 방법으로 계산된다.

------

test set 생성

data snooping이란 데이터를 구성할 때 발생할 수 있는 일종의 통계편향으로, 만약에 데이터를 반복탐색하여 얻은 결과로 모델을 만들었을 때 데이터를 반복탐색하면 실제로 존재하지 않는 패턴까지 발견하게 되어서 곧 과적합을 만든다. (잘못된 결론으로 이끈다) 따라서 이는 레이블 편향과 비슷한 문제이므로 sample을 shuffle하여 train set을 구성하는 것이 좋다. 계층 샘플링과 랜덤 샘플링으로 나뉘는데, 계층 샘플링은 test set이 여러 카테고리를 대표할 수 있게끔 구성된 것으로, 랜덤 샘플링보다 훨씬 고르게 분포가 잘 되어있다.

상관계수는 feature과 target과의 상관계수를 구하여 어떤 feature가 더 연관성이 있는지를 알 때 편한 지표이다. 하지만 상관계수는 선형적인 상관계수가 있는 거지 비선형으로는 불가능하다. 또한 상관계수는 기울기랑은 전혀 관련이 없다.

-------

데이터 처리 함수 사용 장점 (손재새변)

데이터를 처리하기 위한 함수를 미리 만들어놓으면 어느 데이터라도 손쉽게 사용 가능하며, 재사용이 가능하고, 새 데이터 주입 전에 함수를 사용하면 되는거고, 여러 데이터 변환을 쉽게 하여 어느 조합이 좋은지 확인 가능하다.

-----

교차 검증

k-fold cross validation이란 폴드라고 하는 중복되지 않는 n개의 subset으로 랜덤히 분할하여 이 중 랜덤하게 하나를 고르고, 그 하나는 평가에 사용한다. 나머지는 전부 학습에 사용하게 된다. grid search는 모든 hyperparameter의 조합을 테스트해보는 것으로 시간이 오래 걸린다. 하지만 random search는 균등분포와 같은 분포가 주어지면 개발자가 지정해놓은 횟수만큼 randomly하게 hyperparameter를 뽑아서 테스팅하는 방법으로 조금 더 공정하면서도 빠르게 가능하다.

-----

ensemble

ensemble이란 여러 약한 예측기를 연결하여 강한 예측기를 만드는 것인데, 분산이 강한 decision tree를 여러 개 연결하여서 각각의 dt가 내놓은 예측을 수집하여 새로운 예측을 만드는 학습알고리즘을 random forest라고 한다. 특히 각각의 모델이 다른 오차를 내놓을 때 성능이 좋다고 하는데, 이는 다양성 때문이다. 다양성을 강조하기 위하여 extra tree라고 하는 것도 있다.)

-----

오차 행렬과 roc 곡선

오차 행렬이란 분류에서 얼마나 많은 sample을 예측 성공하였는지 나타낼 수 있는 metric이다. 왼쪽부터 TN, FP, FN, TP로 구분되며, TN과 TP, 즉 diagonal에 있는 박스들의 숫자가 많을 수록 좋은 예측기라고 볼 수 있다.

여기서 Accuracy는 (TN+TP) / (TN+FP+FN+TP)이며, F1 score은 2*(recall+precision)/(recall*precision)이고, recall은 (TP)/(FN+TP), precision은 (TP)/(FP+TP)이다. (precision은 p니깐 다 p밖에 없네?) 참고로 precision과 recall은 서로 trade off 관계이며 0에서 서로 값이 같아진다. 

ROC 곡선이란 이진분류가 얼마나 잘 되었는지를 나타내는 metric으로, y축에 가까이 붙은 곡선이 좋은 예측기이며, 또한 FPR, 즉 (FP)/(TN+FP)가 적어야 좋은 예측기이다.

-------

선형 회귀 모델

선형회귀 모델이란 결국에는 선형결합 + bias의 형태로 이루어져 있는데, 각각의 x에 붙은 coefficient인 weight와 bias를 loss가 최소인 것으로 구하는 것이 학습이 되겠다. 결국 학습은 loss를 최소로 하는 모델 파라미터를 구하는 것이다. 그러면 선형 회귀에서 가장 많이 사용하는 loss function은 RMSE와 MAE이다. 이때 MSE는 평균 제곱 오차로 오차의 제곱을 각각 하여 평균을 내는 것이다. 제곱을 하는 이유는 음수 항이 나오지 않게끔 하기 위함이고, MSE의 장점은 수학적 분석의 편의성과 계산의 용이성 때문이다. 

-------

경사하강법

경사하강법이란 loss function의 최솟값을 찾기 위해 연산하는 과정을 의미하며 궁극적으로 global minima를 찾기 위한 최적화알고리즘이다. 여기서 학습율이 너무 작으면 데이터에 적응하는 시간은 느려지지만 noise에 덜 민감해지고, 학습율이 너무 크면 빨리 적응하지만 이전에 학습한 데이터를 금방 잊을 수도 있어 결국 과적합 문제가 일어날 수 있다. (gradient vanishing problem) 

경사하강법의 문제점은 (1) local minima나 평탄한 함수에서 global minima를 찾기 힘들다는 점이다. 이때 convex function과 같이 함수의 global minima가 가운데로 모이도록 변환하면 해결 가능하다. (2) feature의 scale이 다를 경우에는 문제를 야기할 수 있다. 

-------

배치경사하강법

배치경사하강법은 모든 데이터를 이용하여 weight와 bias를 구하는 방법이다. 이러면 특이성에 민감하지 않을 수 있지만, 모든 데이터를 이용하는 것이기 때문에 시간이 오래 걸릴 수밖에 없다. 따라서 미니배치 경사 하강법이 도입되었다.

-------

확률적 경사 하강법

확률적 경사 하강법은 맨 처음에 random하게 starting data point를 잡아서 w_new = w_now * r + b 라는 식을 통해 global minima point를 찾는 최적화알고리즘이다. 매 스텝에서 한 샘플을 랜덤하게 가져와서 그에 대한 gradient를 계산하기 때문에 속도가 훨씬 빠르고 local minima를 탈출할 수 있지만, global minima를 찾을 것이라는 보장을 할 수가 없다.

------

미니배치 경사 하강법

훈련 데이터를 미니배치라고 하는 작은 단위로 분할하여 (online) 학습하는 것으로, 이는 적은 데이터를 사용하기 때문에 한정된 자원에서 매우 유리하다. 장점으로는 GPU의 사용으로 행렬의 연산을 더욱 빠르게 할 수 있다는 것이다.

------

학습 곡선

학습 곡선이란 train loss는 위에서 아래로 부드럽게 내려오고, val loss는 아래서 위로 부드럽게 올라오는 곡선으로, 어느 지점에서 수평으로 만나는 형식이다. 이 둘의 사이를 gap이라고 하였을 때, 만약에 gap이 크면 overfitting되었다고 말하고, 둘 사이가 특정 평면에서 큰 loss에서 만난다면 underfitting된 것이다. 만약에 줄일 수 없는 오차가 있다면 이에 대한 유일한 해결책은 noise를 제거하는 것이다. 또한 편향이 크면 underfitting될 가능성이 높고, 편향이 크다는건 자유도가 없다는 것으로, 자유도가 없으면 underfitting된 것으로 이해하여도 될 것 같다. 반면에 자유도가 크면 overfitting되는 것이겠다.

-------

회귀에서의 규제 

회귀에서의 규제는 L2, L1이 있다. L2 회귀는 ridge regression으로 규제항 + MSE로 구성되어 있으며, 가능하면 0으로 가깝게 feature을 구성한다는 방식으로 진행된다. L1 회귀는 lasso regression으로 규제항 + MSE로 구성되어 있으며, 이는 가능하면 feature의 값을 0으로 처리한다. L1 회귀는 가중치 벡터를 사용한다. 

L1와 L2를 비교하였을 때 공통점은 전력 임계점, 즉 optimization goal에 가까워질 수록 gradient가 0에 가까워진다는 것이다. 다만 아예 0이 되지는 않는다. (최적의 parameter가 원점에 가까워진다면)

조기종료도 규제 중 하나이다. val loss가 최소화되지 않을 때, 즉 val loss가 최대가 될 때 조기종료되며, 일정 시간 동안 대기 후에 val loss가 더 이상 감소되지 않을 때 이전 model parameter를 불러온 후에 조기종료시킨다.

로지스틱 회귀는 회귀이지만 분류, 즉 로지스틱 값을 반환하는 함수로써 0과 1 사이의 값을 반환한다. (이진 분류) 소프트맥스 회귀는 다중 클래스 분류는 지원하도록 한 회귀 모델이다.

-------

SVM
 
SVM이란 각각의 point와 가장 멀리 떨어진, 그니깐 각 포인트와 가장 멀리 떨어진 결정 경계를 찾는 알고리즘이다. 각각의 클래스로부터 가장 멀리 떨어진 결정 경계를 이용한 분류기이며, 여기서 결정 경계를 hyperplane이라고 한다.

SVM의 손실 함수는 힌지 손실이라고 하는 것인데, 힌지는 여기서 가장 멀리 떨어져 있는 hyperplane을 찾아주는 것으로, 힌지 손실을 가장 적게 하는 것이 SVM의 SGD가 할 역할이라고 볼 수 있다. 여기서의 hyperparameter는 C인데, C를 작게 하면 할 수록 margin violation을 허용 (soft margin)하는 것으로, overfitting을 막을 수 있다. 하지만 너무 작게 두면 오히려 분류가 잘 되지 않는 underfitting이 발생할 수 있다. C가 SVM의 규제의 역할을 할 수 있다.

-------

하드마진과 소프트마진

하드마진이란 margin violation을 허용하지 않는 것이고, 소프트마진이란 margin violation을 일정량 허용하는 것이다. 여기서 SVM의 문제점이 있는데, 데이터가 선형적으로 배치되지 않으면, 그니깐 각 클래스들이 선형적으로 구분될 수 있어야 하는데 그렇지 않다면 기존 선형 SVM으로는 불가능하다. 따라서 여기서 완벽히 hard margin하려면 비선형 SVM을 도입하여야 한다.

비선형 SVM은 PolynormialFeatures를 이용하여 구현이 가능하고, 이를 통하여 다항함수의 hyperplane을 그릴 수 있다. 하지만 차수가 높아질 수록 계산량이 늘어 속도는 느려지게 된다. 따라서 kernel trick을 사용한다. 차수를 완전히 높이지 않더라도 차수를 높인 성능과 동일하게 구성하는 것이다. 사실 차수를 무한정 늘려도 비선형적인 hyperplane을 구성하는 데에는 한계가 있을 것이다. 예를 들어서 100차와 10000차의 graph는 별 차이가 없는 것과 마찬가지란 말이다.

-------

SVM 회귀

SVM 회귀는 분류와 매우 다른데, 회귀는 가능하면 hyperplane에 많은 support vector를 수용하지만, 이때 hyperplane을 point가 벗어나는 오차를 최소화하하도록 구성한다. 그니깐 결국엔 제한된 margin error를 가지게 하는 것이다. 여기서의 hyperplane의 폭은 입실론으로 조정한다.

-------

SVM 이론

SVM은 loss function으로 힌지 손실을 사용하는데, 여기서 힌지는 학습 데이터 각각의 범주를 구분하면서 데이터와의 거리가 가장 먼 결정 경계를 찾는 것이다. 여기서의 힌지 손실을 가능하면 낮게 구성하는 것이 좋다.

------

결정 트리

결정 트리란 if-then의 연속이며, 각 노드에서 특정 값의 임계값 k에 의하여 2개의 subset으로 계속 나뉘어지는 것을 말한다. 결정 트리의 노드는 총 3가지, 가장 맨 위에 있는 노드인 루트 노드, 중간에서 2개의 subset을 만드는 분할 노드, 맨 끝을 구성하는 leaf node가 있다. 여기서 각 노드를 구성하는 속성은 아래와 같다.

samples은 이 노드에 얼마나 많은 samples이 접근하였는가를 나타낸다. 예를 들어서 samples이 1000이면 이 노드에서 두개의 subset으로 split되기 전 1000개의 노드가 있다는 것이다. 또한 values는 현재 노드에서 각 클래스에 있는 샘플의 갯수를 의미한다. 마지막으로 gini는 gini impurity의 값을 의미한다. 

결정트리의 장점이란 각 component의 scaling이 따로 필요 없으며, 평균을 원점으로 할 필요가 없다. 그리고 전처리가 거의 필요 없다는 점이 큰 장점이 된다.

-------

모델 해석

모델을 해석하는 데에는 화이트박스와 블랙박스가 있다. 화이트박스 모델은 모델의 연산 과정을 매우 쉽게 알 수 있는 모델을 의미하며, 예시로는 지금 다루는 decision tree가 있다. 블랙박스는 모델의 연산 과정은 쉽게 알 수 있으나, 왜 그런 예측을 하였는 지는 명확히 설명할 수 없는 모델을 의미한다. 블랙박스의 예시로는 신경망, random forest가 있다. 그래서 결국에 설명할 수 있는 모델인 explainable AI가 요즘 ai 신기술에서 가장 주목받고 있는 기술이다. 

-------

결정 트리의 훈련과 원리

결정 트리는 CART 손실 함수로 구성된다. 여기서 CART를 최소화시켜야 하는데, CART란 학습 데이터셋을 하나의 특성 k의 임계값을 사용하여 두개의 subset으로 분리시키는 것을 말한다. CART는 지금, 그니깐 국소적으로 현재의 값을 최적화하지 전체적인 트리의 깊이나 파라미터의 수 등을 생각하지 않는다. 따라서 그리디 알고리즘이라고 볼 수 있다. 따라서 예측 속도는 빠르지만, 학습 속도는 매우 느리다. 불순도는 gini, entropy가 있다.

------

결정 트리의 규제 

결정 트리의 규제는 파라미터가 그의 역할을 한다. 비파라미터 모델이란 파라미터를 사용자가 지정하지 않은 모델로써, 이러면 명확한 기준이 바로세우지 않기 때문에 overfitting이 발생할 수 있지만, 파라미터를 지정해놓는 파라미터 모델은 선형적인 모델인 경우에는 파라미터가 결정되어 있기 때문에 자유도가 적고, 자유도가 적으면 편향은 커서 결국엔 underfitting은 막을 수 있는 것이다. (train data에 대한 학습은 제대로 일어날 수 있는 것임)

따라서 결정트리는 리프 노드의 수 제한, depth, 분리 시 CART 알고리즘에서의 feature의 임계값 k의 갯수 등을 hyperparameter로 제공하여 overfitting을 막는다.

-------

결정 트리 회귀

결정 트리의 예측값은 평균값으로 구성되고, 알고리즘이 예측값과 가능한 많은 샘플이 가까이 있도록 영역을 분할한다. 불순도를 최소화하며, MSE도 동시에 최소화하는 방향으로 학습하게 된다. 

-------

결정 트리의 축 & 문제점

결정 트리의 축은 수직으로 이루어져 있으며, 이는 데이터의 방향성에 매우 민감하다는 의미이다. 결정 트리의 가장 큰 문제점은 분산이 크다는 건데, 분산이 크면 사용자의 하이퍼파라미터가 살짝 변해도 아예 다른 모델이 생성될 수 있다는 것이기 때문에 각각의 예측을 종합하여 결과를 내리는 ensemble 모델인 random forest가 decision tree의 해결책이 될 수 있다.

-------

앙상블 학습

앙상블 학습이란 다양한 약한 예측기들을 연결하여 강한 예측기를 만드는 것을 의미한다. 약한 예측기의 예측값을 종합하여 다수결, 평균 등의 방법을 사용해 최종적인 결과를 만든다. 이때 각각의 예측값의 오차가 서로 달라야 다양성을 보장할 수 있기 때문에 더 좋은 모델을 만들 수 있다. 

random forest란 decision tree의 모임으로, 개별 트리의 예측을 모아 가장 많은 선택을 받은 class를 최종 예측 결과로 두는 알고리즘이다. 이때 배깅이나 페이스팅으로 샘플링한다.

------

배깅, 페이스팅

배깅이란 train set에서 중복을 허용하여 샘플링하는 것을 의미하고, 페이스팅이란 train set에서 중복을 비허용하여 샘플링하는 것을 의미한다. 중복을 허용한다는 것은 특정 데이터가 여러번 뽑힐 수 있다는 것을 의미하니, 배깅이 페이스팅보다 편향성이 조금 더 강하다.

-----

OOB 평가

배깅을 하면 train set에서 63% 정도가 샘플링되는데, 나머지 37%는 선택받지 못한 샘플로써, OOB라고 불린다. (Out Of Bag) 이때 이 37%의 데이터를 val set 교차 검증으로 사용한다. OOB 평가는 학습이 끝난 이후에 자동적으로 진행된다. (oob_score=True라면)

------

random patches method, random subspaces method

Random Patches: 데이터의 일부 샘플과 일부 특성을 무작위로 골라서 각 모델이 서로 다른 부분을 학습하게 하는 방법. 샘플과 특성 모두 무작위로 선택해 다양성을 극대화함.

Random Subspaces: 모든 샘플을 사용하되, 일부 특성만 무작위로 골라서 각 모델이 다른 특성 조합을 학습하게 하는 방법. 고차원 데이터에서 오버피팅을 줄이는 데 효과적임.

random patches method, random subspaces method 전부 다 배깅이나 페이스팅과 비슷한 특성 샘플링이다. random patches는 샘플과 특성을 모두 무작위로 샘플링하여 각 모델이 서로 다른 부분을 학습하는 것이다. 이로 인하여 모델의 다양성을 극대화하는 방식이다. random subspaces method는 모든 샘플을 사용하되 특성을 랜덤으로 샘플링하여 모델의 overfitting을 줄이기 위한 수단이다. 이 둘은 편향은 높지만 분산을 낮춘다.

-------

랜덤 포레스트의 feature sampling & extra tree

extra tree : Extra Trees는 랜덤 포레스트와 비슷한 앙상블 방법으로, 의사결정 트리를 더 무작위하게 학습시켜 모델의 다양성을 극대화하는 알고리즘입니다. 주요 차이점은 분할 기준을 무작위로 선택하여 트리 분할을 수행하고, 부트스트래핑 없이 전체 데이터를 사용해 학습할 수 있다는 점입니다. 

랜덤 포레스트는 전체 특성에서 최선의 특성을 찾는 대신에 random patches method나 random subspaces method와 같이 랜덤으로 샘플링하는 것이다. 이로 인하여 무작위성을 더욱 주입하여 트리를 다양하게 만들고, 이때 편향이 커지지만 분산을 낮춘다. extra tree라고 하는 알고리즘은 트리의 다양성을 극대화하기 위하여 분할 기준을 무작위로 선택함과 동시에 부트스트래핑 없이 전체 데이터를 사용해 학습하는 방식이다. (학습 속도가 훨씬 빠르다)

------

부스팅

부스팅은 크게 3가지, adaboost, gradient boosting, HGB가 있다. adaboost는 문제를 잘 해결하지 못하는 sample에게 더 큰 가중치를 부여하여 어려운 sample을 더 잘 예측할 수 있도록 하는 부스팅 기법이다. gradient boosting은 이전 모델과 현재 모델의 loss의 차이인 reconstruction error을 최소화하는 방향으로 학습하는 부스팅 기법이다. HGB는 히스토그램 기반 gradient boosting이다.

-----

스태킹 

스태킹이랑 ensemble하여 나온 결과를 새로운 메타모델의 입력으로 받아들여서 더욱 성능 좋은 모델을 개발하는 것을 말한다.

-----

차원의 저주

차원의 저주란 feature의 갯수, 즉 dimensionality가 너무 커서 모델이 오히려 제대로 된 학습이 어려워지는 현상을 말한다. 데이터의 차원이 증가한다는 것은 model parameter가 증가한다는 것이고, 이는 데이터 공간의 부피가 증가함을 이야기하며, 부피가 증가하면 데이터의 밀도가 희소해진다. 결국에는 모델 과적합의 원인이 된다.

----

차원의 저주 해결 방법

차원의 저주를 해결하기 위해선 manifold learning과 투영이 있다. 투영이란 고차원을 저차원 공간 가까이 배치하여서 nD를 n-1D로 변환하는 과정을 의미한다. 투영하게 되면 물론 연산량이 대폭 감소할 수는 있으나 오차가 발생할 수 있다. 추후에 보게 될 PCA에서도 고차원을 저차원으로 dimensionality reduction하게 될 텐데 이때 다시 restore가 가능하지만 아무래도 loss 때문에 완전한 복구가 어렵다. manifold learning은 n차원의 고차원을 저차원의 manifold로 변환하면 더욱 속도가 빨라지겠다는 가설이다. 

-----

PCA

PCA란 주성분 분석으로, 데이터의 분산이 최대가 되는 축을 찾는 알고리즘이다. 순서로는, 학습 데이터셋에서 분산이 최대인 축을 찾고, 이 축과 두번째로 분산이 최대이면서 수직인 축을 찾고... 이를 계속 반복하여서 압축한다. 차원 축소 후에는 data set의 데이터 공간의 밀도는 커질 것이다. (이전에 데이터 공간이 컸기 때문에 밀도가 작았다) 

-----

랜덤 PCA, 점진적 PCA, 랜덤투영, 지역선형임베딩, isomap, 다차원스케일링, t-SNE, 선형판별분석

랜덤 PCA는 대용량 데이터셋을 다룰 때 빠르게 차원을 축소할 수 있는 방법입니다. 보통 PCA는 데이터의 분산이 가장 큰 방향을 찾아서 이를 기준으로 축을 정하는데, 랜덤 PCA는 이 과정을 조금 단순화해서 무작위로 축을 잡고 근사치를 구합니다. 정확성보다는 속도에 더 중점을 둡니다.

점진적 PCA는 대규모 데이터셋을 한꺼번에 메모리에 불러오지 않고, 작은 배치로 나눠서 반복적으로 처리합니다. 데이터를 한 번에 전체를 다 불러오는 것이 아니라 조금씩 불러와서 처리하는 것이므로 메모리 효율이 높습니다.

랜덤 투영은 차원을 줄이기 위해 무작위로 방향을 선택해 데이터를 투영하는 방법입니다. 본질적으로, 랜덤 투영을 통해 고차원의 데이터를 무작위의 저차원 공간에 투영하면 원래 데이터 간의 거리를 어느 정도 보존할 수 있다는 수학적 사실에 기반합니다.

LLE는 데이터가 실제로는 저차원 공간에 존재하지만 그 형태가 구부러지거나 꼬여 있는 경우에 유용합니다. 데이터가 매니폴드(휘어진 표면)에 놓여 있다고 가정하고, 데이터의 국소적인 관계를 보존하면서 차원을 축소합니다.

ISOMAP은 매니폴드 학습 알고리즘 중 하나로, 데이터가 휘어진 구조일 때 그 구조를 고려하여 차원을 축소합니다. 데이터 간의 거리를 유지하면서도 매니폴드 구조를 따라 차원을 축소하는 점에서 LLE와 유사하지만, 전체 데이터를 고려하여 전역적으로 거리를 유지하려고 합니다.

MDS는 데이터 간의 거리를 최대한 유지하면서 차원을 축소하는 방법입니다. 이 방법은 원래 고차원 데이터에서의 유사성을 저차원에서도 최대한 비슷하게 유지하고자 합니다.

t-SNE는 고차원 데이터에서 각 데이터 간의 유사성을 최대한 보존하면서 차원을 줄이는 방법입니다. 특히 클러스터링이 잘 보이도록 데이터 포인트를 2D나 3D로 투영하는 데 탁월한 성능을 발휘합니다.

LDA는 차원을 줄이면서 데이터의 클래스 정보를 보존하려는 목적의 방법입니다. 데이터 간의 분산을 최대한 크게 하면서, 클래스 내의 분산을 작게 만들어서 특정 클래스에 속하는 데이터끼리 잘 모이도록 차원을 축소합니다.
