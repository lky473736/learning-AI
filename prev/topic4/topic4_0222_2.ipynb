{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b995c6-765b-408a-ad9e-6e6f3d475453",
   "metadata": {},
   "source": [
    "### learning-AI101 : topic4_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19390b-d1dd-4886-8407-374d942f1c59",
   "metadata": {},
   "source": [
    "#### RNN 구현 : 작곡 AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461891e0-6f73-428f-8798-393de0b2c739",
   "metadata": {},
   "source": [
    "(복습) 인공지능 구축하는 법\n",
    "- 0) 데이터 전처리, 데이터 준비하기\n",
    "  1) 모델링\n",
    "  2) compile\n",
    "  3) fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19043218-c8de-4153-a454-1d35bc2f956c",
   "metadata": {},
   "source": [
    "#### 0. 데이터 전처리, 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc548670-8d55-40e9-bac6-0bee38c60c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\"G\"d2B\"D\"A3/2B/2c\"G\"B2G\"D\"A2e\"G\"d2B\"D\"A3/2B/2c:2/4\"F\"BF:3/4\"G\"G2e:\"C\"g2e\"Bb\"f2d\"F\"c2AF2e\"C\"g2e\"Bb\"f\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 파일 열기\n",
    "data = open('../data/pianoabc/pianoabc.txt', 'r').read()\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab5dd2-01bd-44a7-9d89-4c551f10fece",
   "metadata": {},
   "source": [
    "**위에 보니깐 코드랑 숫자 등이 있음 <-- 느낌 상 abc notation 악보일 가능성이 높음**  \n",
    "- compile, fit하기 위해서 문자나 숫자로 치환하여야 함\n",
    "- 악보에 abc notation을 적용하여 음악을 숫자나 문자로 치환하였음\n",
    "- 숫자는 음표의 길이 / 영어는 CDEFGABC (도레미파솔라시)\n",
    "- pianoabc.txt는 abc notation으로 짜여진 클래식 악보 몇개를 이어붙인 파일이다\n",
    "- 따옴표 : 주석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d44acf-1f42-4454-989d-460001a3c3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', \"'\", ',', '/', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', 'A', 'B', 'C', 'D', 'E', 'F', 'G', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'z']\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# 문자로 되어있으니 숫자로 바꾸어야 한다 (학습하려면) -> bag of words 만들기\n",
    "# bag of words : 특정 파일에서 문자가 무엇무엇이 있는지, 숫자가 무엇무엇이 있는지\n",
    "# a는 1, b는 2... 이런 식으로 문자를 숫자로 치환\n",
    "\n",
    "bag_of_words = list(set(data)) # set을 이용하여 bag of words 만들기\n",
    "bag_of_words.sort() # 뒤죽박죽인 set을 위해 sort()처리를 한번 함\n",
    "print (bag_of_words)\n",
    "print (len(bag_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d92f5b1c-e739-4251-812a-d4b41dacddb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\"': 0, \"'\": 1, ',': 2, '/': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, ':': 13, 'A': 14, 'B': 15, 'C': 16, 'D': 17, 'E': 18, 'F': 19, 'G': 20, '^': 21, '_': 22, 'a': 23, 'b': 24, 'c': 25, 'd': 26, 'e': 27, 'f': 28, 'g': 29, 'z': 30}\n"
     ]
    }
   ],
   "source": [
    "# bag of words를 이용해서 data_table을 만들어보자\n",
    "\n",
    "digital_data = data\n",
    "\n",
    "data_table = {}\n",
    "numbering = 0\n",
    "\n",
    "for i in bag_of_words :\n",
    "    data_table[bag_of_words[numbering]] = numbering\n",
    "    numbering += 1\n",
    "\n",
    "print (data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27d4640d-8e0a-4dac-a150-b789c8cc47ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 0, 20, 0, 26, 5, 15, 0, 17, 0]\n"
     ]
    }
   ],
   "source": [
    "# data를 숫자화하여 digital_data 저장하기\n",
    "digital_data = []\n",
    "\n",
    "for i in data : \n",
    "    digital_data.append(data_table[i])\n",
    "    \n",
    "print (digital_data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b09083-58af-4f00-8e27-824d8b6d72a6",
   "metadata": {},
   "source": [
    "결론\n",
    "- digital_data : data를 수치화함\n",
    "- bag_of_words : data에 있는 모든 문자와 숫자\n",
    "- 그러면 trainX, trianY를 어떻게 만드는가?\n",
    "  - 만약 [27, 0, 20, 0, 26]이라는 데이터가 있을 때\n",
    "  - RNN의 목적은 그 다음 걸 예측하는 것이기 때문에,\n",
    "  - trainX가 [27, 0]이라면 trainY는 [20]\n",
    "  - trainX가 [27, 0, 20, 0]이라면 trainY는 26이다. X 다음 값이 당연히 Y가 된다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd5bf9e-6e54-46d8-9c5b-d447d6810b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292022\n",
      "25 11680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 15, 0, 20, 0, 20, 5, 20, 20, 5, 17, 0, 18, 0, 20, 5, 18, 0, 20, 0, 20, 6]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainX와 trainY 만들기\n",
    "# trainX가 25개일때, trainY가 1개이도록 만들기\n",
    "length = len(digital_data)\n",
    "print (length)\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "num = 0\n",
    "\n",
    "while True :\n",
    "    try : \n",
    "        train_X.append(digital_data[num : num + 25])\n",
    "        train_Y.append(digital_data[num + 25])\n",
    "        num += 25\n",
    "\n",
    "    except IndexError :\n",
    "        break\n",
    "\n",
    "print (len(train_X[0]), len(train_Y))\n",
    "train_X.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8733a1e-62a9-4d63-8498-8f95e7dd9f54",
   "metadata": {},
   "source": [
    "**np.array를 이용해서 shape을 확인해보자**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8192b4-57d6-4e68-802d-37173c7391c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 17:36:55.559987: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a7890-d64a-4ed9-bfda-d4f19179a349",
   "metadata": {},
   "source": [
    "**원핫인코딩을 하여 학습효율을 높이자**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1aab3b1-c0ae-406b-9689-c1df5b875002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(2, 25, 31), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_X = tf.one_hot(train_X, 31)\n",
    "train_Y = tf.one_hot(train_Y, 31)\n",
    "print(train_X[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab0507-15f2-4e0b-9806-69cfb9c6b1a6",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152fb57-8ebb-432e-b83e-49f6116b545c",
   "metadata": {},
   "source": [
    "#### 1. 모델링 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ca827a0-14c6-40e5-82fa-c4d2c448b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # LSTM 레이어를 통해 RNN을 구성하자\n",
    "    tf.keras.layers.LSTM(100, input_shape=(25, 31)),\n",
    "    # 문자 31개 중 마지막에 올 문자를 예측하는 문자와 같음 -> 따라서 softmax + categorical_crossentropy를 사용\n",
    "    tf.keras.layers.Dense(31, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# LSTM 레이어를 사용할 땐 activation을 중간에 넣을 필요가 없다\n",
    "# LSTM 레이어를 사용할 땐 epochs를 엄청 많이 돌려야한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0bbe85-215f-4e56-8355-7b2582a16f34",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1924f466-2344-4061-a470-ddae2f52dc6d",
   "metadata": {},
   "source": [
    "#### 2. fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aab19558-b873-4129-86e4-853a03e214bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "183/183 [==============================] - 4s 10ms/step - loss: 2.6572\n",
      "Epoch 2/50\n",
      "183/183 [==============================] - 2s 14ms/step - loss: 2.2418\n",
      "Epoch 3/50\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 1.9373\n",
      "Epoch 4/50\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 1.7647\n",
      "Epoch 5/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 1.6843\n",
      "Epoch 6/50\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 1.6329\n",
      "Epoch 7/50\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 1.5915\n",
      "Epoch 8/50\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 1.5501\n",
      "Epoch 9/50\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 1.5207\n",
      "Epoch 10/50\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 1.4900\n",
      "Epoch 11/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 1.4615\n",
      "Epoch 12/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 1.4361\n",
      "Epoch 13/50\n",
      "183/183 [==============================] - 6s 30ms/step - loss: 1.4115\n",
      "Epoch 14/50\n",
      "183/183 [==============================] - 5s 29ms/step - loss: 1.3907\n",
      "Epoch 15/50\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 1.3714\n",
      "Epoch 16/50\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 1.3468\n",
      "Epoch 17/50\n",
      "183/183 [==============================] - 5s 27ms/step - loss: 1.3241\n",
      "Epoch 18/50\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 1.3008\n",
      "Epoch 19/50\n",
      "183/183 [==============================] - 5s 27ms/step - loss: 1.2781\n",
      "Epoch 20/50\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 1.2551\n",
      "Epoch 21/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 1.2327\n",
      "Epoch 22/50\n",
      "183/183 [==============================] - 5s 29ms/step - loss: 1.2091\n",
      "Epoch 23/50\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 1.1829\n",
      "Epoch 24/50\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 1.1534\n",
      "Epoch 25/50\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 1.1290\n",
      "Epoch 26/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 1.1041\n",
      "Epoch 27/50\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 1.0757\n",
      "Epoch 28/50\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 1.0425\n",
      "Epoch 29/50\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 1.0135\n",
      "Epoch 30/50\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.9898\n",
      "Epoch 31/50\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.9555\n",
      "Epoch 32/50\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 0.9258\n",
      "Epoch 33/50\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 0.8966\n",
      "Epoch 34/50\n",
      "183/183 [==============================] - 5s 29ms/step - loss: 0.8654\n",
      "Epoch 35/50\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.8357\n",
      "Epoch 36/50\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.8073\n",
      "Epoch 37/50\n",
      "183/183 [==============================] - 5s 30ms/step - loss: 0.7780\n",
      "Epoch 38/50\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.7506\n",
      "Epoch 39/50\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.7187\n",
      "Epoch 40/50\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 0.6925\n",
      "Epoch 41/50\n",
      "183/183 [==============================] - 5s 30ms/step - loss: 0.6620\n",
      "Epoch 42/50\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 0.6350\n",
      "Epoch 43/50\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.6057\n",
      "Epoch 44/50\n",
      "183/183 [==============================] - 7s 38ms/step - loss: 0.5811\n",
      "Epoch 45/50\n",
      "183/183 [==============================] - 5s 29ms/step - loss: 0.5569\n",
      "Epoch 46/50\n",
      "183/183 [==============================] - 5s 27ms/step - loss: 0.5296\n",
      "Epoch 47/50\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 0.5028\n",
      "Epoch 48/50\n",
      "183/183 [==============================] - 5s 27ms/step - loss: 0.4732\n",
      "Epoch 49/50\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 0.4484\n",
      "Epoch 50/50\n",
      "183/183 [==============================] - 7s 38ms/step - loss: 0.4261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x141f32590>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba88580-104f-40b2-a33d-0a3114c4453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100)               52800     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 31)                3131      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55931 (218.48 KB)\n",
      "Trainable params: 55931 (218.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcade888-6c09-4fef-80ad-0f7eca0d5e5b",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1afd78-ba58-45fe-8a0e-d114923d24e1",
   "metadata": {},
   "source": [
    "#### 여태까지 했던거 정리\n",
    "- LSTM 레이어를 이용하여 작곡 AI를 만듦\n",
    "    - train_X, train_Y로 학습시켰다. (각각 25개, 11680개씩)\n",
    "- 만든 모델\n",
    "    - input : 25개의 문자를 입력한다면\n",
    "    - output : 다음 문자를 예측해주는 프로그램 (일종의 코드)\n",
    "    - 따라서 model.predict([25개 문자])를 하면 한 글자만 예측하게 되니 반복문을 통해 여러번 반복시켜준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "617eb519-8dee-4617-800e-17d856f23b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "다음 문자가 올 확률 :  [[2.9400101e-06 1.5767519e-08 1.6570741e-08 6.6890959e-07 2.7467590e-06\n",
      "  9.9901164e-01 5.9358270e-05 1.8257993e-05 3.3275125e-09 8.6563375e-08\n",
      "  2.5808370e-07 4.5119631e-07 3.0264424e-09 1.1507207e-06 1.6126896e-06\n",
      "  2.0852785e-04 4.0433450e-05 6.4873170e-08 1.6002700e-07 8.6361197e-06\n",
      "  1.3078492e-04 4.2236836e-05 6.1239717e-08 1.7917242e-06 6.0037633e-05\n",
      "  2.1375732e-04 1.0248308e-04 5.4570996e-06 5.6581284e-06 8.0658130e-05\n",
      "  2.9184909e-08]]\n",
      "가장 큰 확률인 다음 문자의 인덱스 :  5\n",
      "가장 큰 확률인 다음 문자 :  2\n",
      "가장 큰 확률인 다음 문자를 수치화 :  5\n",
      "실제 다음 문자 :  5\n"
     ]
    }
   ],
   "source": [
    "# digital_data : 원본 데이터를 수치화한 것\n",
    "# 여기서 랜덤으로 25개 뽑아서 predict에 넣어보자\n",
    "\n",
    "import random\n",
    "ind = random.randint(1, len(digital_data)-26)\n",
    "# 무작위로 데이터 뽑기\n",
    "test_X = digital_data[ind:ind+25]\n",
    "# 원핫인코딩\n",
    "test_X = tf.one_hot(test_X, 31)\n",
    "# 2차원 데이터를 3차원으로 늘리기\n",
    "test_X = tf.expand_dims(test_X, axis = 0)\n",
    "\n",
    "predict_value = model.predict(test_X) # 무작위 25개 데이터 리스트를 넣어줌 \n",
    "print ('다음 문자가 올 확률 : ', predict_value) # 예측값은 다 확률임. 여기서 가장 확률이 높은게 다음 문자가 될거임\n",
    "max_rate = np.argmax(predict_value[0]) # argmax : 특정 리스트에서 가장 높은 확률의 인덱스 리턴\n",
    "print ('가장 큰 확률인 다음 문자의 인덱스 : ', max_rate)\n",
    "print ('가장 큰 확률인 다음 문자 : ', list(data_table.keys())[max_rate])\n",
    "print ('가장 큰 확률인 다음 문자를 수치화 : ', data_table[list(data_table.keys())[max_rate]])\n",
    "print ('실제 다음 문자 : ', digital_data[ind+25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ba7fb-acaa-4b70-a41d-ab451a791591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
