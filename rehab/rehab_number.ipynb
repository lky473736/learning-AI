{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "107b53a8",
   "metadata": {},
   "source": [
    "## learning-AI : rehab\n",
    "### number dataset (self-made)로 Convnet, LSTM-DNN\n",
    "\n",
    "<br>\n",
    "\n",
    "- **임규연 (lky473736)**\n",
    "- 2025.07.28.에 문서 작성\n",
    "- 예시 데이터셋은 현재 진행 중인 프로젝트인 **operation (https://github.com/lky473736/operation-exp)** 에서 나온 아이디어를 가지고 만들었습니다.\n",
    "\n",
    "------\n",
    "\n",
    "- **Reference**\n",
    "    - https://github.com/lky473736/learning-AI101/blob/main/insight/insight_3_split_sequence_and_CNN.ipynb\n",
    "    - https://github.com/lky473736/operation-exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0219bfb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T14:18:35.163508Z",
     "start_time": "2025-07-28T14:18:35.159979Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fb269af",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 목차\n",
    "\n",
    "- **도입 : 순환 데이터의 이해와 self-made 데이터셋인 number dataset**\n",
    "- **1. split_sequences 구현 (특정 window에서 그 다음 수치를 target 값을 선택)**\n",
    "- **2. regression : CNN-DNN, LSTM-DNN**\n",
    "\n",
    "-----\n",
    "\n",
    "### 도입 : 순환 데이터의 이해와 self-made 데이터셋인 number dataset\n",
    "\n",
    "흔히 \"시계열\"이라고 불리우는 데이터들은 3차원 데이터입니다. 왜냐하면 그들의 크기는 (window의 총 갯수, 신호의 window의 수, 신호의 feature 수)로 이루어져 있습니다. 이를테면 UCI-HAR의 데이터를 생각해봅시다. UCI- HAR 데이터셋은 총 2개의 센서를 사용합니다. **가속도계(accelerometer)와 자이로스코프(gyroscope).** 각각의 센서는 x, y, z의 3축 방향 데이터를 제공합니다. 따라서 총 6개의 시계열 신호(가속도 x/y/z + 자이로 x/y/z)가 포함되어 있으며, 이들은 50Hz의 주기로 측정되었습니다. 그러면 feature의 갯수는 총 6개가 될 것이며, window는 50개의 수치로 이루어져 있을 것이며, 그 window가 가령 1000개 있다면 전체 데이터셋의 크기는 (1000, 50, 6)이 될 겁니다.\n",
    "\n",
    "그러면 window는 무엇일까요? window를 알아보기 전에, 만약 DNN을 시계열 데이터 분석에 사용한다면 어떻게 될까요? 그저 단순히 모든 노드를 연결하여 각각의 데이터포인트를 모두 짚어서 보는 FCNN은 이미지나 신호에 적합한 네트워크가 아닙니다. 모든 수치를 개별적으로 취급하여 보기 때문에 signal의 주기성이나 모양, 특징을 파악할 수 없기 때문에 representation을 얻기엔 부족하니, 시계열을 묶음 형태로 잘라서 보자는 겁니다. 시계열을 묶음 형태로 잘라서 보면, 묶음과 묶음 사이의 표현을 학습할 수 있게 되면서 모든 포인트를 보지 않아도 전체적으로 시계열의 표현을 학습할 수 있게 되는 겁니다. (그래서 PatchTST나 Mamba같은 것도 생기지 않았습니까? 시계열 혹은 텍스트를 잘라서 큰 덩어리로 보자는 개념입니다.) \n",
    "\n",
    "<img src=\"https://images.velog.io/images/findingflow/post/088196e2-54ae-4d82-a2a3-7c3110545fca/image.png\" width=\"600px\" align=\"center\"> \n",
    "\n",
    "위 그림이 시계열을 windowing, 즉 여러 묶음으로 만드는 것입니다. 저렇게 한 포인트씩 (한 수치씩) 앞으로 전진하면서 특정 window size만큼 묶어내는 것이죠. 이제 모델에게 저 묶음을 input으로 주게 됩니다. 시계열 AI를 공부하면서 가장 헷갈렸던 포인트를 아래에 정리해보겠습니다.\n",
    "\n",
    "- Q. 그러면 저 window들을 통해 모델을 학습시키게 된다면, 모델은 minibatch gradient descent될 때 각 window들이 섞일 것인데 시계열은 섞는 순간 선후관계가 없어지는 것 아닌가?\n",
    "    - A. windowing을 하는 목적을 기억해야 합니다. windowing을 하는 목적은 연속성 살리기입니다. 만약 시계열에 windowing을 하지 않고 각각의 수치 하나하나씩을 보게 된다면 tabular을 다루는 것과 다름이 없습니다. windowing을 하는 것 자체가 시간적 상호관계를 가능한 한 살리면서 보자는 취지입니다. 따라서 아무리 섞어도 window 안 수치들이 섞이는 게 아니라서 괜찮습니다.\n",
    "- Q. 시계열을 CNN에? CNN은 이미지를 학습시키는 네트워크가 아닌가?\n",
    "    - A. Conv1D를 사용하면 됩니다. Conv1D는 아래처럼 작동합니다. 아래처럼 filter의 갯수만큼 stride의 양대로 slide되면서 feature map을 구성하게 되는 것이지요.\n",
    "    - <img src=\"https://divingintogeneticsandgenomics.com/img/conv1d.png\" width=\"500px\">\n",
    "\n",
    "따라서, windowing하는 함수인 split_seqeunces를 이용하여 number dataset에 적용하고 이를 CNN-DNN과 CNN-LSTM에 적용해볼 것입니다. number dataset은 굉장히 직관적이게 구성된 내가 직접 만든 데이터셋으로, 아래와 같이 구성하려고 합니다.\n",
    "\n",
    "- 1부터 50000까지 숫자가 있다고 가정\n",
    "- windowing 진행 (target값은 다음 값)\n",
    "    - 예를 들어 window size가 10이라면 input은 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], target은 11\n",
    "- input에 -0.1~0.1의 랜덤 노이즈 첨가 (실제 현장에서 노이즈 섞인 걸 구현해내기 위함)\n",
    "\n",
    "-----\n",
    "\n",
    "### 1. split_sequences 구현 (특정 window에서 그 다음 수치를 target 값을 선택)\n",
    "\n",
    "<img src='https://www.researchgate.net/publication/325158306/figure/fig5/AS:681968115134465@1539605277480/Sliding-window-technique.ppm' width='500px' align=center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d782e43f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T14:18:35.870006Z",
     "start_time": "2025-07-28T14:18:35.165972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [4, 5, 6, 7, 8, 9, 10, 11, 12, 13], [5, 6, 7, 8, 9, 10, 11, 12, 13, 14], [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [8, 9, 10, 11, 12, 13, 14, 15, 16, 17], [9, 10, 11, 12, 13, 14, 15, 16, 17, 18], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "# split_sequences 구현 \n",
    "'''\n",
    "    - 여기서는 1d array가 input임을 가정하고 만듦\n",
    "'''\n",
    "\n",
    "def split_sequences(data, window_size) :\n",
    "    sequences = {'windows' : [],\n",
    "              'target' : []}\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(data) and i+window_size < len(data) :\n",
    "        window = data[i:i+window_size]\n",
    "        target = data[i+window_size]\n",
    "        \n",
    "        sequences['windows'].append(window)\n",
    "        sequences['target'].append(target)\n",
    "        i = i + 1\n",
    "        \n",
    "    return sequences\n",
    "\n",
    "data = [i for i in range (1, 50001)]\n",
    "sequences = split_sequences(data, \n",
    "                           window_size=10)\n",
    "\n",
    "print (sequences['windows'][:10])\n",
    "print (sequences['target'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ebcb861c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T14:18:36.195351Z",
     "start_time": "2025-07-28T14:18:35.872197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9, 2.1, 3.1, 3.9, 5.1, 6.0, 6.9, 8.1, 8.9, 10.0], [2.0, 3.0, 4.1, 5.1, 6.0, 6.9, 8.0, 9.0, 10.0, 11.1]]\n",
      "[11, 12]\n"
     ]
    }
   ],
   "source": [
    "# noise 추가\n",
    "\n",
    "import random \n",
    "\n",
    "for i in range (len(sequences['windows'])) :\n",
    "    for j in range (len(sequences['windows'][i])) : \n",
    "        sequences['windows'][i][j] += random.randint(-1, 1) * 0.1\n",
    "\n",
    "print (sequences['windows'][:2])\n",
    "print (sequences['target'][:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6116db0",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "### 2. regression : CNN-DNN, LSTM-DNN\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*n7r5J6oEcG_LgeevnD1abw.jpeg\" width=\"500px\" align=center>\n",
    "\n",
    "CNN layer은 크게 Convolution layer, Pooling layer로 이루어져 있다. Convolution layer은 feature extraction, 즉 특정 데이터의 특징을 추출하는 역할을 수행한다. 애초에 convolution 연산이 filter가 데이터 영역을 돌면서 새로운 제 2의 feature을 만드는 역할이니, 딥러닝에서 제 2의 feature은 원본 데이터의 특징일 것이다. Pooling layer은 feature map의 크기를 줄이면서 이동 불변성을 유지하는 역할을 도맡는다. 최근에 알게 된 사실인데, Convolution layer은 사실은 Cross-Correlation으로 불리우는 게 더 맞다고 한다. CNN에서의 convolution은 실제 convolution처럼 component들을 뒤집지 않는다. 단지 상호관계에 있는 수들을 뽑아내는 역할이지.\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/9982923F5ACB86A10E\" width=\"500px\" align=center>\n",
    "\n",
    "\n",
    "LSTM은 RNN의 장기 기억 및 단기 기억 비포괄 문제를 해결하기 위해 cell state를 도입한 네트워크이다. 보통은 RNN과 마찬가지로 activation function을 tanh를 사용하지만, LSTM은 너무 복잡한 구조이면서 긴 sequence에 대한 입력을 제대로 해결하지 못함으로 transformer가 나왔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "314b71b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T14:18:36.242375Z",
     "start_time": "2025-07-28T14:18:36.197918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49990, 10)\n",
      "(49990, 1, 10)\n",
      "torch.Size([49990, 1, 10]) torch.Size([49990])\n"
     ]
    }
   ],
   "source": [
    "# reshape : feature 1개\n",
    "# pytorch로 학습하기 위해서 tensor로 변경 \n",
    "\n",
    "# nn.Conv1d는 입력을 [batch_size, in_channels, sequence_length]\n",
    "\n",
    "data = np.array(sequences['windows'])\n",
    "target = np.array(sequences['target'])\n",
    "\n",
    "print (data.shape)\n",
    "\n",
    "data = data.reshape(data.shape[0], 1, data.shape[1])  # (N, 1, T)\n",
    "\n",
    "print (data.shape)\n",
    "\n",
    "data = torch.tensor(data)\n",
    "target = torch.tensor(target)\n",
    "print (data.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "78a99d39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T14:18:36.254864Z",
     "start_time": "2025-07-28T14:18:36.244897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31993, 1, 10]) torch.Size([9998, 1, 10]) torch.Size([7999, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "# train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target,\n",
    "                                                   test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                 test_size=0.2)\n",
    "\n",
    "print (X_train.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "18c7ba20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T14:18:36.266255Z",
     "start_time": "2025-07-28T14:18:36.257408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31993\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x12f195f10>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x12b8adf10>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1312b8110>\n"
     ]
    }
   ],
   "source": [
    "# batch 단위로 Dataloader 구축\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class Number(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data \n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.target[idx]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_DS = Number(X_train, y_train)\n",
    "test_DS = Number(X_test, y_test)\n",
    "val_DS = Number(X_val, y_val)\n",
    "\n",
    "print (len(train_DS))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_DL = DataLoader(train_DS, \n",
    "                     batch_size=32,\n",
    "                     shuffle=True)\n",
    "test_DL = DataLoader(test_DS,\n",
    "                    batch_size=32,\n",
    "                    shuffle=False) # False해야 하는 이유 : 검증/테스트는 모델이 얼마나 잘 학습됐는지를 \"정확하게\" 평가해야 해서\n",
    "val_DL = DataLoader(val_DS,\n",
    "                    batch_size=32,\n",
    "                    shuffle=False) # 이하동문\n",
    "\n",
    "print (train_DL)\n",
    "print (test_DL)\n",
    "print (val_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "923cca30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T14:18:36.291581Z",
     "start_time": "2025-07-28T14:18:36.269194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_DNN                                  [32, 1]                   --\n",
       "├─Sequential: 1-1                        [32, 25, 8]               --\n",
       "│    └─Conv1d: 2-1                       [32, 25, 8]               100\n",
       "│    └─BatchNorm1d: 2-2                  [32, 25, 8]               50\n",
       "│    └─ReLU: 2-3                         [32, 25, 8]               --\n",
       "├─MaxPool1d: 1-2                         [32, 25, 4]               --\n",
       "├─Sequential: 1-3                        [32, 50, 2]               --\n",
       "│    └─Conv1d: 2-4                       [32, 50, 2]               3,800\n",
       "│    └─BatchNorm1d: 2-5                  [32, 50, 2]               100\n",
       "│    └─ReLU: 2-6                         [32, 50, 2]               --\n",
       "├─MaxPool1d: 1-4                         [32, 50, 1]               --\n",
       "├─AdaptiveAvgPool1d: 1-5                 [32, 50, 1]               --\n",
       "├─Sequential: 1-6                        [32, 1]                   --\n",
       "│    └─Linear: 2-7                       [32, 10]                  510\n",
       "│    └─BatchNorm1d: 2-8                  [32, 10]                  20\n",
       "│    └─ReLU: 2-9                         [32, 10]                  --\n",
       "│    └─Linear: 2-10                      [32, 1]                   11\n",
       "==========================================================================================\n",
       "Total params: 4,591\n",
       "Trainable params: 4,591\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.29\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.16\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 0.18\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN-DNN model\n",
    "\n",
    "class CNN_DNN (nn.Module) : \n",
    "    def __init__ (self) :\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1,\n",
    "                     out_channels=25,\n",
    "                      kernel_size=3,\n",
    "                     stride=1),\n",
    "            nn.BatchNorm1d(25),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=2) \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=25,\n",
    "                     out_channels=50,\n",
    "                      kernel_size=3,\n",
    "                     stride=1),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=2) \n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(50, 10),\n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1) \n",
    "        )\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)   \n",
    "        return self.classifier(x)\n",
    "\n",
    "model_CNN_DNN = CNN_DNN()\n",
    "summary(model_CNN_DNN,\n",
    "       input_size=(32, 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "69d7fd97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T00:07:34.836118Z",
     "start_time": "2025-07-29T00:07:34.821429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM_DNN                                 [32, 1]                   --\n",
       "├─LSTM: 1-1                              [32, 10, 64]              50,432\n",
       "├─Sequential: 1-2                        [32, 1]                   --\n",
       "│    └─Linear: 2-1                       [32, 32]                  2,080\n",
       "│    └─ReLU: 2-2                         [32, 32]                  --\n",
       "│    └─Linear: 2-3                       [32, 16]                  528\n",
       "│    └─ReLU: 2-4                         [32, 16]                  --\n",
       "│    └─Linear: 2-5                       [32, 1]                   17\n",
       "==========================================================================================\n",
       "Total params: 53,057\n",
       "Trainable params: 53,057\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 16.22\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.18\n",
       "Params size (MB): 0.21\n",
       "Estimated Total Size (MB): 0.39\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM-DNN model\n",
    "\n",
    "class LSTM_DNN_Improved(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1, \n",
    "            hidden_size=64, \n",
    "            num_layers=2, \n",
    "            batch_first=True,\n",
    "            dropout=0.2,  # LSTM 레이어 간 dropout 추가\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(64)\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),  # BatchNorm 추가\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),     # Dropout 추가\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (batch, seq_len, feature)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        x = lstm_out[:, -1, :]\n",
    "        x = self.tanh(x)  \n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        out = self.fc_layers(x)\n",
    "        return out\n",
    "\n",
    "model_LSTM_DNN = LSTM_DNN()\n",
    "summary(model_LSTM_DNN, input_size=(32, 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "82265304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T00:35:12.881778Z",
     "start_time": "2025-07-29T00:07:38.410285Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-DNN\n",
      "epoch 1 : train loss 833683325.376, val loss 817522311.936\n",
      "epoch 2 : train loss 92768419.72615235, val loss 107373.3659375\n",
      "epoch 3 : train loss 25539.513799060343, val loss 1571.28721251297\n",
      "epoch 4 : train loss 774.8819674133063, val loss 391.18407943725583\n",
      "epoch 5 : train loss 280.88196085476875, val loss 223.0464349911213\n",
      "epoch 6 : train loss 199.0317246317193, val loss 180.09034726786612\n",
      "epoch 7 : train loss 151.95012810060382, val loss 117.17105086326599\n",
      "epoch 8 : train loss 104.11077929017692, val loss 68.68417383861542\n",
      "epoch 9 : train loss 65.79671215644478, val loss 35.39907164764404\n",
      "epoch 10 : train loss 41.10773234213889, val loss 32.15395763015747\n",
      "epoch 11 : train loss 49.32956838272512, val loss 9.192999920248985\n",
      "epoch 12 : train loss 78.91196111318841, val loss 9.017008454322815\n",
      "epoch 13 : train loss 42.4892330664359, val loss 5219.862114257812\n",
      "epoch 14 : train loss 58.550026986509565, val loss 3.7824759488105775\n",
      "epoch 15 : train loss 53.564859849102795, val loss 7.467203241348266\n",
      "epoch 16 : train loss 131.2019764334336, val loss 1.5210727821588517\n",
      "epoch 17 : train loss 1.6832165365032852, val loss 2.8291756217479707\n",
      "epoch 18 : train loss 58.09891635192372, val loss 1.1272694313526153\n",
      "epoch 19 : train loss 52.48537198284315, val loss 1.8277171387672424\n",
      "epoch 20 : train loss 81.34865943582543, val loss 0.5489405726194382\n",
      "epoch 21 : train loss 57.48312087917887, val loss 1.2657114964351057\n",
      "epoch 22 : train loss 45.484026827460156, val loss 1.1708142764866352\n",
      "epoch 23 : train loss 21.71291865565255, val loss 0.6225498826503754\n",
      "epoch 24 : train loss 64.10105722666904, val loss 93.15420103454589\n",
      "epoch 25 : train loss 72.67950199660287, val loss 0.4592552667856216\n",
      "epoch 26 : train loss 8.310790362598375, val loss 4.943290144920349\n",
      "epoch 27 : train loss 40.3545253389217, val loss 0.33316186305880546\n",
      "epoch 28 : train loss 32.45596462867409, val loss 4.812591764450073\n",
      "epoch 29 : train loss 59.153663159400224, val loss 0.17146894037723542\n",
      "epoch 30 : train loss 36.318269324591846, val loss 743.4028294677735\n",
      "epoch 31 : train loss 31.796374639658257, val loss 1.6944543430805206\n",
      "epoch 32 : train loss 29.973297015834135, val loss 0.16000761479139328\n",
      "epoch 33 : train loss 64.31180319299037, val loss 0.8831137351244688\n",
      "epoch 34 : train loss 68.71577999923844, val loss 0.10726099607348442\n",
      "epoch 35 : train loss 51.58728248313069, val loss 0.10751969854533672\n",
      "epoch 36 : train loss 46.59079475470446, val loss 3697.58029296875\n",
      "epoch 37 : train loss 52.98429306027945, val loss 0.025070714788511396\n",
      "epoch 38 : train loss 50.33881867001438, val loss 0.0439813886359334\n",
      "epoch 39 : train loss 51.047779342495836, val loss 0.04284709168970585\n",
      "epoch 40 : train loss 51.27783332443191, val loss 0.8840201795101166\n",
      "epoch 41 : train loss 19.053711683984382, val loss 2.2776694626808167\n",
      "epoch 42 : train loss 34.37295422492875, val loss 0.02793471654318273\n",
      "epoch 43 : train loss 69.40818476037587, val loss 0.025597141947597265\n",
      "epoch 44 : train loss 114.52837834119588, val loss 0.0930195392370224\n",
      "epoch 45 : train loss 0.08075324441632256, val loss 0.1639284076988697\n",
      "epoch 46 : train loss 24.171628512531985, val loss 3.7548855476379392\n",
      "epoch 47 : train loss 58.984990550149696, val loss 0.02834643956273794\n",
      "epoch 48 : train loss 59.57709667193284, val loss 0.10240509957820178\n",
      "epoch 49 : train loss 38.923632547676796, val loss 0.03637226077541709\n",
      "epoch 50 : train loss 56.20398871660768, val loss 0.10081540518999099\n",
      "epoch 51 : train loss 86.96897371099145, val loss 2.6736659750938414\n",
      "epoch 52 : train loss 0.26870104478532447, val loss 0.22191042871586977\n",
      "epoch 53 : train loss 99.3075743607711, val loss 0.025851931042969227\n",
      "epoch 54 : train loss 132.5135739664766, val loss 0.5075498495101929\n",
      "epoch 55 : train loss 0.10995748856663703, val loss 0.05506482293456793\n",
      "epoch 56 : train loss 52.80643086949224, val loss 0.44516734886169435\n",
      "epoch 57 : train loss 25.587539230706636, val loss 193.37988790893556\n",
      "epoch 58 : train loss 66.04279029689822, val loss 0.018523043796420096\n",
      "epoch 59 : train loss 23.710067197233904, val loss 0.07581476570665836\n",
      "epoch 60 : train loss 24.17595142980432, val loss 1.3167662463188172\n",
      "epoch 61 : train loss 107.40790353233879, val loss 0.032323922593146565\n",
      "epoch 62 : train loss 26.28299302221788, val loss 0.012551960572600364\n",
      "epoch 63 : train loss 132.2496978480285, val loss 3.0032706393301485\n",
      "epoch 64 : train loss 0.6012310316720978, val loss 0.7740556905269623\n",
      "epoch 65 : train loss 46.32485920116724, val loss 1.9507218952178955\n",
      "epoch 66 : train loss 46.36028824164765, val loss 0.11427830819040537\n",
      "epoch 67 : train loss 35.740875176521016, val loss 0.07166695547103882\n",
      "epoch 68 : train loss 28.989951914019883, val loss 4.289068963050842\n",
      "epoch 69 : train loss 83.42592274150695, val loss 0.031033332955092193\n",
      "epoch 70 : train loss 30.70499132950697, val loss 0.015897276014089586\n",
      "epoch 71 : train loss 26.587882544004593, val loss 0.07495920842885971\n",
      "epoch 72 : train loss 92.8517145314347, val loss 0.022660069212317467\n",
      "epoch 73 : train loss 20.400177688704805, val loss 0.010112745806574822\n",
      "epoch 74 : train loss 96.16750565485668, val loss 0.04701593397557736\n",
      "epoch 75 : train loss 9.177541344456607, val loss 41.72589047241211\n",
      "epoch 76 : train loss 101.74843062337906, val loss 0.03062767693400383\n",
      "epoch 77 : train loss 0.6328708962076344, val loss 0.0520306161493063\n",
      "epoch 78 : train loss 41.72702885840251, val loss 0.07510089346393943\n",
      "epoch 79 : train loss 56.090200674002524, val loss 0.9253807461261749\n",
      "epoch 80 : train loss 47.2450104621239, val loss 0.01610648697055876\n",
      "epoch 81 : train loss 54.222206356711915, val loss 0.19327569378167392\n",
      "epoch 82 : train loss 26.684995091529096, val loss 0.09019492591917515\n",
      "epoch 83 : train loss 34.4577628731447, val loss 0.9399312877655029\n",
      "epoch 84 : train loss 83.16801908484194, val loss 0.013367603461258114\n",
      "epoch 85 : train loss 39.74891225286096, val loss 0.020571559119969607\n",
      "epoch 86 : train loss 38.49141642577585, val loss 0.03424629209376871\n",
      "epoch 87 : train loss 46.94335746608209, val loss 0.05101213543862104\n",
      "epoch 88 : train loss 34.30239201339707, val loss 5.629500511169433\n",
      "epoch 89 : train loss 40.48950587928062, val loss 305.24133477783204\n",
      "epoch 90 : train loss 35.048500702970195, val loss 0.033313973478972914\n",
      "epoch 91 : train loss 49.81344932345953, val loss 0.03939008510857821\n",
      "epoch 92 : train loss 32.23420150460396, val loss 2.397004436969757\n",
      "epoch 93 : train loss 40.16987530729826, val loss 0.11810720797628164\n",
      "epoch 94 : train loss 26.728842661384494, val loss 0.058064037365838886\n",
      "epoch 95 : train loss 56.21435572677012, val loss 0.053389562882483005\n",
      "epoch 96 : train loss 76.62544213117891, val loss 0.04568657980114221\n",
      "epoch 97 : train loss 12.753218823017901, val loss 51.378876739501955\n",
      "epoch 98 : train loss 63.75882148730662, val loss 0.0130681030806154\n",
      "epoch 99 : train loss 23.26097391579766, val loss 39.85364025878906\n",
      "epoch 100 : train loss 42.30866151824314, val loss 0.3599513951539993\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.3682\n",
      "R² Score: 1.0000\n",
      "LSTM-DNN\n",
      "epoch 1 : train loss 565624349.728, val loss 208766906.752\n",
      "epoch 2 : train loss 217390547.56, val loss 206899744.416\n",
      "epoch 3 : train loss 225202611.56, val loss 208567842.304\n",
      "epoch 4 : train loss 208751489.144, val loss 208256197.536\n",
      "epoch 5 : train loss 209721787.272, val loss 208503588.8\n",
      "epoch 6 : train loss 208741797.248, val loss 208263936.672\n",
      "epoch 7 : train loss 208774115.352, val loss 208523829.888\n",
      "epoch 8 : train loss 208812370.624, val loss 208497174.72\n",
      "epoch 9 : train loss 208742374.696, val loss 208278521.984\n",
      "epoch 10 : train loss 208761711.896, val loss 208340478.304\n",
      "epoch 11 : train loss 209201661.912, val loss 208154593.152\n",
      "epoch 12 : train loss 208569955.904, val loss 208260806.304\n",
      "epoch 13 : train loss 208833300.584, val loss 208291284.0\n",
      "epoch 14 : train loss 208762329.84, val loss 208260218.24\n",
      "epoch 15 : train loss 208804687.704, val loss 208287084.32\n",
      "epoch 16 : train loss 208790548.984, val loss 208833448.128\n",
      "epoch 17 : train loss 208758286.24, val loss 208401867.84\n",
      "epoch 18 : train loss 208809676.712, val loss 208285570.112\n",
      "epoch 19 : train loss 208792744.792, val loss 208300005.728\n",
      "epoch 20 : train loss 208785395.896, val loss 208262611.488\n",
      "epoch 21 : train loss 208782130.68, val loss 208405270.272\n",
      "epoch 22 : train loss 208739411.68, val loss 208358452.768\n",
      "epoch 23 : train loss 208713221.752, val loss 208291854.56\n",
      "epoch 24 : train loss 208759094.176, val loss 208264939.008\n",
      "epoch 25 : train loss 208817204.088, val loss 208385123.264\n",
      "epoch 26 : train loss 208766891.84, val loss 208299914.176\n",
      "epoch 27 : train loss 208813964.072, val loss 208451189.408\n",
      "epoch 28 : train loss 208710651.752, val loss 208280287.264\n",
      "epoch 29 : train loss 208771480.632, val loss 208715664.128\n",
      "epoch 30 : train loss 208760522.472, val loss 208526069.76\n",
      "epoch 31 : train loss 208745311.064, val loss 208257933.888\n",
      "epoch 32 : train loss 208771769.664, val loss 208730432.32\n",
      "epoch 33 : train loss 208630375.424, val loss 205971348.32\n",
      "epoch 34 : train loss 208184382.656, val loss 208223902.368\n",
      "epoch 35 : train loss 208708724.792, val loss 208283216.608\n",
      "epoch 36 : train loss 208830336.576, val loss 208256125.696\n",
      "epoch 37 : train loss 208795013.36, val loss 208540691.648\n",
      "epoch 38 : train loss 333259888.72, val loss 260623995.936\n",
      "epoch 39 : train loss 212143953.424, val loss 208100298.784\n",
      "epoch 40 : train loss 208619459.888, val loss 208507124.416\n",
      "epoch 41 : train loss 208742208.376, val loss 208289386.432\n",
      "epoch 42 : train loss 208759913.352, val loss 208286629.696\n",
      "epoch 43 : train loss 208752493.232, val loss 208526834.496\n",
      "epoch 44 : train loss 208756165.792, val loss 208260961.088\n",
      "epoch 45 : train loss 208792639.4, val loss 207804676.096\n",
      "epoch 46 : train loss 208177244.872, val loss 208335438.848\n",
      "epoch 47 : train loss 208751293.304, val loss 208087576.576\n",
      "epoch 48 : train loss 207478039.776, val loss 207905911.296\n",
      "epoch 49 : train loss 209576459.48, val loss 208313267.904\n",
      "epoch 50 : train loss 208743482.856, val loss 208292609.728\n",
      "epoch 51 : train loss 208812344.608, val loss 208259416.864\n",
      "epoch 52 : train loss 208753533.52, val loss 208544874.304\n",
      "epoch 53 : train loss 208765785.96, val loss 208427943.808\n",
      "epoch 54 : train loss 208771608.256, val loss 208552192.384\n",
      "epoch 55 : train loss 208375817.888, val loss 208598139.264\n",
      "epoch 56 : train loss 208793282.856, val loss 208207926.208\n",
      "epoch 57 : train loss 208290807.416, val loss 208844218.56\n",
      "epoch 58 : train loss 223283273.16, val loss 207846550.656\n",
      "epoch 59 : train loss 208100706.368, val loss 206587803.584\n",
      "epoch 60 : train loss 208433794.384, val loss 207569041.28\n",
      "epoch 61 : train loss 208707900.712, val loss 208224496.768\n",
      "epoch 62 : train loss 208520021.592, val loss 208361852.704\n",
      "epoch 63 : train loss 208716428.84, val loss 208524404.416\n",
      "epoch 64 : train loss 208768765.0, val loss 208599168.832\n",
      "epoch 65 : train loss 208804913.856, val loss 208459860.352\n",
      "epoch 66 : train loss 208720398.592, val loss 208474376.512\n",
      "epoch 67 : train loss 208742519.392, val loss 208292301.888\n",
      "epoch 68 : train loss 208713849.672, val loss 208263169.696\n",
      "epoch 69 : train loss 208774773.624, val loss 208335896.064\n",
      "epoch 70 : train loss 208741472.64, val loss 208283176.224\n",
      "epoch 71 : train loss 208729869.776, val loss 208383665.728\n",
      "epoch 72 : train loss 208737469.152, val loss 208322797.056\n",
      "epoch 73 : train loss 208767395.192, val loss 208315059.968\n",
      "epoch 74 : train loss 208717041.744, val loss 208135865.216\n",
      "epoch 75 : train loss 208149142.912, val loss 209369557.792\n",
      "epoch 76 : train loss 204633150.4, val loss 165251116.48\n",
      "epoch 77 : train loss 210229633.464, val loss 208602483.136\n",
      "epoch 78 : train loss 208751508.728, val loss 208257517.504\n",
      "epoch 79 : train loss 208776372.104, val loss 208447474.56\n",
      "epoch 80 : train loss 208764948.784, val loss 208475369.088\n",
      "epoch 81 : train loss 208781623.16, val loss 208259543.552\n",
      "epoch 82 : train loss 208754727.832, val loss 208466802.24\n",
      "epoch 83 : train loss 208746511.168, val loss 208275298.752\n",
      "epoch 84 : train loss 208767522.768, val loss 208289751.776\n",
      "epoch 85 : train loss 208769450.504, val loss 208351030.016\n",
      "epoch 86 : train loss 208741528.28, val loss 208258251.712\n",
      "epoch 87 : train loss 208710434.6, val loss 208257613.856\n",
      "epoch 88 : train loss 208750995.704, val loss 208434697.216\n",
      "epoch 89 : train loss 208753435.304, val loss 208266479.072\n",
      "epoch 90 : train loss 208759644.808, val loss 208290394.464\n",
      "epoch 91 : train loss 208764701.528, val loss 208372544.448\n",
      "epoch 92 : train loss 208743808.176, val loss 208266280.832\n",
      "epoch 93 : train loss 208770480.424, val loss 208357129.184\n",
      "epoch 94 : train loss 208745690.104, val loss 208585156.224\n",
      "epoch 95 : train loss 208764381.384, val loss 208265977.536\n",
      "epoch 96 : train loss 208741845.808, val loss 208342364.032\n",
      "epoch 97 : train loss 208778885.776, val loss 208375000.928\n",
      "epoch 98 : train loss 208737564.664, val loss 208258032.992\n",
      "epoch 99 : train loss 208777444.08, val loss 208473682.496\n",
      "epoch 100 : train loss 208744190.648, val loss 208277451.488\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 206811353.8356\n",
      "R² Score: -0.0003\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 (hyperparameter 정의 -> 학습 -> 테스트 및 성능 지표 확인)\n",
    "\n",
    "for i, model in enumerate([model_CNN_DNN, model_LSTM_DNN]) : \n",
    "    if i == 0 : \n",
    "        print (\"CNN-DNN\")\n",
    "        \n",
    "    else : \n",
    "        print (\"LSTM-DNN\")\n",
    "        \n",
    "    optimizer = optim.AdamW(model.parameters(),\n",
    "                           lr=0.001)\n",
    "    epoch = 100\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    model.train()\n",
    "    for ep in range (epoch) :\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        for X_batch, y_batch in train_DL : \n",
    "            X_batch = X_batch.float()\n",
    "            y_batch = y_batch.float().unsqueeze(1)\n",
    "            \n",
    "            # inference\n",
    "            y_hat = model.forward(X_batch)\n",
    "            \n",
    "            # loss\n",
    "            loss = criterion(y_hat, y_batch)\n",
    "            \n",
    "            # deriviate\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # update\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # validation\n",
    "        model.eval()\n",
    "        with torch.no_grad() : \n",
    "            for X_batch, y_batch in val_DL : \n",
    "                X_batch = X_batch.float() \n",
    "                y_batch = y_batch.float().unsqueeze(1)\n",
    "                \n",
    "                # inference\n",
    "                y_hat = model.forward(X_batch)\n",
    "                \n",
    "                # loss\n",
    "                loss = criterion (y_hat, y_batch)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        train_losses.append(train_loss / len(train_DL))\n",
    "        val_losses.append (val_loss/len(val_DL))\n",
    "        print (f\"epoch {ep+1} : train loss {train_losses[-1]}, val loss {val_losses[-1]}\")\n",
    "        \n",
    "    # figure about loss per epoch\n",
    "    plt.plot([ep for ep in range (1, epoch+1)], train_losses, label=\"train loss\")\n",
    "    plt.plot([ep for ep in range (1, epoch+1)], val_losses, label=\"val loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # MSE checking, R^2 checking\n",
    "    \n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    test_MSE = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_DL:\n",
    "            X_batch = X_batch.float()\n",
    "            y_batch = y_batch.float().unsqueeze(1)\n",
    "            y_hat = model(X_batch)\n",
    "            mse = F.mse_loss(y_hat, y_batch, reduction='sum')\n",
    "            test_MSE += mse.item()\n",
    "            y_true.append(y_batch)\n",
    "            y_pred.append(y_hat)\n",
    "\n",
    "    y_true = torch.cat(y_true)\n",
    "    y_pred = torch.cat(y_pred)\n",
    "\n",
    "    test_MSE /= len(y_true)\n",
    "\n",
    "    ss_total = torch.sum((y_true - torch.mean(y_true)) ** 2)\n",
    "    ss_res = torch.sum((y_true - y_pred) ** 2)\n",
    "    r2_score = 1 - (ss_res / ss_total)\n",
    "\n",
    "    print(f\"Test MSE: {test_MSE:.4f}\")\n",
    "    print(f\"R² Score: {r2_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d550b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
