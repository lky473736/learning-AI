{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "107b53a8",
   "metadata": {},
   "source": [
    "## learning-AI : PAMAP classification (DL)\n",
    "### PAMAP (Physical Activity Monitoring) 데이터를 U-net을 통한 Encoder-Decoder 방식의 classification\n",
    "\n",
    "<br>\n",
    "\n",
    "- **임규연 (lky473736)**\n",
    "- 2024.09.03. ~ 2024.09.08.에 문서 작성\n",
    "- **dataset** : https://archive.ics.uci.edu/dataset/231/pamap2+physical+activity+monitoring\n",
    "- **data abstract** : The PAMAP2 Physical Activity Monitoring dataset contains data of 18 different physical activities (such as walking, cycling, playing soccer, etc.), performed by 9 subjects wearing 3 inertial measurement units and a heart rate monitor. The dataset can be used for activity recognition and intensity estimation, while developing and applying algorithms of data processing, segmentation, feature extraction and classification.\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "\n",
    "## <span id='dl'><mark>DL</mark></span>\n",
    "\n",
    "deep learning으로 PAMAP을 classification한다. **kmat2019가 작성한 'U-net(1D-CNN) with Keras'를 참고하여 classification한다.**\n",
    "\n",
    "- **Reference**\n",
    "    - https://www.kaggle.com/code/kmat2019/u-net-1d-cnn-with-keras\n",
    "    - https://github.com/lky473736/learning-AI/blob/main/report/HARTH/U-net_classification_HARTH.ipynb\n",
    "    - https://github.com/lky473736/learning-AI/blob/main/insight/insight_4_U_net_on_ion_switching.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baae97e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.201511Z",
     "start_time": "2024-09-08T14:25:06.196838Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, Reshape, Conv1D, BatchNormalization, Activation, AveragePooling1D, GlobalAveragePooling1D, Lambda, Input, Concatenate, Add, UpSampling1D, Multiply\n",
    "from keras.models import Model\n",
    "# objectives 작동 X -> losses로 변경\n",
    "from keras.losses import mean_squared_error\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau,LearningRateScheduler\n",
    "from keras.initializers import random_normal\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dffdf69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.420963Z",
     "start_time": "2024-09-08T14:25:06.204086Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>act_level</th>\n",
       "      <th>hr_mean</th>\n",
       "      <th>hr_mean_normal</th>\n",
       "      <th>hr_std</th>\n",
       "      <th>hr_std_normal</th>\n",
       "      <th>hand_tmp_mean</th>\n",
       "      <th>hand_tmp_std</th>\n",
       "      <th>...</th>\n",
       "      <th>ankle_acc_xz_cor</th>\n",
       "      <th>hand_gyr_xy_cor</th>\n",
       "      <th>hand_gyr_yz_cor</th>\n",
       "      <th>hand_gyr_xz_cor</th>\n",
       "      <th>chest_gyr_xy_cor</th>\n",
       "      <th>chest_gyr_yz_cor</th>\n",
       "      <th>chest_gyr_xz_cor</th>\n",
       "      <th>ankle_gyr_xy_cor</th>\n",
       "      <th>ankle_gyr_yz_cor</th>\n",
       "      <th>ankle_gyr_xz_cor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3006</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>light</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1.175676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.105427e-15</td>\n",
       "      <td>34.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233251</td>\n",
       "      <td>-0.472662</td>\n",
       "      <td>0.335516</td>\n",
       "      <td>-0.377507</td>\n",
       "      <td>-0.290138</td>\n",
       "      <td>-0.779952</td>\n",
       "      <td>0.071855</td>\n",
       "      <td>-0.305959</td>\n",
       "      <td>-0.003001</td>\n",
       "      <td>-0.638866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3497</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>moderate</td>\n",
       "      <td>124.605469</td>\n",
       "      <td>1.683858</td>\n",
       "      <td>0.927920</td>\n",
       "      <td>1.253946e-02</td>\n",
       "      <td>31.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119772</td>\n",
       "      <td>-0.287380</td>\n",
       "      <td>-0.230390</td>\n",
       "      <td>-0.491314</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>-0.799319</td>\n",
       "      <td>-0.135736</td>\n",
       "      <td>-0.653133</td>\n",
       "      <td>-0.654575</td>\n",
       "      <td>0.391363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14495</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>vigorous</td>\n",
       "      <td>113.493430</td>\n",
       "      <td>1.891557</td>\n",
       "      <td>2.315888</td>\n",
       "      <td>3.859813e-02</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025673</td>\n",
       "      <td>-0.265566</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>-0.121345</td>\n",
       "      <td>-0.004923</td>\n",
       "      <td>-0.317761</td>\n",
       "      <td>-0.202148</td>\n",
       "      <td>-0.660278</td>\n",
       "      <td>-0.528138</td>\n",
       "      <td>0.402147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13278</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>light</td>\n",
       "      <td>82.513672</td>\n",
       "      <td>1.375228</td>\n",
       "      <td>0.492657</td>\n",
       "      <td>8.210948e-03</td>\n",
       "      <td>33.812500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724061</td>\n",
       "      <td>-0.196728</td>\n",
       "      <td>0.315984</td>\n",
       "      <td>-0.380337</td>\n",
       "      <td>0.284190</td>\n",
       "      <td>-0.109078</td>\n",
       "      <td>-0.071734</td>\n",
       "      <td>-0.177813</td>\n",
       "      <td>0.237828</td>\n",
       "      <td>-0.729771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14969</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>light</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.106061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.327472e-15</td>\n",
       "      <td>34.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001651</td>\n",
       "      <td>-0.060776</td>\n",
       "      <td>0.165672</td>\n",
       "      <td>0.311760</td>\n",
       "      <td>-0.272620</td>\n",
       "      <td>-0.014943</td>\n",
       "      <td>-0.191610</td>\n",
       "      <td>-0.261158</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>0.057685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11768</th>\n",
       "      <td>10708</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>light</td>\n",
       "      <td>82.582031</td>\n",
       "      <td>1.376367</td>\n",
       "      <td>0.930285</td>\n",
       "      <td>1.550475e-02</td>\n",
       "      <td>33.525635</td>\n",
       "      <td>0.030741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193950</td>\n",
       "      <td>-0.354026</td>\n",
       "      <td>0.175876</td>\n",
       "      <td>-0.172933</td>\n",
       "      <td>0.184131</td>\n",
       "      <td>-0.274344</td>\n",
       "      <td>-0.485489</td>\n",
       "      <td>-0.100010</td>\n",
       "      <td>-0.000800</td>\n",
       "      <td>0.031654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11769</th>\n",
       "      <td>4870</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>light</td>\n",
       "      <td>76.998047</td>\n",
       "      <td>1.132324</td>\n",
       "      <td>0.806906</td>\n",
       "      <td>1.186626e-02</td>\n",
       "      <td>32.083130</td>\n",
       "      <td>0.029390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135629</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>-0.203294</td>\n",
       "      <td>-0.097797</td>\n",
       "      <td>-0.273316</td>\n",
       "      <td>-0.009717</td>\n",
       "      <td>-0.076216</td>\n",
       "      <td>0.009411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11770</th>\n",
       "      <td>11822</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>moderate</td>\n",
       "      <td>93.445312</td>\n",
       "      <td>1.557422</td>\n",
       "      <td>0.493415</td>\n",
       "      <td>8.223580e-03</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404942</td>\n",
       "      <td>0.520845</td>\n",
       "      <td>-0.951838</td>\n",
       "      <td>-0.561901</td>\n",
       "      <td>-0.169119</td>\n",
       "      <td>0.299434</td>\n",
       "      <td>-0.100683</td>\n",
       "      <td>-0.555866</td>\n",
       "      <td>-0.442849</td>\n",
       "      <td>0.063207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11771</th>\n",
       "      <td>3866</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>moderate</td>\n",
       "      <td>129.160156</td>\n",
       "      <td>1.745408</td>\n",
       "      <td>0.361877</td>\n",
       "      <td>4.890232e-03</td>\n",
       "      <td>30.465576</td>\n",
       "      <td>0.031088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136336</td>\n",
       "      <td>-0.147614</td>\n",
       "      <td>-0.344375</td>\n",
       "      <td>-0.329746</td>\n",
       "      <td>-0.024487</td>\n",
       "      <td>-0.536806</td>\n",
       "      <td>-0.161019</td>\n",
       "      <td>-0.752563</td>\n",
       "      <td>-0.627185</td>\n",
       "      <td>0.436639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11772</th>\n",
       "      <td>3450</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>moderate</td>\n",
       "      <td>142.234375</td>\n",
       "      <td>1.922086</td>\n",
       "      <td>1.714464</td>\n",
       "      <td>2.316843e-02</td>\n",
       "      <td>32.173340</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200755</td>\n",
       "      <td>-0.081262</td>\n",
       "      <td>0.130816</td>\n",
       "      <td>-0.278256</td>\n",
       "      <td>-0.254757</td>\n",
       "      <td>-0.723943</td>\n",
       "      <td>-0.039044</td>\n",
       "      <td>-0.016410</td>\n",
       "      <td>-0.662742</td>\n",
       "      <td>-0.085954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11773 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  sub_id  activity_id act_level     hr_mean  hr_mean_normal  \\\n",
       "0            3006       2           17     light   87.000000        1.175676   \n",
       "1            3497       2            4  moderate  124.605469        1.683858   \n",
       "2           14495       7            5  vigorous  113.493430        1.891557   \n",
       "3           13278       7           17     light   82.513672        1.375228   \n",
       "4           14969       8            3     light   73.000000        1.106061   \n",
       "...           ...     ...          ...       ...         ...             ...   \n",
       "11768       10708       6            2     light   82.582031        1.376367   \n",
       "11769        4870       3            2     light   76.998047        1.132324   \n",
       "11770       11822       6            4  moderate   93.445312        1.557422   \n",
       "11771        3866       2            7  moderate  129.160156        1.745408   \n",
       "11772        3450       2           13  moderate  142.234375        1.922086   \n",
       "\n",
       "         hr_std  hr_std_normal  hand_tmp_mean  hand_tmp_std  ...  \\\n",
       "0      0.000000   7.105427e-15      34.375000      0.000000  ...   \n",
       "1      0.927920   1.253946e-02      31.875000      0.000000  ...   \n",
       "2      2.315888   3.859813e-02      32.500000      0.000000  ...   \n",
       "3      0.492657   8.210948e-03      33.812500      0.000000  ...   \n",
       "4      0.000000   7.327472e-15      34.437500      0.000000  ...   \n",
       "...         ...            ...            ...           ...  ...   \n",
       "11768  0.930285   1.550475e-02      33.525635      0.030741  ...   \n",
       "11769  0.806906   1.186626e-02      32.083130      0.029390  ...   \n",
       "11770  0.493415   8.223580e-03      31.750000      0.000000  ...   \n",
       "11771  0.361877   4.890232e-03      30.465576      0.031088  ...   \n",
       "11772  1.714464   2.316843e-02      32.173340      0.026163  ...   \n",
       "\n",
       "       ankle_acc_xz_cor  hand_gyr_xy_cor  hand_gyr_yz_cor  hand_gyr_xz_cor  \\\n",
       "0              0.233251        -0.472662         0.335516        -0.377507   \n",
       "1             -0.119772        -0.287380        -0.230390        -0.491314   \n",
       "2              0.025673        -0.265566         0.824691        -0.121345   \n",
       "3              0.724061        -0.196728         0.315984        -0.380337   \n",
       "4             -0.001651        -0.060776         0.165672         0.311760   \n",
       "...                 ...              ...              ...              ...   \n",
       "11768          0.193950        -0.354026         0.175876        -0.172933   \n",
       "11769          0.135629         0.056979         0.008235         0.001093   \n",
       "11770         -0.404942         0.520845        -0.951838        -0.561901   \n",
       "11771         -0.136336        -0.147614        -0.344375        -0.329746   \n",
       "11772          0.200755        -0.081262         0.130816        -0.278256   \n",
       "\n",
       "       chest_gyr_xy_cor  chest_gyr_yz_cor  chest_gyr_xz_cor  ankle_gyr_xy_cor  \\\n",
       "0             -0.290138         -0.779952          0.071855         -0.305959   \n",
       "1              0.011124         -0.799319         -0.135736         -0.653133   \n",
       "2             -0.004923         -0.317761         -0.202148         -0.660278   \n",
       "3              0.284190         -0.109078         -0.071734         -0.177813   \n",
       "4             -0.272620         -0.014943         -0.191610         -0.261158   \n",
       "...                 ...               ...               ...               ...   \n",
       "11768          0.184131         -0.274344         -0.485489         -0.100010   \n",
       "11769         -0.203294         -0.097797         -0.273316         -0.009717   \n",
       "11770         -0.169119          0.299434         -0.100683         -0.555866   \n",
       "11771         -0.024487         -0.536806         -0.161019         -0.752563   \n",
       "11772         -0.254757         -0.723943         -0.039044         -0.016410   \n",
       "\n",
       "       ankle_gyr_yz_cor  ankle_gyr_xz_cor  \n",
       "0             -0.003001         -0.638866  \n",
       "1             -0.654575          0.391363  \n",
       "2             -0.528138          0.402147  \n",
       "3              0.237828         -0.729771  \n",
       "4              0.066954          0.057685  \n",
       "...                 ...               ...  \n",
       "11768         -0.000800          0.031654  \n",
       "11769         -0.076216          0.009411  \n",
       "11770         -0.442849          0.063207  \n",
       "11771         -0.627185          0.436639  \n",
       "11772         -0.662742         -0.085954  \n",
       "\n",
       "[11773 rows x 68 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data load\n",
    "\n",
    "df = pd.read_csv(\"../../data/PAMAP/PAMAP_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10ec2f14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.434522Z",
     "start_time": "2024-09-08T14:25:06.422821Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'transient', 1: 'lying', 2: 'sitting', 3: 'standing', 4: 'walking', 5: 'running', 6: 'cycling', 7: 'Nordic walking', 9: 'watching TV', 10: 'computer work', 11: 'car driving', 12: 'ascending stairs', 13: 'descending stairs', 16: 'vacuum cleaning', 17: 'ironing', 18: 'folding laundry', 19: 'house cleaning', 20: 'playing soccer', 24: 'rope jumping'}\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11773 entries, 0 to 11772\n",
      "Data columns (total 68 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        11773 non-null  int64  \n",
      " 1   sub_id            11773 non-null  int64  \n",
      " 2   activity_id       11773 non-null  int64  \n",
      " 3   act_level         11773 non-null  object \n",
      " 4   hr_mean           11773 non-null  float64\n",
      " 5   hr_mean_normal    11773 non-null  float64\n",
      " 6   hr_std            11773 non-null  float64\n",
      " 7   hr_std_normal     11773 non-null  float64\n",
      " 8   hand_tmp_mean     11773 non-null  float64\n",
      " 9   hand_tmp_std      11773 non-null  float64\n",
      " 10  hand_acc_x_mean   11773 non-null  float64\n",
      " 11  hand_acc_x_std    11773 non-null  float64\n",
      " 12  hand_acc_y_mean   11773 non-null  float64\n",
      " 13  hand_acc_y_std    11773 non-null  float64\n",
      " 14  hand_acc_z_mean   11773 non-null  float64\n",
      " 15  hand_acc_z_std    11773 non-null  float64\n",
      " 16  hand_gyr_x_mean   11773 non-null  float64\n",
      " 17  hand_gyr_x_std    11773 non-null  float64\n",
      " 18  hand_gyr_y_mean   11773 non-null  float64\n",
      " 19  hand_gyr_y_std    11773 non-null  float64\n",
      " 20  hand_gyr_z_mean   11773 non-null  float64\n",
      " 21  hand_gyr_z_std    11773 non-null  float64\n",
      " 22  chest_tmp_mean    11773 non-null  float64\n",
      " 23  chest_tmp_std     11773 non-null  float64\n",
      " 24  chest_acc_x_mean  11773 non-null  float64\n",
      " 25  chest_acc_x_std   11773 non-null  float64\n",
      " 26  chest_acc_y_mean  11773 non-null  float64\n",
      " 27  chest_acc_y_std   11773 non-null  float64\n",
      " 28  chest_acc_z_mean  11773 non-null  float64\n",
      " 29  chest_acc_z_std   11773 non-null  float64\n",
      " 30  chest_gyr_x_mean  11773 non-null  float64\n",
      " 31  chest_gyr_x_std   11773 non-null  float64\n",
      " 32  chest_gyr_y_mean  11773 non-null  float64\n",
      " 33  chest_gyr_y_std   11773 non-null  float64\n",
      " 34  chest_gyr_z_mean  11773 non-null  float64\n",
      " 35  chest_gyr_z_std   11773 non-null  float64\n",
      " 36  ankle_tmp_mean    11773 non-null  float64\n",
      " 37  ankle_tmp_std     11773 non-null  float64\n",
      " 38  ankle_acc_x_mean  11773 non-null  float64\n",
      " 39  ankle_acc_x_std   11773 non-null  float64\n",
      " 40  ankle_acc_y_mean  11773 non-null  float64\n",
      " 41  ankle_acc_y_std   11773 non-null  float64\n",
      " 42  ankle_acc_z_mean  11773 non-null  float64\n",
      " 43  ankle_acc_z_std   11773 non-null  float64\n",
      " 44  ankle_gyr_x_mean  11773 non-null  float64\n",
      " 45  ankle_gyr_x_std   11773 non-null  float64\n",
      " 46  ankle_gyr_y_mean  11773 non-null  float64\n",
      " 47  ankle_gyr_y_std   11773 non-null  float64\n",
      " 48  ankle_gyr_z_mean  11773 non-null  float64\n",
      " 49  ankle_gyr_z_std   11773 non-null  float64\n",
      " 50  hand_acc_xy_cor   11773 non-null  float64\n",
      " 51  hand_acc_yz_cor   11773 non-null  float64\n",
      " 52  hand_acc_xz_cor   11773 non-null  float64\n",
      " 53  chest_acc_xy_cor  11773 non-null  float64\n",
      " 54  chest_acc_yz_cor  11773 non-null  float64\n",
      " 55  chest_acc_xz_cor  11773 non-null  float64\n",
      " 56  ankle_acc_xy_cor  11773 non-null  float64\n",
      " 57  ankle_acc_yz_cor  11773 non-null  float64\n",
      " 58  ankle_acc_xz_cor  11773 non-null  float64\n",
      " 59  hand_gyr_xy_cor   11773 non-null  float64\n",
      " 60  hand_gyr_yz_cor   11773 non-null  float64\n",
      " 61  hand_gyr_xz_cor   11773 non-null  float64\n",
      " 62  chest_gyr_xy_cor  11773 non-null  float64\n",
      " 63  chest_gyr_yz_cor  11773 non-null  float64\n",
      " 64  chest_gyr_xz_cor  11773 non-null  float64\n",
      " 65  ankle_gyr_xy_cor  11773 non-null  float64\n",
      " 66  ankle_gyr_yz_cor  11773 non-null  float64\n",
      " 67  ankle_gyr_xz_cor  11773 non-null  float64\n",
      "dtypes: float64(64), int64(3), object(1)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# 각 feature의 이름 \n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/00231/readme.pdf\n",
    "\n",
    "features_name = {0: 'transient', 1:'lying', 2:'sitting', 3:'standing',\n",
    "              4:'walking', 5:'running', 6:'cycling', 7:'Nordic walking',\n",
    "              9:'watching TV', 10:'computer work', 11:'car driving',\n",
    "              12:'ascending stairs', 13:'descending stairs', 16:'vacuum cleaning',\n",
    "              17:'ironing', 18:'folding laundry', 19:'house cleaning',\n",
    "              20:'playing soccer', 24:'rope jumping'}\n",
    "\n",
    "print (features_name)\n",
    "print ()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cd30ca8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.440766Z",
     "start_time": "2024-09-08T14:25:06.437305Z"
    }
   },
   "outputs": [],
   "source": [
    "# 필요없는 열 제거\n",
    "\n",
    "df = df.drop(['Unnamed: 0',\n",
    "              'sub_id',\n",
    "              'act_level',\n",
    "              'hr_mean',\n",
    "              'hr_mean_normal',\n",
    "              'hr_std',\n",
    "              'hr_std_normal'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccc86e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.446830Z",
     "start_time": "2024-09-08T14:25:06.442639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  4  5  3  6  2  7 16 12  1 13 24]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    label이 0-based가 아니기 때문에 0-based로 바꾸어야 할 듯 하다.\\n    (labelencoding)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target에 포함된 요소들 확인하기\n",
    "\n",
    "print (df['activity_id'].unique())\n",
    "\n",
    "\n",
    "'''\n",
    "    label이 0-based가 아니기 때문에 0-based로 바꾸어야 할 듯 하다.\n",
    "    (labelencoding)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cc11405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.476373Z",
     "start_time": "2024-09-08T14:25:06.448811Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>hand_tmp_mean</th>\n",
       "      <th>hand_tmp_std</th>\n",
       "      <th>hand_acc_x_mean</th>\n",
       "      <th>hand_acc_x_std</th>\n",
       "      <th>hand_acc_y_mean</th>\n",
       "      <th>hand_acc_y_std</th>\n",
       "      <th>hand_acc_z_mean</th>\n",
       "      <th>hand_acc_z_std</th>\n",
       "      <th>hand_gyr_x_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>ankle_acc_xz_cor</th>\n",
       "      <th>hand_gyr_xy_cor</th>\n",
       "      <th>hand_gyr_yz_cor</th>\n",
       "      <th>hand_gyr_xz_cor</th>\n",
       "      <th>chest_gyr_xy_cor</th>\n",
       "      <th>chest_gyr_yz_cor</th>\n",
       "      <th>chest_gyr_xz_cor</th>\n",
       "      <th>ankle_gyr_xy_cor</th>\n",
       "      <th>ankle_gyr_yz_cor</th>\n",
       "      <th>ankle_gyr_xz_cor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>34.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.165524</td>\n",
       "      <td>2.383779</td>\n",
       "      <td>3.381285</td>\n",
       "      <td>2.582771</td>\n",
       "      <td>8.492507</td>\n",
       "      <td>1.224852</td>\n",
       "      <td>0.093030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233251</td>\n",
       "      <td>-0.472662</td>\n",
       "      <td>0.335516</td>\n",
       "      <td>-0.377507</td>\n",
       "      <td>-0.290138</td>\n",
       "      <td>-0.779952</td>\n",
       "      <td>0.071855</td>\n",
       "      <td>-0.305959</td>\n",
       "      <td>-0.003001</td>\n",
       "      <td>-0.638866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>31.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.040995</td>\n",
       "      <td>3.734766</td>\n",
       "      <td>3.069947</td>\n",
       "      <td>2.591651</td>\n",
       "      <td>1.161251</td>\n",
       "      <td>1.837110</td>\n",
       "      <td>0.055998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119772</td>\n",
       "      <td>-0.287380</td>\n",
       "      <td>-0.230390</td>\n",
       "      <td>-0.491314</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>-0.799319</td>\n",
       "      <td>-0.135736</td>\n",
       "      <td>-0.653133</td>\n",
       "      <td>-0.654575</td>\n",
       "      <td>0.391363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.723040</td>\n",
       "      <td>10.188184</td>\n",
       "      <td>11.705779</td>\n",
       "      <td>17.220389</td>\n",
       "      <td>-1.367870</td>\n",
       "      <td>4.527840</td>\n",
       "      <td>0.186308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025673</td>\n",
       "      <td>-0.265566</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>-0.121345</td>\n",
       "      <td>-0.004923</td>\n",
       "      <td>-0.317761</td>\n",
       "      <td>-0.202148</td>\n",
       "      <td>-0.660278</td>\n",
       "      <td>-0.528138</td>\n",
       "      <td>0.402147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>33.812500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.618932</td>\n",
       "      <td>1.935690</td>\n",
       "      <td>0.542981</td>\n",
       "      <td>2.907890</td>\n",
       "      <td>8.430229</td>\n",
       "      <td>0.975924</td>\n",
       "      <td>-0.163251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724061</td>\n",
       "      <td>-0.196728</td>\n",
       "      <td>0.315984</td>\n",
       "      <td>-0.380337</td>\n",
       "      <td>0.284190</td>\n",
       "      <td>-0.109078</td>\n",
       "      <td>-0.071734</td>\n",
       "      <td>-0.177813</td>\n",
       "      <td>0.237828</td>\n",
       "      <td>-0.729771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>34.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.275877</td>\n",
       "      <td>0.082824</td>\n",
       "      <td>1.006239</td>\n",
       "      <td>0.153816</td>\n",
       "      <td>2.709588</td>\n",
       "      <td>0.155286</td>\n",
       "      <td>-0.008753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001651</td>\n",
       "      <td>-0.060776</td>\n",
       "      <td>0.165672</td>\n",
       "      <td>0.311760</td>\n",
       "      <td>-0.272620</td>\n",
       "      <td>-0.014943</td>\n",
       "      <td>-0.191610</td>\n",
       "      <td>-0.261158</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>0.057685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11768</th>\n",
       "      <td>1</td>\n",
       "      <td>33.525635</td>\n",
       "      <td>0.030741</td>\n",
       "      <td>-4.306831</td>\n",
       "      <td>0.087374</td>\n",
       "      <td>1.634235</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>8.393767</td>\n",
       "      <td>0.110314</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193950</td>\n",
       "      <td>-0.354026</td>\n",
       "      <td>0.175876</td>\n",
       "      <td>-0.172933</td>\n",
       "      <td>0.184131</td>\n",
       "      <td>-0.274344</td>\n",
       "      <td>-0.485489</td>\n",
       "      <td>-0.100010</td>\n",
       "      <td>-0.000800</td>\n",
       "      <td>0.031654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11769</th>\n",
       "      <td>1</td>\n",
       "      <td>32.083130</td>\n",
       "      <td>0.029390</td>\n",
       "      <td>-1.545991</td>\n",
       "      <td>0.086820</td>\n",
       "      <td>3.379703</td>\n",
       "      <td>0.093813</td>\n",
       "      <td>8.981813</td>\n",
       "      <td>0.103787</td>\n",
       "      <td>-0.011143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135629</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>-0.203294</td>\n",
       "      <td>-0.097797</td>\n",
       "      <td>-0.273316</td>\n",
       "      <td>-0.009717</td>\n",
       "      <td>-0.076216</td>\n",
       "      <td>0.009411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11770</th>\n",
       "      <td>3</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.034760</td>\n",
       "      <td>1.780491</td>\n",
       "      <td>3.100475</td>\n",
       "      <td>1.319988</td>\n",
       "      <td>1.092313</td>\n",
       "      <td>0.994165</td>\n",
       "      <td>0.060559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404942</td>\n",
       "      <td>0.520845</td>\n",
       "      <td>-0.951838</td>\n",
       "      <td>-0.561901</td>\n",
       "      <td>-0.169119</td>\n",
       "      <td>0.299434</td>\n",
       "      <td>-0.100683</td>\n",
       "      <td>-0.555866</td>\n",
       "      <td>-0.442849</td>\n",
       "      <td>0.063207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11771</th>\n",
       "      <td>6</td>\n",
       "      <td>30.465576</td>\n",
       "      <td>0.031088</td>\n",
       "      <td>-8.275569</td>\n",
       "      <td>3.245008</td>\n",
       "      <td>6.196727</td>\n",
       "      <td>4.417230</td>\n",
       "      <td>2.372815</td>\n",
       "      <td>1.843274</td>\n",
       "      <td>0.081074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136336</td>\n",
       "      <td>-0.147614</td>\n",
       "      <td>-0.344375</td>\n",
       "      <td>-0.329746</td>\n",
       "      <td>-0.024487</td>\n",
       "      <td>-0.536806</td>\n",
       "      <td>-0.161019</td>\n",
       "      <td>-0.752563</td>\n",
       "      <td>-0.627185</td>\n",
       "      <td>0.436639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11772</th>\n",
       "      <td>8</td>\n",
       "      <td>32.173340</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>-3.077000</td>\n",
       "      <td>3.850697</td>\n",
       "      <td>3.495658</td>\n",
       "      <td>3.910041</td>\n",
       "      <td>8.028176</td>\n",
       "      <td>4.359921</td>\n",
       "      <td>0.129189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200755</td>\n",
       "      <td>-0.081262</td>\n",
       "      <td>0.130816</td>\n",
       "      <td>-0.278256</td>\n",
       "      <td>-0.254757</td>\n",
       "      <td>-0.723943</td>\n",
       "      <td>-0.039044</td>\n",
       "      <td>-0.016410</td>\n",
       "      <td>-0.662742</td>\n",
       "      <td>-0.085954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11773 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity_id  hand_tmp_mean  hand_tmp_std  hand_acc_x_mean  \\\n",
       "0               10      34.375000      0.000000        -1.165524   \n",
       "1                3      31.875000      0.000000       -12.040995   \n",
       "2                4      32.500000      0.000000        -3.723040   \n",
       "3               10      33.812500      0.000000        -3.618932   \n",
       "4                2      34.437500      0.000000        -9.275877   \n",
       "...            ...            ...           ...              ...   \n",
       "11768            1      33.525635      0.030741        -4.306831   \n",
       "11769            1      32.083130      0.029390        -1.545991   \n",
       "11770            3      31.750000      0.000000       -10.034760   \n",
       "11771            6      30.465576      0.031088        -8.275569   \n",
       "11772            8      32.173340      0.026163        -3.077000   \n",
       "\n",
       "       hand_acc_x_std  hand_acc_y_mean  hand_acc_y_std  hand_acc_z_mean  \\\n",
       "0            2.383779         3.381285        2.582771         8.492507   \n",
       "1            3.734766         3.069947        2.591651         1.161251   \n",
       "2           10.188184        11.705779       17.220389        -1.367870   \n",
       "3            1.935690         0.542981        2.907890         8.430229   \n",
       "4            0.082824         1.006239        0.153816         2.709588   \n",
       "...               ...              ...             ...              ...   \n",
       "11768        0.087374         1.634235        0.082474         8.393767   \n",
       "11769        0.086820         3.379703        0.093813         8.981813   \n",
       "11770        1.780491         3.100475        1.319988         1.092313   \n",
       "11771        3.245008         6.196727        4.417230         2.372815   \n",
       "11772        3.850697         3.495658        3.910041         8.028176   \n",
       "\n",
       "       hand_acc_z_std  hand_gyr_x_mean  ...  ankle_acc_xz_cor  \\\n",
       "0            1.224852         0.093030  ...          0.233251   \n",
       "1            1.837110         0.055998  ...         -0.119772   \n",
       "2            4.527840         0.186308  ...          0.025673   \n",
       "3            0.975924        -0.163251  ...          0.724061   \n",
       "4            0.155286        -0.008753  ...         -0.001651   \n",
       "...               ...              ...  ...               ...   \n",
       "11768        0.110314        -0.003882  ...          0.193950   \n",
       "11769        0.103787        -0.011143  ...          0.135629   \n",
       "11770        0.994165         0.060559  ...         -0.404942   \n",
       "11771        1.843274         0.081074  ...         -0.136336   \n",
       "11772        4.359921         0.129189  ...          0.200755   \n",
       "\n",
       "       hand_gyr_xy_cor  hand_gyr_yz_cor  hand_gyr_xz_cor  chest_gyr_xy_cor  \\\n",
       "0            -0.472662         0.335516        -0.377507         -0.290138   \n",
       "1            -0.287380        -0.230390        -0.491314          0.011124   \n",
       "2            -0.265566         0.824691        -0.121345         -0.004923   \n",
       "3            -0.196728         0.315984        -0.380337          0.284190   \n",
       "4            -0.060776         0.165672         0.311760         -0.272620   \n",
       "...                ...              ...              ...               ...   \n",
       "11768        -0.354026         0.175876        -0.172933          0.184131   \n",
       "11769         0.056979         0.008235         0.001093         -0.203294   \n",
       "11770         0.520845        -0.951838        -0.561901         -0.169119   \n",
       "11771        -0.147614        -0.344375        -0.329746         -0.024487   \n",
       "11772        -0.081262         0.130816        -0.278256         -0.254757   \n",
       "\n",
       "       chest_gyr_yz_cor  chest_gyr_xz_cor  ankle_gyr_xy_cor  ankle_gyr_yz_cor  \\\n",
       "0             -0.779952          0.071855         -0.305959         -0.003001   \n",
       "1             -0.799319         -0.135736         -0.653133         -0.654575   \n",
       "2             -0.317761         -0.202148         -0.660278         -0.528138   \n",
       "3             -0.109078         -0.071734         -0.177813          0.237828   \n",
       "4             -0.014943         -0.191610         -0.261158          0.066954   \n",
       "...                 ...               ...               ...               ...   \n",
       "11768         -0.274344         -0.485489         -0.100010         -0.000800   \n",
       "11769         -0.097797         -0.273316         -0.009717         -0.076216   \n",
       "11770          0.299434         -0.100683         -0.555866         -0.442849   \n",
       "11771         -0.536806         -0.161019         -0.752563         -0.627185   \n",
       "11772         -0.723943         -0.039044         -0.016410         -0.662742   \n",
       "\n",
       "       ankle_gyr_xz_cor  \n",
       "0             -0.638866  \n",
       "1              0.391363  \n",
       "2              0.402147  \n",
       "3             -0.729771  \n",
       "4              0.057685  \n",
       "...                 ...  \n",
       "11768          0.031654  \n",
       "11769          0.009411  \n",
       "11770          0.063207  \n",
       "11771          0.436639  \n",
       "11772         -0.085954  \n",
       "\n",
       "[11773 rows x 61 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoding을 진행한다.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "df['activity_id'] = LE.fit_transform(df['activity_id'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58f6b103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.525497Z",
     "start_time": "2024-09-08T14:25:06.479851Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hand_tmp_mean</th>\n",
       "      <th>hand_tmp_std</th>\n",
       "      <th>hand_acc_x_mean</th>\n",
       "      <th>hand_acc_x_std</th>\n",
       "      <th>hand_acc_y_mean</th>\n",
       "      <th>hand_acc_y_std</th>\n",
       "      <th>hand_acc_z_mean</th>\n",
       "      <th>hand_acc_z_std</th>\n",
       "      <th>hand_gyr_x_mean</th>\n",
       "      <th>hand_gyr_x_std</th>\n",
       "      <th>...</th>\n",
       "      <th>hand_gyr_xy_cor</th>\n",
       "      <th>hand_gyr_yz_cor</th>\n",
       "      <th>hand_gyr_xz_cor</th>\n",
       "      <th>chest_gyr_xy_cor</th>\n",
       "      <th>chest_gyr_yz_cor</th>\n",
       "      <th>chest_gyr_xz_cor</th>\n",
       "      <th>ankle_gyr_xy_cor</th>\n",
       "      <th>ankle_gyr_yz_cor</th>\n",
       "      <th>ankle_gyr_xz_cor</th>\n",
       "      <th>activity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.906391</td>\n",
       "      <td>-0.882330</td>\n",
       "      <td>0.794080</td>\n",
       "      <td>-0.189977</td>\n",
       "      <td>-0.045566</td>\n",
       "      <td>-0.178241</td>\n",
       "      <td>1.573033</td>\n",
       "      <td>-0.463362</td>\n",
       "      <td>0.353393</td>\n",
       "      <td>-0.353461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.943103</td>\n",
       "      <td>0.713250</td>\n",
       "      <td>-0.692812</td>\n",
       "      <td>-1.126229</td>\n",
       "      <td>-1.788009</td>\n",
       "      <td>1.037790</td>\n",
       "      <td>-0.615626</td>\n",
       "      <td>0.083811</td>\n",
       "      <td>-2.155291</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.485654</td>\n",
       "      <td>-0.882330</td>\n",
       "      <td>-1.529294</td>\n",
       "      <td>0.255038</td>\n",
       "      <td>-0.117174</td>\n",
       "      <td>-0.176231</td>\n",
       "      <td>-0.847440</td>\n",
       "      <td>-0.090604</td>\n",
       "      <td>0.207085</td>\n",
       "      <td>1.398970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382405</td>\n",
       "      <td>-0.506400</td>\n",
       "      <td>-1.061178</td>\n",
       "      <td>0.275135</td>\n",
       "      <td>-1.846476</td>\n",
       "      <td>0.118200</td>\n",
       "      <td>-1.656592</td>\n",
       "      <td>-1.238058</td>\n",
       "      <td>1.168066</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.137643</td>\n",
       "      <td>-0.882330</td>\n",
       "      <td>0.247707</td>\n",
       "      <td>2.380797</td>\n",
       "      <td>1.869062</td>\n",
       "      <td>3.136292</td>\n",
       "      <td>-1.682450</td>\n",
       "      <td>1.547578</td>\n",
       "      <td>0.721926</td>\n",
       "      <td>2.005533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316390</td>\n",
       "      <td>1.767528</td>\n",
       "      <td>0.136323</td>\n",
       "      <td>0.200490</td>\n",
       "      <td>-0.392753</td>\n",
       "      <td>-0.175993</td>\n",
       "      <td>-1.678015</td>\n",
       "      <td>-0.981551</td>\n",
       "      <td>1.202851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.593181</td>\n",
       "      <td>-0.882330</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>-0.337578</td>\n",
       "      <td>-0.698374</td>\n",
       "      <td>-0.104622</td>\n",
       "      <td>1.552471</td>\n",
       "      <td>-0.614915</td>\n",
       "      <td>-0.659150</td>\n",
       "      <td>-0.617608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108073</td>\n",
       "      <td>0.671155</td>\n",
       "      <td>-0.701971</td>\n",
       "      <td>1.545344</td>\n",
       "      <td>0.237215</td>\n",
       "      <td>0.401716</td>\n",
       "      <td>-0.231395</td>\n",
       "      <td>0.572388</td>\n",
       "      <td>-2.448536</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941193</td>\n",
       "      <td>-0.882330</td>\n",
       "      <td>-0.938570</td>\n",
       "      <td>-0.947913</td>\n",
       "      <td>-0.591825</td>\n",
       "      <td>-0.728253</td>\n",
       "      <td>-0.336245</td>\n",
       "      <td>-1.114539</td>\n",
       "      <td>-0.048743</td>\n",
       "      <td>-1.169156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303341</td>\n",
       "      <td>0.347199</td>\n",
       "      <td>1.538175</td>\n",
       "      <td>-1.044745</td>\n",
       "      <td>0.521390</td>\n",
       "      <td>-0.129311</td>\n",
       "      <td>-0.481296</td>\n",
       "      <td>0.225730</td>\n",
       "      <td>0.091672</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11768</th>\n",
       "      <td>0.433449</td>\n",
       "      <td>1.504662</td>\n",
       "      <td>0.122989</td>\n",
       "      <td>-0.946414</td>\n",
       "      <td>-0.447387</td>\n",
       "      <td>-0.744407</td>\n",
       "      <td>1.540433</td>\n",
       "      <td>-1.141920</td>\n",
       "      <td>-0.029498</td>\n",
       "      <td>-1.194200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.584086</td>\n",
       "      <td>0.369190</td>\n",
       "      <td>-0.030657</td>\n",
       "      <td>1.079907</td>\n",
       "      <td>-0.261687</td>\n",
       "      <td>-1.431140</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.088277</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11769</th>\n",
       "      <td>-0.369764</td>\n",
       "      <td>1.399736</td>\n",
       "      <td>0.712799</td>\n",
       "      <td>-0.946596</td>\n",
       "      <td>-0.045930</td>\n",
       "      <td>-0.741840</td>\n",
       "      <td>1.734581</td>\n",
       "      <td>-1.145894</td>\n",
       "      <td>-0.058186</td>\n",
       "      <td>-1.195850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659690</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.532625</td>\n",
       "      <td>-0.722263</td>\n",
       "      <td>0.271271</td>\n",
       "      <td>-0.491254</td>\n",
       "      <td>0.272623</td>\n",
       "      <td>-0.064722</td>\n",
       "      <td>-0.064051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11770</th>\n",
       "      <td>-0.555257</td>\n",
       "      <td>-0.882330</td>\n",
       "      <td>-1.100693</td>\n",
       "      <td>-0.388700</td>\n",
       "      <td>-0.110152</td>\n",
       "      <td>-0.464185</td>\n",
       "      <td>-0.870201</td>\n",
       "      <td>-0.603810</td>\n",
       "      <td>0.225103</td>\n",
       "      <td>0.426059</td>\n",
       "      <td>...</td>\n",
       "      <td>2.063433</td>\n",
       "      <td>-2.061279</td>\n",
       "      <td>-1.289649</td>\n",
       "      <td>-0.563293</td>\n",
       "      <td>1.470427</td>\n",
       "      <td>0.273480</td>\n",
       "      <td>-1.364945</td>\n",
       "      <td>-0.808522</td>\n",
       "      <td>0.109486</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11771</th>\n",
       "      <td>-1.270447</td>\n",
       "      <td>1.531609</td>\n",
       "      <td>-0.724870</td>\n",
       "      <td>0.093712</td>\n",
       "      <td>0.601984</td>\n",
       "      <td>0.237152</td>\n",
       "      <td>-0.447433</td>\n",
       "      <td>-0.086851</td>\n",
       "      <td>0.306157</td>\n",
       "      <td>0.048274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040554</td>\n",
       "      <td>-0.752064</td>\n",
       "      <td>-0.538219</td>\n",
       "      <td>0.109485</td>\n",
       "      <td>-1.054003</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>-1.954721</td>\n",
       "      <td>-1.182490</td>\n",
       "      <td>1.314118</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11772</th>\n",
       "      <td>-0.319533</td>\n",
       "      <td>1.149159</td>\n",
       "      <td>0.385723</td>\n",
       "      <td>0.293226</td>\n",
       "      <td>-0.019261</td>\n",
       "      <td>0.122305</td>\n",
       "      <td>1.419730</td>\n",
       "      <td>1.445345</td>\n",
       "      <td>0.496254</td>\n",
       "      <td>0.462860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241346</td>\n",
       "      <td>0.272078</td>\n",
       "      <td>-0.371560</td>\n",
       "      <td>-0.961651</td>\n",
       "      <td>-1.618932</td>\n",
       "      <td>0.546527</td>\n",
       "      <td>0.252554</td>\n",
       "      <td>-1.254627</td>\n",
       "      <td>-0.371683</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11773 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hand_tmp_mean  hand_tmp_std  hand_acc_x_mean  hand_acc_x_std  \\\n",
       "0           0.906391     -0.882330         0.794080       -0.189977   \n",
       "1          -0.485654     -0.882330        -1.529294        0.255038   \n",
       "2          -0.137643     -0.882330         0.247707        2.380797   \n",
       "3           0.593181     -0.882330         0.269948       -0.337578   \n",
       "4           0.941193     -0.882330        -0.938570       -0.947913   \n",
       "...              ...           ...              ...             ...   \n",
       "11768       0.433449      1.504662         0.122989       -0.946414   \n",
       "11769      -0.369764      1.399736         0.712799       -0.946596   \n",
       "11770      -0.555257     -0.882330        -1.100693       -0.388700   \n",
       "11771      -1.270447      1.531609        -0.724870        0.093712   \n",
       "11772      -0.319533      1.149159         0.385723        0.293226   \n",
       "\n",
       "       hand_acc_y_mean  hand_acc_y_std  hand_acc_z_mean  hand_acc_z_std  \\\n",
       "0            -0.045566       -0.178241         1.573033       -0.463362   \n",
       "1            -0.117174       -0.176231        -0.847440       -0.090604   \n",
       "2             1.869062        3.136292        -1.682450        1.547578   \n",
       "3            -0.698374       -0.104622         1.552471       -0.614915   \n",
       "4            -0.591825       -0.728253        -0.336245       -1.114539   \n",
       "...                ...             ...              ...             ...   \n",
       "11768        -0.447387       -0.744407         1.540433       -1.141920   \n",
       "11769        -0.045930       -0.741840         1.734581       -1.145894   \n",
       "11770        -0.110152       -0.464185        -0.870201       -0.603810   \n",
       "11771         0.601984        0.237152        -0.447433       -0.086851   \n",
       "11772        -0.019261        0.122305         1.419730        1.445345   \n",
       "\n",
       "       hand_gyr_x_mean  hand_gyr_x_std  ...  hand_gyr_xy_cor  hand_gyr_yz_cor  \\\n",
       "0             0.353393       -0.353461  ...        -0.943103         0.713250   \n",
       "1             0.207085        1.398970  ...        -0.382405        -0.506400   \n",
       "2             0.721926        2.005533  ...        -0.316390         1.767528   \n",
       "3            -0.659150       -0.617608  ...        -0.108073         0.671155   \n",
       "4            -0.048743       -1.169156  ...         0.303341         0.347199   \n",
       "...                ...             ...  ...              ...              ...   \n",
       "11768        -0.029498       -1.194200  ...        -0.584086         0.369190   \n",
       "11769        -0.058186       -1.195850  ...         0.659690         0.007887   \n",
       "11770         0.225103        0.426059  ...         2.063433        -2.061279   \n",
       "11771         0.306157        0.048274  ...         0.040554        -0.752064   \n",
       "11772         0.496254        0.462860  ...         0.241346         0.272078   \n",
       "\n",
       "       hand_gyr_xz_cor  chest_gyr_xy_cor  chest_gyr_yz_cor  chest_gyr_xz_cor  \\\n",
       "0            -0.692812         -1.126229         -1.788009          1.037790   \n",
       "1            -1.061178          0.275135         -1.846476          0.118200   \n",
       "2             0.136323          0.200490         -0.392753         -0.175993   \n",
       "3            -0.701971          1.545344          0.237215          0.401716   \n",
       "4             1.538175         -1.044745          0.521390         -0.129311   \n",
       "...                ...               ...               ...               ...   \n",
       "11768        -0.030657          1.079907         -0.261687         -1.431140   \n",
       "11769         0.532625         -0.722263          0.271271         -0.491254   \n",
       "11770        -1.289649         -0.563293          1.470427          0.273480   \n",
       "11771        -0.538219          0.109485         -1.054003          0.006201   \n",
       "11772        -0.371560         -0.961651         -1.618932          0.546527   \n",
       "\n",
       "       ankle_gyr_xy_cor  ankle_gyr_yz_cor  ankle_gyr_xz_cor  activity_id  \n",
       "0             -0.615626          0.083811         -2.155291           10  \n",
       "1             -1.656592         -1.238058          1.168066            3  \n",
       "2             -1.678015         -0.981551          1.202851            4  \n",
       "3             -0.231395          0.572388         -2.448536           10  \n",
       "4             -0.481296          0.225730          0.091672            2  \n",
       "...                 ...               ...               ...          ...  \n",
       "11768          0.001888          0.088277          0.007700            1  \n",
       "11769          0.272623         -0.064722         -0.064051            1  \n",
       "11770         -1.364945         -0.808522          0.109486            3  \n",
       "11771         -1.954721         -1.182490          1.314118            6  \n",
       "11772          0.252554         -1.254627         -0.371683            8  \n",
       "\n",
       "[11773 rows x 61 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Z-score normalization을 진행한다.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df[[feature_name for feature_name in df.columns if feature_name != 'activity_id']]\n",
    "y = df['activity_id']\n",
    "\n",
    "SS = StandardScaler()\n",
    "X = SS.fit_transform(X)\n",
    "\n",
    "scaled_df = pd.DataFrame(data=X, \n",
    "                        columns = [feature_name for feature_name in df.columns if feature_name != 'activity_id'])\n",
    "scaled_df['activity_id'] = y\n",
    "\n",
    "scaled_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c34aec95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.574757Z",
     "start_time": "2024-09-08T14:25:06.527976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hand_tmp_mean', 'hand_tmp_std', 'hand_acc_x_mean', 'hand_acc_x_std',\n",
      "       'hand_acc_y_mean', 'hand_acc_y_std', 'hand_acc_z_mean',\n",
      "       'hand_acc_z_std', 'hand_gyr_x_mean', 'hand_gyr_x_std',\n",
      "       'hand_gyr_y_mean', 'hand_gyr_y_std', 'hand_gyr_z_mean',\n",
      "       'hand_gyr_z_std', 'chest_tmp_mean', 'chest_tmp_std', 'chest_acc_x_mean',\n",
      "       'chest_acc_x_std', 'chest_acc_y_mean', 'chest_acc_y_std',\n",
      "       'chest_acc_z_mean', 'chest_acc_z_std', 'chest_gyr_x_mean',\n",
      "       'chest_gyr_x_std', 'chest_gyr_y_mean', 'chest_gyr_y_std',\n",
      "       'chest_gyr_z_mean', 'chest_gyr_z_std', 'ankle_tmp_mean',\n",
      "       'ankle_tmp_std', 'ankle_acc_x_mean', 'ankle_acc_x_std',\n",
      "       'ankle_acc_y_mean', 'ankle_acc_y_std', 'ankle_acc_z_mean',\n",
      "       'ankle_acc_z_std', 'ankle_gyr_x_mean', 'ankle_gyr_x_std',\n",
      "       'ankle_gyr_y_mean', 'ankle_gyr_y_std', 'ankle_gyr_z_mean',\n",
      "       'ankle_gyr_z_std', 'hand_acc_xy_cor', 'hand_acc_yz_cor',\n",
      "       'hand_acc_xz_cor', 'chest_acc_xy_cor', 'chest_acc_yz_cor',\n",
      "       'chest_acc_xz_cor', 'ankle_acc_xy_cor', 'ankle_acc_yz_cor',\n",
      "       'ankle_acc_xz_cor', 'hand_gyr_xy_cor', 'hand_gyr_yz_cor',\n",
      "       'hand_gyr_xz_cor', 'chest_gyr_xy_cor', 'chest_gyr_yz_cor',\n",
      "       'chest_gyr_xz_cor', 'ankle_gyr_xy_cor', 'ankle_gyr_yz_cor',\n",
      "       'ankle_gyr_xz_cor', 'activity_id'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11773 entries, 0 to 11772\n",
      "Data columns (total 61 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   hand_tmp_mean     11773 non-null  float64\n",
      " 1   hand_tmp_std      11773 non-null  float64\n",
      " 2   hand_acc_x_mean   11773 non-null  float64\n",
      " 3   hand_acc_x_std    11773 non-null  float64\n",
      " 4   hand_acc_y_mean   11773 non-null  float64\n",
      " 5   hand_acc_y_std    11773 non-null  float64\n",
      " 6   hand_acc_z_mean   11773 non-null  float64\n",
      " 7   hand_acc_z_std    11773 non-null  float64\n",
      " 8   hand_gyr_x_mean   11773 non-null  float64\n",
      " 9   hand_gyr_x_std    11773 non-null  float64\n",
      " 10  hand_gyr_y_mean   11773 non-null  float64\n",
      " 11  hand_gyr_y_std    11773 non-null  float64\n",
      " 12  hand_gyr_z_mean   11773 non-null  float64\n",
      " 13  hand_gyr_z_std    11773 non-null  float64\n",
      " 14  chest_tmp_mean    11773 non-null  float64\n",
      " 15  chest_tmp_std     11773 non-null  float64\n",
      " 16  chest_acc_x_mean  11773 non-null  float64\n",
      " 17  chest_acc_x_std   11773 non-null  float64\n",
      " 18  chest_acc_y_mean  11773 non-null  float64\n",
      " 19  chest_acc_y_std   11773 non-null  float64\n",
      " 20  chest_acc_z_mean  11773 non-null  float64\n",
      " 21  chest_acc_z_std   11773 non-null  float64\n",
      " 22  chest_gyr_x_mean  11773 non-null  float64\n",
      " 23  chest_gyr_x_std   11773 non-null  float64\n",
      " 24  chest_gyr_y_mean  11773 non-null  float64\n",
      " 25  chest_gyr_y_std   11773 non-null  float64\n",
      " 26  chest_gyr_z_mean  11773 non-null  float64\n",
      " 27  chest_gyr_z_std   11773 non-null  float64\n",
      " 28  ankle_tmp_mean    11773 non-null  float64\n",
      " 29  ankle_tmp_std     11773 non-null  float64\n",
      " 30  ankle_acc_x_mean  11773 non-null  float64\n",
      " 31  ankle_acc_x_std   11773 non-null  float64\n",
      " 32  ankle_acc_y_mean  11773 non-null  float64\n",
      " 33  ankle_acc_y_std   11773 non-null  float64\n",
      " 34  ankle_acc_z_mean  11773 non-null  float64\n",
      " 35  ankle_acc_z_std   11773 non-null  float64\n",
      " 36  ankle_gyr_x_mean  11773 non-null  float64\n",
      " 37  ankle_gyr_x_std   11773 non-null  float64\n",
      " 38  ankle_gyr_y_mean  11773 non-null  float64\n",
      " 39  ankle_gyr_y_std   11773 non-null  float64\n",
      " 40  ankle_gyr_z_mean  11773 non-null  float64\n",
      " 41  ankle_gyr_z_std   11773 non-null  float64\n",
      " 42  hand_acc_xy_cor   11773 non-null  float64\n",
      " 43  hand_acc_yz_cor   11773 non-null  float64\n",
      " 44  hand_acc_xz_cor   11773 non-null  float64\n",
      " 45  chest_acc_xy_cor  11773 non-null  float64\n",
      " 46  chest_acc_yz_cor  11773 non-null  float64\n",
      " 47  chest_acc_xz_cor  11773 non-null  float64\n",
      " 48  ankle_acc_xy_cor  11773 non-null  float64\n",
      " 49  ankle_acc_yz_cor  11773 non-null  float64\n",
      " 50  ankle_acc_xz_cor  11773 non-null  float64\n",
      " 51  hand_gyr_xy_cor   11773 non-null  float64\n",
      " 52  hand_gyr_yz_cor   11773 non-null  float64\n",
      " 53  hand_gyr_xz_cor   11773 non-null  float64\n",
      " 54  chest_gyr_xy_cor  11773 non-null  float64\n",
      " 55  chest_gyr_yz_cor  11773 non-null  float64\n",
      " 56  chest_gyr_xz_cor  11773 non-null  float64\n",
      " 57  ankle_gyr_xy_cor  11773 non-null  float64\n",
      " 58  ankle_gyr_yz_cor  11773 non-null  float64\n",
      " 59  ankle_gyr_xz_cor  11773 non-null  float64\n",
      " 60  activity_id       11773 non-null  int64  \n",
      "dtypes: float64(60), int64(1)\n",
      "memory usage: 5.5 MB\n",
      "None\n",
      "\n",
      "Index(['hand_tmp_mean', 'hand_tmp_std', 'hand_acc_x_mean', 'hand_acc_x_std',\n",
      "       'hand_acc_y_mean', 'hand_acc_y_std', 'hand_acc_z_mean',\n",
      "       'hand_acc_z_std', 'hand_gyr_x_mean', 'hand_gyr_x_std',\n",
      "       'hand_gyr_y_mean', 'hand_gyr_y_std', 'hand_gyr_z_mean',\n",
      "       'hand_gyr_z_std', 'chest_tmp_mean', 'chest_tmp_std', 'chest_acc_x_mean',\n",
      "       'chest_acc_x_std', 'chest_acc_y_mean', 'chest_acc_y_std',\n",
      "       'chest_acc_z_mean', 'chest_acc_z_std', 'chest_gyr_x_mean',\n",
      "       'chest_gyr_x_std', 'chest_gyr_y_mean', 'chest_gyr_y_std',\n",
      "       'chest_gyr_z_mean', 'chest_gyr_z_std', 'ankle_tmp_mean',\n",
      "       'ankle_tmp_std', 'ankle_acc_x_mean', 'ankle_acc_x_std',\n",
      "       'ankle_acc_y_mean', 'ankle_acc_y_std', 'ankle_acc_z_mean',\n",
      "       'ankle_acc_z_std', 'ankle_gyr_x_mean', 'ankle_gyr_x_std',\n",
      "       'ankle_gyr_y_mean', 'ankle_gyr_y_std', 'ankle_gyr_z_mean',\n",
      "       'ankle_gyr_z_std', 'hand_acc_xy_cor', 'hand_acc_yz_cor',\n",
      "       'hand_acc_xz_cor', 'chest_acc_xy_cor', 'chest_acc_yz_cor',\n",
      "       'chest_acc_xz_cor', 'ankle_acc_xy_cor', 'ankle_acc_yz_cor',\n",
      "       'ankle_acc_xz_cor', 'hand_gyr_xy_cor', 'hand_gyr_yz_cor',\n",
      "       'hand_gyr_xz_cor', 'chest_gyr_xy_cor', 'chest_gyr_yz_cor',\n",
      "       'chest_gyr_xz_cor', 'ankle_gyr_xy_cor', 'ankle_gyr_yz_cor',\n",
      "       'ankle_gyr_xz_cor', 'activity_id'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2355 entries, 9418 to 11772\n",
      "Data columns (total 61 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   hand_tmp_mean     2355 non-null   float64\n",
      " 1   hand_tmp_std      2355 non-null   float64\n",
      " 2   hand_acc_x_mean   2355 non-null   float64\n",
      " 3   hand_acc_x_std    2355 non-null   float64\n",
      " 4   hand_acc_y_mean   2355 non-null   float64\n",
      " 5   hand_acc_y_std    2355 non-null   float64\n",
      " 6   hand_acc_z_mean   2355 non-null   float64\n",
      " 7   hand_acc_z_std    2355 non-null   float64\n",
      " 8   hand_gyr_x_mean   2355 non-null   float64\n",
      " 9   hand_gyr_x_std    2355 non-null   float64\n",
      " 10  hand_gyr_y_mean   2355 non-null   float64\n",
      " 11  hand_gyr_y_std    2355 non-null   float64\n",
      " 12  hand_gyr_z_mean   2355 non-null   float64\n",
      " 13  hand_gyr_z_std    2355 non-null   float64\n",
      " 14  chest_tmp_mean    2355 non-null   float64\n",
      " 15  chest_tmp_std     2355 non-null   float64\n",
      " 16  chest_acc_x_mean  2355 non-null   float64\n",
      " 17  chest_acc_x_std   2355 non-null   float64\n",
      " 18  chest_acc_y_mean  2355 non-null   float64\n",
      " 19  chest_acc_y_std   2355 non-null   float64\n",
      " 20  chest_acc_z_mean  2355 non-null   float64\n",
      " 21  chest_acc_z_std   2355 non-null   float64\n",
      " 22  chest_gyr_x_mean  2355 non-null   float64\n",
      " 23  chest_gyr_x_std   2355 non-null   float64\n",
      " 24  chest_gyr_y_mean  2355 non-null   float64\n",
      " 25  chest_gyr_y_std   2355 non-null   float64\n",
      " 26  chest_gyr_z_mean  2355 non-null   float64\n",
      " 27  chest_gyr_z_std   2355 non-null   float64\n",
      " 28  ankle_tmp_mean    2355 non-null   float64\n",
      " 29  ankle_tmp_std     2355 non-null   float64\n",
      " 30  ankle_acc_x_mean  2355 non-null   float64\n",
      " 31  ankle_acc_x_std   2355 non-null   float64\n",
      " 32  ankle_acc_y_mean  2355 non-null   float64\n",
      " 33  ankle_acc_y_std   2355 non-null   float64\n",
      " 34  ankle_acc_z_mean  2355 non-null   float64\n",
      " 35  ankle_acc_z_std   2355 non-null   float64\n",
      " 36  ankle_gyr_x_mean  2355 non-null   float64\n",
      " 37  ankle_gyr_x_std   2355 non-null   float64\n",
      " 38  ankle_gyr_y_mean  2355 non-null   float64\n",
      " 39  ankle_gyr_y_std   2355 non-null   float64\n",
      " 40  ankle_gyr_z_mean  2355 non-null   float64\n",
      " 41  ankle_gyr_z_std   2355 non-null   float64\n",
      " 42  hand_acc_xy_cor   2355 non-null   float64\n",
      " 43  hand_acc_yz_cor   2355 non-null   float64\n",
      " 44  hand_acc_xz_cor   2355 non-null   float64\n",
      " 45  chest_acc_xy_cor  2355 non-null   float64\n",
      " 46  chest_acc_yz_cor  2355 non-null   float64\n",
      " 47  chest_acc_xz_cor  2355 non-null   float64\n",
      " 48  ankle_acc_xy_cor  2355 non-null   float64\n",
      " 49  ankle_acc_yz_cor  2355 non-null   float64\n",
      " 50  ankle_acc_xz_cor  2355 non-null   float64\n",
      " 51  hand_gyr_xy_cor   2355 non-null   float64\n",
      " 52  hand_gyr_yz_cor   2355 non-null   float64\n",
      " 53  hand_gyr_xz_cor   2355 non-null   float64\n",
      " 54  chest_gyr_xy_cor  2355 non-null   float64\n",
      " 55  chest_gyr_yz_cor  2355 non-null   float64\n",
      " 56  chest_gyr_xz_cor  2355 non-null   float64\n",
      " 57  ankle_gyr_xy_cor  2355 non-null   float64\n",
      " 58  ankle_gyr_yz_cor  2355 non-null   float64\n",
      " 59  ankle_gyr_xz_cor  2355 non-null   float64\n",
      " 60  activity_id       2355 non-null   int64  \n",
      "dtypes: float64(60), int64(1)\n",
      "memory usage: 1.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_train = scaled_df\n",
    "df_test = scaled_df.iloc[int(scaled_df.shape[0] * 0.8) : ]\n",
    "\n",
    "print (df_train.columns)\n",
    "print (df_train.info())\n",
    "print ()\n",
    "print (df_test.columns)\n",
    "print (df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ece2086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.583990Z",
     "start_time": "2024-09-08T14:25:06.577287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  3  4  2  5  1  6  9  7  0  8 11]\n",
      "[ 9  6  5 10  0  1  7  3  8  2  4 11]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    info()에서 본 df가 결측치가 없음을 확인했으니, 결측치 처리는 pass\n",
    "'''\n",
    "\n",
    "# class 확인\n",
    "\n",
    "print (df_train['activity_id'].unique())\n",
    "print (df_test['activity_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "940c5e80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.676503Z",
     "start_time": "2024-09-08T14:25:06.594673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity_id\n",
      "10    2000\n",
      "3     2000\n",
      "4     2000\n",
      "2     2000\n",
      "5     2000\n",
      "1     2000\n",
      "6     2000\n",
      "9     2000\n",
      "7     2000\n",
      "0     2000\n",
      "8     2000\n",
      "11    2000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "activity_id\n",
      "10    2000\n",
      "3     2000\n",
      "4     2000\n",
      "2     2000\n",
      "5     2000\n",
      "1     2000\n",
      "6     2000\n",
      "9     2000\n",
      "7     2000\n",
      "0     2000\n",
      "8     2000\n",
      "11    2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    oversampling은 함수로 구현한다. 원래는 SMOTE를 사용하려고 하였다.\n",
    "    SMOTE (Synthetic Minority Over-sampling Technique)는 적은 수의 \n",
    "    클래스 사이에서 새로운 가상 records를 구성하는 것이다.\n",
    "    하지만, 랜덤으로 위치를 다시 uniting하기 때문에 시계열 데이터에는 적합하지 않아 직접 구현한다.\n",
    "'''\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE()\n",
    "# harth_input_resampled, harth_target_resampled = smote.fit_resample(harth_input, \n",
    "#                                                                    harth_target)\n",
    "# print (harth_target_resampled.value_counts())\n",
    "# print (harth_input_resampled.shape, harth_target_resampled.shape)\n",
    "\n",
    "# class 별로 데이터 추출 -> 복제하는 방식\n",
    "    \n",
    "# 만약 2000개보다 샘플이 적음 -> replace == True로 복제\n",
    "# 만약 2000개보다 샘플이 많음 -> 복제\n",
    "    \n",
    "def oversampling(df, target_col, max_size) :\n",
    "    # 결과를 저장할 리스트 \n",
    "    dfs = []\n",
    "    \n",
    "    for label in df[target_col].unique() :\n",
    "        class_df = df[df[target_col] == label]\n",
    "        \n",
    "        if len(class_df) < max_size :\n",
    "            # 샘플 수가 max_size보다 적으면 데이터를 복제하여 max_size로 만듦\n",
    "            sampled_df = class_df.sample(max_size, replace=True, random_state=42)\n",
    "        else :\n",
    "            # 샘플 수가 max_size보다 많으면 앞부분부터 max_size만큼 선택함\n",
    "            sampled_df = class_df.head(max_size)\n",
    "        \n",
    "        # 리스트에 추가\n",
    "        dfs.append(sampled_df)\n",
    "    \n",
    "    # 리스트에 저장된 데이터프레임들을 합침\n",
    "    df_resampled = pd.concat(dfs).reset_index(drop=True)\n",
    "    \n",
    "    return df_resampled\n",
    "\n",
    "df_train_resampled = oversampling(df_train, 'activity_id', max_size=2000)\n",
    "df_test_resampled = oversampling(df_train, 'activity_id', max_size=2000)\n",
    "print (df_train_resampled['activity_id'].value_counts())\n",
    "print ()\n",
    "print (df_test_resampled['activity_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9871fc8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:25:06.701354Z",
     "start_time": "2024-09-08T14:25:06.678498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       hand_tmp_mean  hand_tmp_std  hand_acc_x_mean  hand_acc_x_std  \\\n",
      "0           0.453977     -0.882330        -0.097431       -0.634573   \n",
      "1           0.914208      1.142936         0.855524       -0.024653   \n",
      "2           0.732386     -0.882330        -0.280188       -0.405089   \n",
      "3           0.036363     -0.882330         0.082850       -0.005500   \n",
      "4           0.488778     -0.882330         0.034279       -0.679005   \n",
      "...              ...           ...              ...             ...   \n",
      "23995      -2.434518     -0.882330         0.465925        0.569297   \n",
      "23996      -2.434518     -0.882330         0.211117        0.799635   \n",
      "23997      -1.425285     -0.882330        -0.275577        2.078471   \n",
      "23998      -4.313780     -0.882330         0.636909        0.489950   \n",
      "23999      -1.425285     -0.882330        -0.150753        2.089662   \n",
      "\n",
      "       hand_acc_y_mean  hand_acc_y_std  hand_acc_z_mean  hand_acc_z_std  \\\n",
      "0             0.879808       -0.378651        -0.296451       -0.111293   \n",
      "1             0.750473       -0.199355         0.819502       -0.036791   \n",
      "2            -0.224866        0.022800         1.037256       -0.021266   \n",
      "3             0.844130       -0.088096        -0.186999        0.702338   \n",
      "4            -0.617152       -0.277993         1.550841       -0.743647   \n",
      "...                ...             ...              ...             ...   \n",
      "23995         0.878750        0.738471        -2.574707        3.997873   \n",
      "23996         1.090512        0.733507        -2.346777        4.281054   \n",
      "23997         1.058378        0.536226        -0.565207        2.080494   \n",
      "23998         1.351208        1.554223        -1.193580        2.527368   \n",
      "23999         1.198558        0.741497        -0.852898        1.776024   \n",
      "\n",
      "       hand_gyr_x_mean  hand_gyr_x_std  ...  hand_gyr_xy_cor  hand_gyr_yz_cor  \\\n",
      "0            -0.034987        0.034996  ...        -0.974383        -0.108180   \n",
      "1             0.202054        0.148273  ...        -0.445978         0.374167   \n",
      "2            -0.147966        0.501583  ...        -2.111617         1.156649   \n",
      "3            -0.087350        0.918264  ...        -1.182182         1.319249   \n",
      "4             0.112150       -0.773737  ...        -1.072768         1.070497   \n",
      "...                ...             ...  ...              ...              ...   \n",
      "23995         3.422432        3.072285  ...        -0.739230         0.437376   \n",
      "23996         5.648326        2.295580  ...        -0.878724         0.714711   \n",
      "23997         1.531750        0.901609  ...        -1.273387         0.692464   \n",
      "23998         2.407689        1.375440  ...        -0.175637         0.777085   \n",
      "23999         1.612462        1.061672  ...        -0.739910         0.795677   \n",
      "\n",
      "       hand_gyr_xz_cor  chest_gyr_xy_cor  chest_gyr_yz_cor  chest_gyr_xz_cor  \\\n",
      "0             1.907305         -0.679944          0.075573         -0.109159   \n",
      "1             0.433534         -1.923118         -1.936045          2.682215   \n",
      "2            -1.203116          0.652081         -0.958886         -0.866191   \n",
      "3             0.573400          0.797540         -0.766410         -1.970566   \n",
      "4            -1.602548         -1.807115         -0.391491          0.696867   \n",
      "...                ...               ...               ...               ...   \n",
      "23995        -0.609831         -1.497708         -0.182805         -1.728979   \n",
      "23996        -0.961537         -2.599730          0.211236         -1.498605   \n",
      "23997         0.778683         -0.652769          0.288406         -1.928718   \n",
      "23998        -0.696861          0.824392          0.260862          0.373113   \n",
      "23999         1.227590         -0.637784          0.474096         -2.527833   \n",
      "\n",
      "       ankle_gyr_xy_cor  ankle_gyr_yz_cor  ankle_gyr_xz_cor  activity_id  \n",
      "0             -0.148563         -0.462749          0.426773           10  \n",
      "1             -0.239698          0.565702         -0.534138           10  \n",
      "2              0.584418         -0.508633         -1.559895           10  \n",
      "3             -1.185996         -0.044567         -0.896735           10  \n",
      "4             -0.305108          0.071076         -1.745702           10  \n",
      "...                 ...               ...               ...          ...  \n",
      "23995         -0.062929         -0.465271         -1.139860           11  \n",
      "23996         -0.207599         -0.369366         -1.121636           11  \n",
      "23997         -0.452836          0.910909         -1.434130           11  \n",
      "23998          0.980741          1.305348          0.317733           11  \n",
      "23999         -1.145258          0.885985         -1.549712           11  \n",
      "\n",
      "[24000 rows x 61 columns]        hand_tmp_mean  hand_tmp_std  hand_acc_x_mean  hand_acc_x_std  \\\n",
      "0           0.453977     -0.882330        -0.097431       -0.634573   \n",
      "1           0.914208      1.142936         0.855524       -0.024653   \n",
      "2           0.732386     -0.882330        -0.280188       -0.405089   \n",
      "3           0.036363     -0.882330         0.082850       -0.005500   \n",
      "4           0.488778     -0.882330         0.034279       -0.679005   \n",
      "...              ...           ...              ...             ...   \n",
      "23995      -2.434518     -0.882330         0.465925        0.569297   \n",
      "23996      -2.434518     -0.882330         0.211117        0.799635   \n",
      "23997      -1.425285     -0.882330        -0.275577        2.078471   \n",
      "23998      -4.313780     -0.882330         0.636909        0.489950   \n",
      "23999      -1.425285     -0.882330        -0.150753        2.089662   \n",
      "\n",
      "       hand_acc_y_mean  hand_acc_y_std  hand_acc_z_mean  hand_acc_z_std  \\\n",
      "0             0.879808       -0.378651        -0.296451       -0.111293   \n",
      "1             0.750473       -0.199355         0.819502       -0.036791   \n",
      "2            -0.224866        0.022800         1.037256       -0.021266   \n",
      "3             0.844130       -0.088096        -0.186999        0.702338   \n",
      "4            -0.617152       -0.277993         1.550841       -0.743647   \n",
      "...                ...             ...              ...             ...   \n",
      "23995         0.878750        0.738471        -2.574707        3.997873   \n",
      "23996         1.090512        0.733507        -2.346777        4.281054   \n",
      "23997         1.058378        0.536226        -0.565207        2.080494   \n",
      "23998         1.351208        1.554223        -1.193580        2.527368   \n",
      "23999         1.198558        0.741497        -0.852898        1.776024   \n",
      "\n",
      "       hand_gyr_x_mean  hand_gyr_x_std  ...  hand_gyr_xy_cor  hand_gyr_yz_cor  \\\n",
      "0            -0.034987        0.034996  ...        -0.974383        -0.108180   \n",
      "1             0.202054        0.148273  ...        -0.445978         0.374167   \n",
      "2            -0.147966        0.501583  ...        -2.111617         1.156649   \n",
      "3            -0.087350        0.918264  ...        -1.182182         1.319249   \n",
      "4             0.112150       -0.773737  ...        -1.072768         1.070497   \n",
      "...                ...             ...  ...              ...              ...   \n",
      "23995         3.422432        3.072285  ...        -0.739230         0.437376   \n",
      "23996         5.648326        2.295580  ...        -0.878724         0.714711   \n",
      "23997         1.531750        0.901609  ...        -1.273387         0.692464   \n",
      "23998         2.407689        1.375440  ...        -0.175637         0.777085   \n",
      "23999         1.612462        1.061672  ...        -0.739910         0.795677   \n",
      "\n",
      "       hand_gyr_xz_cor  chest_gyr_xy_cor  chest_gyr_yz_cor  chest_gyr_xz_cor  \\\n",
      "0             1.907305         -0.679944          0.075573         -0.109159   \n",
      "1             0.433534         -1.923118         -1.936045          2.682215   \n",
      "2            -1.203116          0.652081         -0.958886         -0.866191   \n",
      "3             0.573400          0.797540         -0.766410         -1.970566   \n",
      "4            -1.602548         -1.807115         -0.391491          0.696867   \n",
      "...                ...               ...               ...               ...   \n",
      "23995        -0.609831         -1.497708         -0.182805         -1.728979   \n",
      "23996        -0.961537         -2.599730          0.211236         -1.498605   \n",
      "23997         0.778683         -0.652769          0.288406         -1.928718   \n",
      "23998        -0.696861          0.824392          0.260862          0.373113   \n",
      "23999         1.227590         -0.637784          0.474096         -2.527833   \n",
      "\n",
      "       ankle_gyr_xy_cor  ankle_gyr_yz_cor  ankle_gyr_xz_cor  activity_id  \n",
      "0             -0.148563         -0.462749          0.426773           10  \n",
      "1             -0.239698          0.565702         -0.534138           10  \n",
      "2              0.584418         -0.508633         -1.559895           10  \n",
      "3             -1.185996         -0.044567         -0.896735           10  \n",
      "4             -0.305108          0.071076         -1.745702           10  \n",
      "...                 ...               ...               ...          ...  \n",
      "23995         -0.062929         -0.465271         -1.139860           11  \n",
      "23996         -0.207599         -0.369366         -1.121636           11  \n",
      "23997         -0.452836          0.910909         -1.434130           11  \n",
      "23998          0.980741          1.305348          0.317733           11  \n",
      "23999         -1.145258          0.885985         -1.549712           11  \n",
      "\n",
      "[24000 rows x 61 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    이전에 oversampling 전에 했었던 작업. \\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 둘 다 모양을 맞추기 위해 400000까지 cut\n",
    "\n",
    "print (df_train_resampled, df_test_resampled)\n",
    "\n",
    "# df_train = df_train.iloc[:400000]\n",
    "# df_test = df_test.iloc[:400000]\n",
    "\n",
    "# df_train.shape, df_test.shape \n",
    "\n",
    "'''\n",
    "    이전에 oversampling 전에 했었던 작업. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94cf4891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:18.265625Z",
     "start_time": "2024-09-08T14:26:18.244038Z"
    }
   },
   "outputs": [],
   "source": [
    "# reshape를 통해 전체 열을 3D ndarray로 재구성\n",
    "\n",
    "features = [feature_name for feature_name in df.columns if feature_name != 'activity_id']\n",
    "\n",
    "train_input = df_train_resampled[features].values.reshape(-1, 100, len(features))\n",
    "train_input_mean = train_input.mean()\n",
    "train_input_sigma = train_input.std()\n",
    "train_input = (train_input - train_input_mean) / train_input_sigma\n",
    "\n",
    "test_input = df_test_resampled[features].values.reshape(-1, 500, len(features))\n",
    "test_input = (test_input - train_input_mean) / train_input_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2d638bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:31.641324Z",
     "start_time": "2024-09-08T14:26:31.636896Z"
    }
   },
   "outputs": [],
   "source": [
    "# label을 target으로 두고, one-hot encoding 진행\n",
    "\n",
    "train_target = pd.get_dummies(df_train_resampled[\"activity_id\"]).values.reshape(-1, 100, len(df_train_resampled['activity_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c69ea85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:34.312070Z",
     "start_time": "2024-09-08T14:26:34.304054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input:(192, 100, 60), val_input:(48, 100, 60), train_target:(192, 100, 12), val_target:(48, 100, 12)\n"
     ]
    }
   ],
   "source": [
    "# val set 구축\n",
    "\n",
    "idx = np.arange(train_input.shape[0])\n",
    "train_idx, val_idx = train_test_split(idx, \n",
    "                                      random_state=111, \n",
    "                                      test_size=0.2)\n",
    "# idx를 섞어서 편향 문제를 방지\n",
    "\n",
    "val_input = train_input[val_idx]\n",
    "train_input = train_input[train_idx]\n",
    "val_target = train_target[val_idx]\n",
    "train_target = train_target[train_idx]\n",
    "\n",
    "print(\"train_input:{}, val_input:{}, train_target:{}, val_target:{}\".format(train_input.shape, val_input.shape, train_target.shape, val_target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43b843",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "```ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 5, 256), (None, 4, 192)]``` 로 인하여 기존 소스코드 로직에 해가 가지 않을 정도로만 수정한다.\n",
    "\n",
    "- Unet 메소드에 upsampling 후 크기가 맞지 않아 concatenate가 되지 않는 문제 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33312089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:37.602209Z",
     "start_time": "2024-09-08T14:26:37.599011Z"
    }
   },
   "outputs": [],
   "source": [
    "def cbr(x, out_layer, kernel, stride, dilation):\n",
    "    x = Conv1D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5806ef57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:39.093467Z",
     "start_time": "2024-09-08T14:26:39.090039Z"
    }
   },
   "outputs": [],
   "source": [
    "def se_block(x_in, layer_n):\n",
    "    x = GlobalAveragePooling1D()(x_in)\n",
    "    x = Dense(layer_n // 8, activation=\"relu\")(x)\n",
    "    x = Dense(layer_n, activation=\"sigmoid\")(x)\n",
    "    x_out = Multiply()([x_in, x])\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb32321a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:39.625547Z",
     "start_time": "2024-09-08T14:26:39.622107Z"
    }
   },
   "outputs": [],
   "source": [
    "def resblock(x_in, layer_n, kernel, dilation, use_se=True):\n",
    "    x = cbr(x_in, layer_n, kernel, 1, dilation)\n",
    "    x = cbr(x, layer_n, kernel, 1, dilation)\n",
    "    if use_se:\n",
    "        x = se_block(x, layer_n)\n",
    "    x = Add()([x_in, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81dc7367",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:47.731924Z",
     "start_time": "2024-09-08T14:26:47.724530Z"
    }
   },
   "outputs": [],
   "source": [
    "def Unet(input_shape=(100, 60)):\n",
    "    layer_n = 64\n",
    "    kernel_size = 7\n",
    "    depth = 2\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    ########## encoder \n",
    "    x = cbr(input_layer, layer_n, kernel_size, 1, 1)  \n",
    "    # shape: (None, 100, 64)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n, kernel_size, 1)\n",
    "    out_0 = x\n",
    "\n",
    "    x = cbr(x, layer_n*2, kernel_size, 5, 1)  \n",
    "    # shape: (None, 20, 128)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n*2, kernel_size, 1)\n",
    "    out_1 = x\n",
    "\n",
    "    x = cbr(x, layer_n*3, kernel_size, 5, 1)  \n",
    "    # shape: (None, 4, 192)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n*3, kernel_size, 1)\n",
    "    out_2 = x\n",
    "\n",
    "    ########## Decoder\n",
    "    x = UpSampling1D(size=5)(x)  # upsample to (None, 20, 192)\n",
    "    x = Concatenate()([x, out_1])  # concatenate with out_1 (None, 20, 128)\n",
    "    x = Conv1D(layer_n*2, kernel_size=1, padding=\"same\")(x)  \n",
    "    x = cbr(x, layer_n*2, kernel_size, 1, 1) \n",
    "    # shape: (None, 20, 128)\n",
    "\n",
    "    x = UpSampling1D(size=5)(x)  # upsample to (None, 100, 128)\n",
    "    x = Concatenate()([x, out_0])  # concatenate with out_0 (None, 100, 64)\n",
    "    x = Conv1D(layer_n, kernel_size=1, padding=\"same\")(x) \n",
    "    x = cbr(x, layer_n, kernel_size, 1, 1) \n",
    "    # shape: (None, 100, 64)\n",
    "\n",
    "    ######### Dense\n",
    "    num_classes = len(df_train_resampled['activity_id'].unique())\n",
    "    x = Conv1D(num_classes, kernel_size=1, \n",
    "               strides=1, padding=\"same\")(x)\n",
    "    out = Activation(\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=out)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72ddadb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:48.317951Z",
     "start_time": "2024-09-08T14:26:48.314762Z"
    }
   },
   "outputs": [],
   "source": [
    "def augmentations(input_data, target_data):\n",
    "    #flip\n",
    "    if np.random.rand() < 0.5:    \n",
    "        input_data = input_data[::-1]\n",
    "        target_data = target_data[::-1]\n",
    "\n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54a81474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:48.824672Z",
     "start_time": "2024-09-08T14:26:48.819713Z"
    }
   },
   "outputs": [],
   "source": [
    "def Datagen(input_dataset, target_dataset, batch_size, is_train=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    idx_1 = np.arange(len(input_dataset))\n",
    "    np.random.shuffle(idx_1)\n",
    "\n",
    "    while True:\n",
    "        for i in range(len(input_dataset)):\n",
    "            input_data = input_dataset[idx_1[i]]\n",
    "            target_data = target_dataset[idx_1[i]]\n",
    "\n",
    "            if is_train:\n",
    "                input_data, target_data = augmentations(input_data, target_data)\n",
    "                \n",
    "            x.append(input_data)\n",
    "            y.append(target_data)\n",
    "            count += 1\n",
    "            \n",
    "            if count == batch_size:\n",
    "                x=np.array(x, dtype=np.float32)\n",
    "                y=np.array(y, dtype=np.float32)\n",
    "                inputs = x\n",
    "                targets = y       \n",
    "                x = []\n",
    "                y = []\n",
    "                count=0\n",
    "                yield inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "012c9fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:49.434751Z",
     "start_time": "2024-09-08T14:26:49.419512Z"
    }
   },
   "outputs": [],
   "source": [
    "# class macroF1(Callback):\n",
    "#     def __init__(self, model, inputs, targets):\n",
    "#         self.model = model\n",
    "#         self.inputs = inputs\n",
    "#         self.targets = np.argmax(targets, axis=2).reshape(-1)\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs):\n",
    "#         # 각 에포크가 끝날 때마다 검증 데이터로 매크로 F1 스코어를 계산하여 출력\n",
    "#         pred = np.argmax(self.model.predict(self.inputs), axis=2).reshape(-1)\n",
    "#         f1_val = f1_score(self.targets, pred, average=\"macro\")\n",
    "#         print(\"val_f1_macro_score: \", f1_val)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class macroF1(Callback):\n",
    "    def __init__(self, inputs, targets):\n",
    "        super(macroF1, self).__init__()\n",
    "        self.inputs = inputs\n",
    "        self.targets = np.argmax(targets, axis=2).reshape(-1)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        predictions = self.model.predict(self.inputs) \n",
    "        pred = np.argmax(predictions, axis=2).reshape(-1)\n",
    "\n",
    "        # Calculate the macro F1 score\n",
    "        f1_val = f1_score(self.targets, pred, average=\"macro\")\n",
    "        \n",
    "        # Add the F1 score to logs\n",
    "        logs['val_f1_macro_score'] = f1_val\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} - val_f1_macro_score: {f1_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b201271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:50.020613Z",
     "start_time": "2024-09-08T14:26:50.016645Z"
    }
   },
   "outputs": [],
   "source": [
    "# def model_fit(model, train_inputs, train_targets, val_inputs, val_targets, n_epoch, batch_size=32):\n",
    "#     # 모델을 학습시키기 위한 함수\n",
    "#     hist = model.fit_generator(\n",
    "#         Datagen(train_inputs, train_targets, batch_size, is_train=True),\n",
    "#         steps_per_epoch=len(train_inputs) // batch_size,\n",
    "#         epochs=n_epoch,\n",
    "#         validation_data=Datagen(val_inputs, val_targets, batch_size),\n",
    "#         validation_steps=len(val_inputs) // batch_size,\n",
    "#         callbacks=[lr_schedule, macroF1(model, val_inputs, val_targets)],\n",
    "#         shuffle=False,\n",
    "#         verbose=1\n",
    "#     )\n",
    "#     return hist\n",
    "\n",
    "'''\n",
    "    fit_generator가 정상적으로 작동하지 않아, 일부 수정함\n",
    "'''\n",
    "\n",
    "def model_fit(model, train_inputs, train_targets, val_inputs, val_targets, n_epoch, batch_size=32):\n",
    "    # 모델을 학습시키기 위한 함수\n",
    "    hist = model.fit(\n",
    "        train_inputs, train_targets,\n",
    "        batch_size=batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=(val_inputs, val_targets),\n",
    "        callbacks=[lr_schedule, macroF1(val_inputs, val_targets)],\n",
    "        shuffle=True, \n",
    "        verbose=1\n",
    "    )\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c9bc2ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:26:50.593741Z",
     "start_time": "2024-09-08T14:26:50.590740Z"
    }
   },
   "outputs": [],
   "source": [
    "def lrs(epoch):\n",
    "    if epoch<35:\n",
    "        lr = learning_rate\n",
    "    elif epoch<50:\n",
    "        lr = learning_rate/10\n",
    "    else:\n",
    "        lr = learning_rate/100\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa3510bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:27:48.129612Z",
     "start_time": "2024-09-08T14:26:51.169210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497ms/step- accuracy: 0.2254 - loss: 2.\n",
      "Epoch 1 - val_f1_macro_score: 0.0753\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 409ms/step - accuracy: 0.2480 - loss: 2.3017 - val_accuracy: 0.1283 - val_loss: 2.7340 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.0753\n",
      "Epoch 2/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8465 - loss: 0.869\n",
      "Epoch 2 - val_f1_macro_score: 0.1733\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.8473 - loss: 0.8635 - val_accuracy: 0.2458 - val_loss: 2.8056 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.1733\n",
      "Epoch 3/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9583 - loss: 0.499\n",
      "Epoch 3 - val_f1_macro_score: 0.2455\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9581 - loss: 0.4954 - val_accuracy: 0.3258 - val_loss: 2.2959 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.2455\n",
      "Epoch 4/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - loss: 0.285\n",
      "Epoch 4 - val_f1_macro_score: 0.3178\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9943 - loss: 0.2866 - val_accuracy: 0.3633 - val_loss: 1.7039 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.3178\n",
      "Epoch 5/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.215\n",
      "Epoch 5 - val_f1_macro_score: 0.5633\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.9991 - loss: 0.2149 - val_accuracy: 0.5775 - val_loss: 1.1720 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.5633\n",
      "Epoch 6/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9953 - loss: 0.202\n",
      "Epoch 6 - val_f1_macro_score: 0.8651\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.9957 - loss: 0.1978 - val_accuracy: 0.8654 - val_loss: 0.7684 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.8651\n",
      "Epoch 7/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9750 - loss: 0.222\n",
      "Epoch 7 - val_f1_macro_score: 0.9026\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9771 - loss: 0.2148 - val_accuracy: 0.8963 - val_loss: 0.5640 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9026\n",
      "Epoch 8/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/stepp - accuracy: 0.9964 - loss: 0.125\n",
      "Epoch 8 - val_f1_macro_score: 0.9829\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.9961 - loss: 0.1262 - val_accuracy: 0.9819 - val_loss: 0.4004 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9829\n",
      "Epoch 9/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.133\n",
      "Epoch 9 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.1334 - val_accuracy: 1.0000 - val_loss: 0.3090 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 10/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.095\n",
      "Epoch 10 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0948 - val_accuracy: 1.0000 - val_loss: 0.2680 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 11/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.084\n",
      "Epoch 11 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0841 - val_accuracy: 1.0000 - val_loss: 0.2211 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 12/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.085\n",
      "Epoch 12 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0844 - val_accuracy: 1.0000 - val_loss: 0.1883 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 13/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.077\n",
      "Epoch 13 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0771 - val_accuracy: 1.0000 - val_loss: 0.1744 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 14/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9996 - loss: 0.081\n",
      "Epoch 14 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9996 - loss: 0.0819 - val_accuracy: 1.0000 - val_loss: 0.1607 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 15/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.062\n",
      "Epoch 15 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0622 - val_accuracy: 1.0000 - val_loss: 0.1595 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 16/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9986 - loss: 0.060\n",
      "Epoch 16 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.9983 - loss: 0.0613 - val_accuracy: 1.0000 - val_loss: 0.1362 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 17/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9891 - loss: 0.103\n",
      "Epoch 17 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.9870 - loss: 0.1141 - val_accuracy: 1.0000 - val_loss: 0.1242 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 18/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9954 - loss: 0.115\n",
      "Epoch 18 - val_f1_macro_score: 0.9991\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9958 - loss: 0.1113 - val_accuracy: 0.9992 - val_loss: 0.1418 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9991\n",
      "Epoch 19/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9932 - loss: 0.073\n",
      "Epoch 19 - val_f1_macro_score: 0.8974\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.9932 - loss: 0.0739 - val_accuracy: 0.9375 - val_loss: 0.2894 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.8974\n",
      "Epoch 20/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.053\n",
      "Epoch 20 - val_f1_macro_score: 0.8970\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0535 - val_accuracy: 0.9369 - val_loss: 0.3074 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.8970\n",
      "Epoch 21/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.050\n",
      "Epoch 21 - val_f1_macro_score: 0.9426\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0505 - val_accuracy: 0.9573 - val_loss: 0.2154 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9426\n",
      "Epoch 22/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.044\n",
      "Epoch 22 - val_f1_macro_score: 0.9882\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0443 - val_accuracy: 0.9894 - val_loss: 0.1333 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9882\n",
      "Epoch 23/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.033\n",
      "Epoch 23 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0334 - val_accuracy: 1.0000 - val_loss: 0.0784 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.040\n",
      "Epoch 24 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0401 - val_accuracy: 1.0000 - val_loss: 0.0622 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 25/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.034\n",
      "Epoch 25 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0342 - val_accuracy: 1.0000 - val_loss: 0.0577 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 26/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.030\n",
      "Epoch 26 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0304 - val_accuracy: 1.0000 - val_loss: 0.0584 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 27/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.038\n",
      "Epoch 27 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0379 - val_accuracy: 1.0000 - val_loss: 0.0581 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 28/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/stepp - accuracy: 1.0000 - loss: 0.035\n",
      "Epoch 28 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0352 - val_accuracy: 1.0000 - val_loss: 0.0514 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 29/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepp - accuracy: 1.0000 - loss: 0.028\n",
      "Epoch 29 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0287 - val_accuracy: 1.0000 - val_loss: 0.0474 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 30/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepp - accuracy: 1.0000 - loss: 0.024\n",
      "Epoch 30 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0445 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 31/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.025\n",
      "Epoch 31 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0255 - val_accuracy: 1.0000 - val_loss: 0.0431 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 32/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.027\n",
      "Epoch 32 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0271 - val_accuracy: 1.0000 - val_loss: 0.0420 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 33/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9999 - loss: 0.025\n",
      "Epoch 33 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9999 - loss: 0.0254 - val_accuracy: 1.0000 - val_loss: 0.0392 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 34/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.021\n",
      "Epoch 34 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 1.0000 - val_loss: 0.0373 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 35/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.025\n",
      "Epoch 35 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0371 - learning_rate: 5.0000e-04 - val_f1_macro_score: 1.0000\n",
      "Epoch 36/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.02\n",
      "Epoch 36 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0216 - val_accuracy: 1.0000 - val_loss: 0.0350 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 37/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0191\n",
      "Epoch 37 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0332 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 38/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/stepp - accuracy: 1.0000 - loss: 0.021\n",
      "Epoch 38 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 1.0000 - val_loss: 0.0315 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 39/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/stepp - accuracy: 1.0000 - loss: 0.021\n",
      "Epoch 39 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 0.0300 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 40/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.026\n",
      "Epoch 40 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0266 - val_accuracy: 1.0000 - val_loss: 0.0286 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 41/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0195\n",
      "Epoch 41 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0194 - val_accuracy: 1.0000 - val_loss: 0.0275 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 42/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/stepp - accuracy: 1.0000 - loss: 0.018\n",
      "Epoch 42 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0265 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 43/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/stepp - accuracy: 1.0000 - loss: 0.019\n",
      "Epoch 43 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0256 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 44/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.018\n",
      "Epoch 44 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 1.0000 - val_loss: 0.0247 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 45/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/stepp - accuracy: 1.0000 - loss: 0.021\n",
      "Epoch 45 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 0.0238 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 46/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.030\n",
      "Epoch 46 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0298 - val_accuracy: 1.0000 - val_loss: 0.0233 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.020\n",
      "Epoch 47 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 0.0228 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 48/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.019\n",
      "Epoch 48 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 0.0223 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 49/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0221\n",
      "Epoch 49 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0217 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 50/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.023\n",
      "Epoch 50 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 1.0000 - val_loss: 0.0211 - learning_rate: 5.0000e-05 - val_f1_macro_score: 1.0000\n",
      "Epoch 51/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/stepp - accuracy: 1.0000 - loss: 0.018\n",
      "Epoch 51 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0206 - learning_rate: 5.0000e-06 - val_f1_macro_score: 1.0000\n",
      "Epoch 52/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.018\n",
      "Epoch 52 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 1.0000 - val_loss: 0.0201 - learning_rate: 5.0000e-06 - val_f1_macro_score: 1.0000\n",
      "Epoch 53/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.018\n",
      "Epoch 53 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 1.0000 - val_loss: 0.0196 - learning_rate: 5.0000e-06 - val_f1_macro_score: 1.0000\n",
      "Epoch 54/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/stepp - accuracy: 1.0000 - loss: 0.022\n",
      "Epoch 54 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0192 - learning_rate: 5.0000e-06 - val_f1_macro_score: 1.0000\n",
      "Epoch 55/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/stepp - accuracy: 1.0000 - loss: 0.019\n",
      "Epoch 55 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 1.0000 - val_loss: 0.0188 - learning_rate: 5.0000e-06 - val_f1_macro_score: 1.0000\n",
      "Epoch 56/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.023\n",
      "Epoch 56 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 1.0000 - val_loss: 0.0184 - learning_rate: 5.0000e-06 - val_f1_macro_score: 1.0000\n",
      "Epoch 57/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.016\n",
      "Epoch 57 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 0.0181 - learning_rate: 5.0000e-06 - val_f1_macro_score: 1.0000\n",
      "Epoch 58/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.021\n",
      "Epoch 58 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 1.0000 - val_loss: 0.0177 - learning_rate: 5.0000e-06 - val_f1_macro_score: 1.0000\n",
      "Epoch 59/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.022\n",
      "Epoch 59 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 1.0000 - val_loss: 0.0174 - learning_rate: 5.0000e-06 - val_f1_macro_score: 1.0000\n",
      "Epoch 60/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.020\n",
      "Epoch 60 - val_f1_macro_score: 1.0000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 0.0172 - learning_rate: 5.0000e-06 - val_f1_macro_score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = Unet()\n",
    "#print(model.summary())\n",
    "\n",
    "learning_rate=0.0005\n",
    "n_epoch=60\n",
    "batch_size=32\n",
    "\n",
    "lr_schedule = LearningRateScheduler(lrs)\n",
    "\n",
    "#regressor\n",
    "#model.compile(loss=\"mean_squared_error\", \n",
    "#              optimizer=Adam(lr=learning_rate),\n",
    "#              metrics=[\"mean_absolute_error\"])\n",
    "\n",
    "#classifier\n",
    "model.compile(loss=categorical_crossentropy, \n",
    "              optimizer=Adam(learning_rate=learning_rate), \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "hist = model_fit(model, train_input, train_target, val_input, val_target, n_epoch, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90a91e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:29:51.091423Z",
     "start_time": "2024-09-08T14:29:50.833064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "SCORE_oldmetric:  1.0\n",
      "SCORE_newmetric:  1.0\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax((model.predict(val_input)+model.predict(val_input[:,::-1,:])[:,::-1,:])/2, axis=2).reshape(-1)\n",
    "gt = np.argmax(val_target, axis=2).reshape(-1)\n",
    "print(\"SCORE_oldmetric: \", cohen_kappa_score(gt, pred, weights=\"quadratic\"))\n",
    "print(\"SCORE_newmetric: \", f1_score(gt, pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "237a1eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:30:28.635913Z",
     "start_time": "2024-09-08T14:30:28.473389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [0.3836458623409271, 0.852135419845581, 0.9565624594688416, 0.9928646087646484, 0.9991666674613953, 0.9979687333106995, 0.9896354079246521, 0.9938542246818542, 0.9999478459358215, 1.0, 1.0, 1.0, 1.0, 0.9997395873069763, 1.0, 0.9963021278381348, 0.9739583134651184, 0.9980729222297668, 0.9928646087646484, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999478459358215, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'loss': [1.9181803464889526, 0.8259056210517883, 0.4710738956928253, 0.29160013794898987, 0.2115555852651596, 0.17173336446285248, 0.170668363571167, 0.1275486797094345, 0.1317455917596817, 0.09316603094339371, 0.08117567747831345, 0.07652150839567184, 0.07747375965118408, 0.08256395161151886, 0.0590260773897171, 0.06507208198308945, 0.17712384462356567, 0.08526816219091415, 0.07598749548196793, 0.05327847972512245, 0.04996681213378906, 0.04330912604928017, 0.034939009696245193, 0.04077534005045891, 0.03527667373418808, 0.028817234560847282, 0.03573485091328621, 0.03333468362689018, 0.028565488755702972, 0.023728765547275543, 0.026199007406830788, 0.025867102667689323, 0.023446982726454735, 0.022880876436829567, 0.02548380196094513, 0.02092014253139496, 0.0202761460095644, 0.021406209096312523, 0.02126489393413067, 0.02608279138803482, 0.01908237300813198, 0.01918068341910839, 0.019123146310448647, 0.019427208229899406, 0.02173224650323391, 0.024373507127165794, 0.020548133179545403, 0.019981786608695984, 0.021844113245606422, 0.02335270494222641, 0.019330497831106186, 0.01866672933101654, 0.019437290728092194, 0.021316273137927055, 0.0186435766518116, 0.021174000576138496, 0.017424700781702995, 0.023265967145562172, 0.023358365520834923, 0.020439406856894493], 'val_accuracy': [0.12833333015441895, 0.24583332240581512, 0.3258333206176758, 0.3633333444595337, 0.5774999856948853, 0.8654167056083679, 0.8962500095367432, 0.981874942779541, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9991666674613953, 0.9375, 0.93687504529953, 0.9572916626930237, 0.9893749356269836, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [2.7340290546417236, 2.8055810928344727, 2.295931100845337, 1.7039175033569336, 1.172038197517395, 0.768437922000885, 0.5640077590942383, 0.40038761496543884, 0.3090380132198334, 0.2679595351219177, 0.2210586667060852, 0.18828433752059937, 0.1743573695421219, 0.16074742376804352, 0.15945427119731903, 0.1362324208021164, 0.12420540302991867, 0.14176863431930542, 0.2893632650375366, 0.30737385153770447, 0.21539990603923798, 0.1333278864622116, 0.07836674898862839, 0.06218231841921806, 0.0577055923640728, 0.05843019112944603, 0.05810825899243355, 0.05144156143069267, 0.04739461466670036, 0.04445986449718475, 0.043078456073999405, 0.041963979601860046, 0.03919271007180214, 0.037322066724300385, 0.0370989590883255, 0.03497115895152092, 0.03316230699419975, 0.03146181255578995, 0.0299831572920084, 0.028631985187530518, 0.027516387403011322, 0.02653118036687374, 0.02560560405254364, 0.02468036115169525, 0.023847321048378944, 0.023343391716480255, 0.022793719545006752, 0.022266864776611328, 0.02168678306043148, 0.021120021119713783, 0.02059292234480381, 0.02011851966381073, 0.019633930176496506, 0.019217977300286293, 0.018826698884367943, 0.018430160358548164, 0.01809961535036564, 0.01772528886795044, 0.017447853460907936, 0.017204945906996727], 'learning_rate': [0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 0.0005000000237487257, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-05, 4.999999873689376e-06, 4.999999873689376e-06, 4.999999873689376e-06, 4.999999873689376e-06, 4.999999873689376e-06, 4.999999873689376e-06, 4.999999873689376e-06, 4.999999873689376e-06, 4.999999873689376e-06, 4.999999873689376e-06], 'val_f1_macro_score': [0.07534254572113812, 0.17330742635576815, 0.24545140737439955, 0.31775110165595477, 0.5633106081320921, 0.8651063689840547, 0.9025651624408605, 0.9828655276624984, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9991087105715839, 0.8974358974358975, 0.8969746327443698, 0.9425740147416706, 0.9882148842545654, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# history 그리고 loss 시각화\n",
    "\n",
    "print (hist.history)\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.xlabel('number of epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend (['train loss', 'validation loss'])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a65de48d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:30:47.349672Z",
     "start_time": "2024-09-08T14:30:47.220997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABL2klEQVR4nO3deVxU9f4/8NdhYAaQXWQRUTRXNBDXcElTiqvlteXevOnNrWuZmhr5S+3m0iZmZlbX8mtltmt2My2XSgy6EYpLqAnikgoqghv7PvP5/THO0YlFhJlzhpnX8/HgMYeZM3M+nHjIq8/n/fl8JCGEABEREZGdcFK7AURERESWxHBDREREdoXhhoiIiOwKww0RERHZFYYbIiIisisMN0RERGRXGG6IiIjIrjir3QClGQwGnD9/Hp6enpAkSe3mEBERUQMIIVBUVITWrVvDyan+vhmHCzfnz59HaGio2s0gIiKiRsjOzkabNm3qPcfhwo2npycA483x8vJSuTVERETUEIWFhQgNDZX/jtfH4cKNaSjKy8uL4YaIiKiZaUhJCQuKiYiIyK4w3BAREZFdYbghIiIiu8JwQ0RERHaF4YaIiIjsCsMNERER2RWGGyIiIrIrDDdERERkVxhuiIiIyK4w3BAREZFdUTXc/Pzzzxg1ahRat24NSZLwzTff3PQ9iYmJ6NWrF3Q6HTp27Ih169ZZvZ1ERETUfKgabkpKShAZGYlVq1Y16PxTp07h3nvvxV133YW0tDTMnj0b//rXv/D9999buaVERETUXKi6ceaIESMwYsSIBp+/evVqtG/fHq+//joAoFu3bvjll1/wxhtvIDY21lrNpHqUl5eh6NJZCAEA4tojIAAI0zdW5CRJ0DhJ1x+dJGgk46MEQAig2mCAwQDoDQboIWAwAAYh4OOuhatzI/O9pAG07oBLC8BZa7Gfp7xKj0vFFRb7PDPVZdCUXrLOZ9sBSTL+zhj35JOuPQf5dxswHiv1u03UnLno3OAf1Fa16zerXcFTUlIQExNj9lxsbCxmz55d53sqKipQUXH9j0VhYaG1mqe4ar0Bqaev4IcjuTh4Nh9uLhp4ubrA09UZXm7XHq993ynQE5FtvBu0m+rN5BWWI+FoHo7/loSp559HgJTf9B+mOXNyBlzcARd3CK07SoQrLvWYjDZDH4Oz5ubhqVpvQPLJy/jmt3P4/sgFlFbqLdo8N5TjMc12PO78HbykMot+NhFRbY46d4P/87tVu36zCjcXLlxAYGCg2XOBgYEoLCxEWVkZ3NzcarwnPj4eL7zwglJNtLryKj2ST1zCjt8vYGdGLq6WVjX4vd2CvTAhuh1G9wyBm1bT4PcJIXAirxg/pOfix/RcpGXnY5DTYfyfywq0kCpQJTTQ21NtuiTBSQKcnZzgVFcW1FcB4loIMVQDFYVARSEkAB4Ayn9+Eb1/boO+HVphYMeWGNjRH50CPORwKYTA7+cKsem3c9hy8LxZb41W4wQLZFA4oxp/l3ZhmtPXcgCtFM4wwAIfTkRUD72TuvGiWYWbxpg/fz7i4uLk7wsLCxEaGqpiixonISMXXx84h8TMPJTc8H/2Pu4uuLtbIAZ3bgUhBArLq1FYVoXC8ioUXTsuKKvC3tNXkJFTiHlfH8aSbRl4uE8oHo1uh3YtW9S4lt4gcDyvCGlZ+Th4Nh8pJy/j9OVS+fV7nXZjpfYduKAaJSGD4P7oF3Bx9VLkPtRFCAG9QUAvjMNO1QYDBADnG4asTMNVpvNzCyuQnlOA9POFSM8pREZOEU5dKpE/M9jbFV9PG4Bg75qhGQBQXQlUlQCVpUBVGfZkZmP51gN4z+V1+EuF6FJxBDszumFnRi4AoJWnDgNva4k2vu7YceQCTuQVyx/l6+6CUZGtcX9UCKJCfZrWw2YwAOmbgF0vA1f+uHaBMGDYAmi7Pwg42VEQJSKb1F3l6zercBMUFITc3Fyz53Jzc+Hl5VVrrw0A6HQ66HQ6JZpnNd8dOo8Zn/8mfx/s7YrY7kG4p3sg+oX5NWjoI7+0Ehv3ncUnu88g60op3v/lFD5IPoUhnVthXP92qNYbkJadj7TsfBw+V1BjaETr7ISBt7XEky1+Qt/0tyFBAOH3o8WDawBn9e+vJElw1kg3/ELX3zMlSRKCvF0R5O2KYV2v9wYWV1TjaE4h5v73EE5eLMGkD/fiy6nR8HJ1qfkhzlrjl5svjuUWYfL3J1Bi6Io//O5Er6vb8U6vs9jY6gEkn7iEvaev4GJRBb5JOy+/XefshJjwQDwYFYLBnVpB29j6nxud/AnYuRjISTN+36IVcOezQO+JFq0NIiKyZZKwkco4SZKwadMm3H///XWeM3fuXGzbtg2HDx+Wnxs7diyuXLmCHTt2NOg6hYWF8Pb2RkFBAby81O1taIiKaj1iViQh+0oZRkW2xr8GtUdEE2pn9AaBpGN5+DjlDBIzL9Z5XgutBhFtfNCzrQ+iQn0w8LaWaJGyHEhaajyhz2PAyNcAp4YPbzUn2VdK8eC7v+JiUQWiO7TEusl9oXOu/We9WlKJ0auSkXWlFHd08MOngy7D+ctxgFcI8PQRQJJQXqXHgayr+PXEZZy5UorBnfzxlx5BtYemxvphAfDrW8ZjrQcwYCYQPR3QeVjuGkREKrmVv9+q9twUFxfjxIkT8venTp1CWloa/Pz80LZtW8yfPx/nzp3Dxx9/DACYOnUq/vOf/+DZZ5/F5MmTsWvXLnz55ZfYunWrWj+C1X26OwvZV8oQ4KnDqw/dDndt0/6TaZwkDOsaiGFdA3H6Ugk+3X0GWw/nwNddi55tfdDzWqC5rZUHNKaCE4Me2P4ssPd94/dD5gFD58EihSE2KtTPHesm9cXDq1OQ8sdl/L+Nh7ByTE95WMukSm/AtM8OIOtKKUL93PDOuN5w1hqMs6gKzwHnDwAhveHqosGA2/wx4DZ/6zQ4O/V6sOn3BHDn/wM8WlnnWkRENk7VcLNv3z7cdddd8vem2pgJEyZg3bp1yMnJQVZWlvx6+/btsXXrVjz99NN488030aZNG7z//vt2Ow28oKwKb+86DgCIu7tzk4PNn4X5t8Dz94Xj+fvC6z6pugLY9ARwZBMAydhb02+KRdthq7q39sbqR3tj0od7seXgeQR7u2L+yG5m57z4bTpS/riMFloN3h/fF34trg39dL7HeM8yvgVCelu3ofpq4LunjceRY4GRy6x7PSIiG2czw1JKaU7DUq/uOIp3E0+iY4AHdswa3KDaGovb9iyQ+n+Akwvw4P8BPR5Svg0q++/+s3hm40EAwKJR4Zg0sD0A4NPdZ/D8N79DkoA1j/bB3eE3zOT7/b/AV5MBv9uAp/Zbt5fr1/8AP/wbcPMFZuwDWlipd4iISEXNZliK6nY+vwxrfzkFAJj3l67qBBshjD0PAPDAaocMNgDwUO82uFBYjte+z8SL36UjyMsVPu5aLN5yBAAw554u5sEGADrdA2h0wJWTQF4GEFhP71hTFJwFflpiPL77RQYbIiIw3NisFT8eQ0W1Af3a+2F4twB1GlGQDRSdNy5S16XhK0nbo2lDb8P5/DJ8ticLszakwV2rQbVBYFRka0wbelvNN+g8gduGAce2GwOitcLN9rnG6eihdwA9/2mdaxARNTNc8MIGZeQU4r8HzgIAnhvZzSKrCjdK1h7jY1AEoK25Ho4jkSQJL47ugZhugaisNiC/tAq3h3hj2UMRdf/36TbK+JixxTqNytwOHP3OGD7vW8H1a4iIruG/hjZo6fajEAK4NyIYPUN91GtIVorxse0d6rXBhmicJLz9SBRiugWgW7AX1ozvXf9Kz11GGPegyv0duHzSso2pLAG2/T/jcfR0IFDtJbOIiGwHh6VsTPKJS0g6dhEuGgnPxnZRtzHZ13puGG5kbloN3p/Qt2Enu/sB7QcDfyQae1gGzrJcQ5JeNQ4bercFhsy13OcSEdkB9tzYEINBIH57BgBgXP/at0ZQTHkBkGssmEUow02jmYam0i04NJV7BEhZZTwe+ZrDDxkSEf0Zw40N+fbQefx+rhAeOmc8Nayjuo05uxeAMO5J5Bl4s7OpLl3vAyAB5/YBBeea/nkGA/BdnHGzzq73AV3+0vTPJCKyMww3NqKiWo/Xvs8EADw59Da09FB5v6asa1vVs9emaTyDgND+xuOjFlhJO+1TIHu3cXuFEa82/fOIiOwQw42N+CTlDM5eLUOglw6Try0SpypTuGG9TdNZatZUUS7w40Lj8V3PAd5tmvZ5RER2iuHGBgghsObnPwAAz9zdpf4ZOErQVwHn9huPGW6azhRuziQDJZca9xmlV4BPHgDKrgKBtxv3jyIiolox3NiAnIJy5BVVQOMk4a89W6vdHODCIaCqFHD1BvxVnrFlD3zbAcGRgDAAmdtu/f1l+cAn9wN5RwCPIODhjwANJzoSEdWF4cYGpJ8vBAB0CvCAq4vKvTbA9cX7Qu/gwnCW0thZU+WFwKcPATkHgRatgAlbgJa1rIhMREQy/uWyAUeuhZvw1jaykWe2qd6mv7rtsCfdRhsf/0g0TrNviIpi4POHjTOt3HyB8ZuBVuxJIyK6GYYbG3DkvPGPXXiwDYQbIcx7bsgyWnU2DvEZqoBjP9z8/MpS4It/GFeJdvUGHv2GqxATETUQw40NSM8x9tx0b+2tcksAXD0NFF8AnFyAkF5qt8a+yLOmNtd/XlU5sGEccPp/gNYT+OfXQOueVm8eEZG9YLhRWUFpFc5eLQNgI8NSpi0XWvcEXNxUbYrdCf+r8fH4TmPPTG2qK4GNE4CTuwCXFsC4jUCbPsq1kYjIDnDKhcpMvTZtfN3g7eaicmtww+J9rLexuKAIwKctkJ8FLAkGnF0BZ921x2tf1eVA/hnj8dj1QLtotVtNRNTssOdGZaZ6m+620GsDcLNMa5Ik8/VpqsuNxcXFucZAcynT+KjRAv/4HGh/p3ptJSJqxthzozLTNPDwYBuotym7CuSlG49ZTGwdA2YAvSca1xGqLgeqK8wfq8qBgG6Ad4jaLSUiarYYblR2vZjYBnpusvcaH/1uAzxaqdsWe6bzMH4REZFVcFhKReVVehzPKwYAdA+xhXDD/aSIiKj5Y7hR0bHcIugNAr7uLgjyclW7Odwsk4iI7ALDjYpM9TbdW3tDkiR1G1NdeX2zTNbbEBFRM8ZwoyKb2nbhwiFjQaubH+DfSe3WEBERNRrDjYpsqpj4xvVt1O5FIiIiagKGG5XoDQIZNhVuUoyPrLchIqJmjuFGJacvl6C0Ug9XFye091d5WrAQXLyPiIjsBsONSkzFxF2DvKBxUnkY6MofQMlF48q4wT3VbQsREVETMdyoxKaKiU31Nq17AS42MCWdiIioCRhuVGJTxcTy4n3cLJOIiJo/hhsVCCGQLm+YaQN7SmVdq7fh+jZERGQHGG5UkFdUgUvFlXCSgC6Bnuo2pvSKcTdqwDgNnIiIqJljuFGBqZj4tlYecNNq1G3MiQTjo39noEVLddtCRERkAQw3KjhybUhK9WLi8kJg5yLjcfhoddtCRERkIQw3Kjhy3kaKiRNeAArPAb7tgUFx6raFiIjIQhhuVHB9ppSKxcRnUoC97xuPR70JaN3VawsREZEFMdworLC8CmculwIAwoNV6rmpKge+nWk8jnoU6DBEnXYQERFZAcONwo7mFAEAWnu7wreFVp1G/G85cOkY4BEI3POSOm0gIiKyEoYbhaleTJx7BPjlDePxyNcAN1912kFERGQlDDcKu77tggr1NgY9sOUpwFANdL2PM6SIiMguMdwoLF3NmVJ7VgPn9gM6b2DkcuWvT0REpACGGwVVVhtwPM9Yc6N4MfHV08Cul43H97wIeAUre30iIiKFMNwo6HheEar0Al6uzmjj66bchYUAvp0NVJUC7QYBUeOVuzYREZHCGG4UdL3exguSJCl34YPrgT9+AjQ64K9vAU78z05ERPaLf+UUdL3eRsFiYiGAHxcaj4fOA1repty1iYiIVMBwoyBViokrCoGSPONx/6nKXZeIiEglDDcKMRiEvO2ComvclF01Pjq7cosFIiJyCAw3Csm6UoriimponZ1wWysP5S5sCjdcrI+IiBwEw41CTL02XQI94aJR8LaX5RsfGW6IiMhBMNwoRLXF+0w9N64+yl6XiIhIJQw3CrlUXAEACPFRcH0bACjPNz6y54aIiBwEw41CSiv1AAA3rUbZC8s1Nz7KXpeIiEglDDcKKasyhht3rbPCF2ZBMRERORaGG4WUVZrCjdI9N/nGR/bcEBGRg2C4UUhpZTUAwNVFpWEpFhQTEZGDYLhRSKnqPTccliIiIsfAcKOQ6zU3CocbzpYiIiIHw3CjEM6WIiIiUgbDjULKK9WaLZVvfGTPDREROQiGGwUIIVCqxrBUdQVQVWI8ZrghIiIHwXCjgEq9AXqDAKDwbClTrw0kQOet3HWJiIhUxHCjANMaN4DCPTemYmJXb8CJ/6mJiMgx8C+eAkzFxC4aSeEdwVlMTEREjofhRgHyTCm1FvBjvQ0RETkQhhsFlKu2r1S+8ZHhhoiIHAjDjQLUW52YWy8QEZHjUT3crFq1CmFhYXB1dUX//v2Rmppa7/krV65Ely5d4ObmhtDQUDz99NMoLy9XqLWNo9q+UlydmIiIHJCq4WbDhg2Ii4vDokWLcODAAURGRiI2NhZ5eXm1nv/5559j3rx5WLRoETIyMvDBBx9gw4YNeO655xRu+a1Rb0dw1twQEZHjUTXcrFixAlOmTMGkSZMQHh6O1atXw93dHWvXrq31/F9//RUDBw7E2LFjERYWhnvuuQePPPLITXt71MatF4iIiJSjWriprKzE/v37ERMTc70xTk6IiYlBSkpKre8ZMGAA9u/fL4eZP/74A9u2bcPIkSPrvE5FRQUKCwvNvpSmyurEAAuKiYjIISk8fee6S5cuQa/XIzAw0Oz5wMBAHD16tNb3jB07FpcuXcKgQYMghEB1dTWmTp1a77BUfHw8XnjhBYu2/Vapt68UC4qJiMjxqF5QfCsSExOxZMkSvPPOOzhw4AC+/vprbN26FS+99FKd75k/fz4KCgrkr+zsbAVbbKT+sBR7boiIyHGo1nPj7+8PjUaD3Nxcs+dzc3MRFBRU63sWLFiARx99FP/6178AALfffjtKSkrw+OOP49///jecatliQKfTQafTWf4HuAWlVcbZUoov4sfZUkRE5IBU67nRarXo3bs3EhIS5OcMBgMSEhIQHR1d63tKS0trBBiNxhgYhBDWa2wTqTJbSogbam58lLsuERGRylTruQGAuLg4TJgwAX369EG/fv2wcuVKlJSUYNKkSQCA8ePHIyQkBPHx8QCAUaNGYcWKFYiKikL//v1x4sQJLFiwAKNGjZJDji1SZViqoggQ1zbsZM8NERE5EFXDzZgxY3Dx4kUsXLgQFy5cQM+ePbFjxw65yDgrK8usp+b555+HJEl4/vnnce7cObRq1QqjRo3CK6+8otaP0CByz42Sw1KmehtnV8DFTbnrEhERqUwStjyeYwWFhYXw9vZGQUEBvLy8FLnm5HV7setoHpY9FIGH+4Yqck2cTwPWDAE8goA5mcpck4iIyEpu5e93s5ot1VyZtl9QdFiKxcREROSgGG4UYBqWUnS2FFcnJiIiB8VwowBVdgXnGjdEROSgGG4UoMpsKW69QEREDorhRgFlVSpsv8CtF4iIyEEx3ChAlUX8WFBMREQOiuHGygwGIffcKDssxYJiIiJyTAw3VlZerZePlZ0tlX/touy5ISIix8JwY2WmYmJArXDjo9w1iYiIbADDjZWZ6m1cXZzg5CQpeGFTQTF7boiIyLEw3FjZ9TVuFN7GizU3RETkoBhurEwuJlZySKq6EqgqMR6z5oaIiBwMw42VmfaVUmUaOAC4eit3XSIiIhvAcGNlZWquTuzqDTgpeF0iIiIbwHBjZaWqbprJISkiInI8DDdWpsrqxNx6gYiIHBjDjZVdr7lRcLYUt14gIiIHxnBjZWVVBgBqbb3AcENERI6H4cbKytSYLcU1boiIyIEx3FiZOgXF+cZH9twQEZEDYrixslI1dwRnQTERETkghhsrU2W2FAuKiYjIgTHcWJlptpSbkrOlWFBMREQOjOHGykyzpdxVWcTPR7lrEhER2QiGGytTZ7ZUvvGRPTdEROSAGG6szDRbylWpcCMEh6WIiMihMdxYmVxQrNSwVEURIIzX5GwpIiJyRAw3VlYqz5ZSqKDYNFNKowNc3JS5JhERkQ1huLGy67OlFOq5ubGYWJKUuSYREZENYbixsnLTbCnFww3rbYiIyDEx3FhRtd6ASr3S4Sbf+MhwQ0REDorhxopMWy8AgKtSBcXceoGIiBwcw40VmWZKOUmAzlmhW82tF4iIyMEx3FjRjTOlJKWKe1lzQ0REDo7hxooUnykFcOsFIiJyeAw3VlRepcKO4CwoJiIiB8dwY0WmYSk3NTbNZEExERE5KIYbK5LDDXtuiIiIFMNwY0XyvlJKhhvOliIiIgfHcGNF14elFNpXCmBBMREROTyGGysyzZZSrOdGXwVUFhuP2XNDREQOiuHGihSfLWWqtwEAV29lrklERGRjGG6sSPGCYtOQlM4bcFKwzoeIiMiGMNxYkeJTweViYh9lrkdERGSDGG6sSPHZUiwmJiIiYrixJtOu4G5ahWZLcV8pIiIihhtrKlN6thQX8CMiImK4saZStYaluPUCERE5MIYbKyqrUqugmD03RETkuBhurKhMrangDDdEROTAGG6sSLVhKc6WIiIiB8ZwY0WK7y3FgmIiIiKGG2tSfrYUh6WIiIgYbqxECCGvc8PZUkRERMphuLGSimoDhDAeK1JQLARnSxEREYHhxmpMM6UAhaaCVxYDhuprF/Sx/vWIiIhsFMONlZiGpLQaJzhrFLjNpmJijRZwcbf+9YiIiGwUw42VmIqJVVnjRpKUuSYREZENYrixEm69QEREpA6GGyspVXp1YhYTExERAWC4sZoytaaBM9wQEZGDY7ixEnlfKaU2zeTWC0RERAAYbqzm+rAUt14gIiJSEsONlchbLyjdc8OCYiIicnAMN1ai+GwpFhQTEREBYLixGsVnS7GgmIiICIANhJtVq1YhLCwMrq6u6N+/P1JTU+s9Pz8/H9OnT0dwcDB0Oh06d+6Mbdu2KdTahitXbbaUjzLXIyIislEKVbvWbsOGDYiLi8Pq1avRv39/rFy5ErGxscjMzERAQECN8ysrK3H33XcjICAAX331FUJCQnDmzBn4+Pgo3/ibKFV8tlSB8ZE9N0RE5OBUDTcrVqzAlClTMGnSJADA6tWrsXXrVqxduxbz5s2rcf7atWtx5coV/Prrr3BxcQEAhIWFKdnkBlN+thSHpYiIiAAVh6UqKyuxf/9+xMTEXG+MkxNiYmKQkpJS63u2bNmC6OhoTJ8+HYGBgejRoweWLFkCvV5f6/kAUFFRgcLCQrMvJZRVXZstpcSwlL4KqCwyHnO2FBEROTjVws2lS5eg1+sRGBho9nxgYCAuXLhQ63v++OMPfPXVV9Dr9di2bRsWLFiA119/HS+//HKd14mPj4e3t7f8FRoaatGfoy6KFhSXF1w/dvW2/vWIiIhsmOoFxbfCYDAgICAAa9asQe/evTFmzBj8+9//xurVq+t8z/z581FQUCB/ZWdnK9JWRaeCm4akdF6ARtWRRiIiItWp9pfQ398fGo0Gubm5Zs/n5uYiKCio1vcEBwfDxcUFGs31wNCtWzdcuHABlZWV0Gq1Nd6j0+mg0+ks2/gGUHS2lLw6sY/1r0VERGTjVOu50Wq16N27NxISEuTnDAYDEhISEB0dXet7Bg4ciBMnTsBgMMjPHTt2DMHBwbUGGzWZem5clZgtxWJiIiIimarDUnFxcXjvvffw0UcfISMjA08++SRKSkrk2VPjx4/H/Pnz5fOffPJJXLlyBbNmzcKxY8ewdetWLFmyBNOnT1frR6hTmTwspUDnGLdeICIikqlaoDFmzBhcvHgRCxcuxIULF9CzZ0/s2LFDLjLOysqCk9P1/BUaGorvv/8eTz/9NCIiIhASEoJZs2Zh7ty5av0IdSqtVHC2FLdeICIikjUq3Dz00EPo169fjVCxbNky7N27Fxs3bmzwZ82YMQMzZsyo9bXExMQaz0VHR2P37t231F41KLqIH4eliIiIZI0alvr5558xcuTIGs+PGDECP//8c5Mb1dzpDQIV1ca6IEVnS7GgmIiIqHHhpri4uNYCXhcXF8UWybNlpplSAGtuiIiIlNaocHP77bdjw4YNNZ5fv349wsPDm9yo5s40JAUAri4K1GyXXDQ+tmhl/WsRERHZuEZ1KyxYsAAPPvggTp48iWHDhgEAEhIS8MUXX9xSvY29Kruh3kaSJOtfsPhauPEIrP88IiIiB9CocDNq1Ch88803WLJkCb766iu4ubkhIiICO3fuxJAhQyzdxmanVMl9pQCg+NpCiB41d1InIiJyNI0uCLn33ntx7733WrItdkPRfaUMeqD0kvGY4YaIiKhxNTd79+7Fnj17ajy/Z88e7Nu3r8mNau7KlNxXqvQyIAwAJMDd3/rXIyIisnGNCjfTp0+vdQPKc+fO2eRqwUqTa26UmCllGpJq4c9NM4mIiNDIcJOeno5evXrVeD4qKgrp6elNblRzV2raNFOJBfzkehsWExMREQGNDDc6na7Gbt4AkJOTA2dn9h6UXdt6QZGam2JOAyciIrpRo8LNPffcg/nz56OgoEB+Lj8/H8899xzuvvtuizWuuVK0oJg9N0RERGYa1c2yfPly3HnnnWjXrh2ioqIAAGlpaQgMDMQnn3xi0QY2R6Zwo8ywVJ7xkTOliIiIADQy3ISEhODQoUP47LPPcPDgQbi5uWHSpEl45JFH4OLiYuk2NjuKzpbiGjdERERmGl0g06JFCwwaNAht27ZFZWUlAGD79u0AgL/+9a+WaV0zVVal4GypElPPDYeliIiIgEaGmz/++AMPPPAADh8+DEmSIIQw22ZAr9fX8277V6pozw2HpYiIiG7UqILiWbNmoX379sjLy4O7uzt+//13JCUloU+fPkhMTLRwE5sfebaUklPBWzDcEBERAY3suUlJScGuXbvg7+8PJycnaDQaDBo0CPHx8Zg5cyZ+++03S7ezWVFstlR1JVB21XjMYSkiIiIAjey50ev18PT0BAD4+/vj/PnzAIB27dohMzPTcq1rpkw1N1Yfliq5tsaNkzPg5mvdaxERETUTjeq56dGjBw4ePIj27dujf//+WLZsGbRaLdasWYMOHTpYuo3NjmI1NzcOSTk1KqcSERHZnUaFm+effx4lJSUAgBdffBH33XcfBg8ejJYtW2LDhg0WbWBzpNjeUqaeGw+uTkxERGTSqL++sbGx8nHHjh1x9OhRXLlyBb6+vmazphyVYsNSXJ2YiIioBot1Lfj5+Vnqo5q9UqVmS3EBPyIiohpYqGEFis2WMq1xw2ngREREMoYbK1Bs+4Virk5MRET0Zww3FlZZbUC1QQAA3F2sXFDM1YmJiIhqYLixMFMxMaDEsBRrboiIiP6M4cbCTENSzk4StM5Wvr3yVHAOSxEREZkw3FiYYjOlKkuBikLjMXtuiIiIZAw3FqbYTKmSa/U2zq6Azsu61yIiImpGGG4sTLkF/K4NSbUIALhwIhERkYzhxsJKldp6gcXEREREtWK4sTDl1rjh1gtERES1YbixsLIqY0Gx1cMNN80kIiKqFcONhZmGpVwV21eKPTdEREQ3YrixMOW3XmDNDRER0Y0YbiyslDU3REREqmK4sTB5tpRS+0pxR3AiIiIzDDcWVq7EOjdCcFiKiIioDgw3FiZvv2DNcFNRBFSXGY8ZboiIiMww3FjY9WEpK4Yb0zRwrQegbWG96xARETVDDDcWpshsKa5OTEREVCeGGwtTZONMzpQiIiKqE8ONhZXKBcVWnC0lb5rJ1YmJiIj+jOHGwsoVHZZizw0REdGfMdxYWGmVArOlGG6IiIjqxHBjYWVKzJbiGjdERER1YrixMEW2XyhhuCEiIqoLw40FCSFQVqXEbCmGGyIiorow3FhQeZUBQhiPrTZbymzrBdbcEBER/RnDjQWZem0AK9bclF0FDFXGY04FJyIiqoHhxoJM+0rpnJ2gcZKscxFTr42rD+Css841iIiImjGGGwsq4+rEREREqmO4sSB5ppQSm2aymJiIiKhWDDcWpOy+Ugw3REREtWG4saCya6sTW3dfKQ5LERER1YfhxoLKKg0ArN1zw2EpIiKi+jDcWJBptpQim2a2YLghIiKqDcONBcmrEyuyrxSHpYiIiGrDcGNBLCgmIiJSH8ONBVl900yDHii9ZDxmuCEiIqoVw40FlVVaebZU6WVAGABIgLu/da5BRETUzDHcWJA8LGWtmhu5mNgf0FhxujkREVEzxnBjQaaCYqsNS5mKiTlTioiIqE4MNxZk9b2l5JlSDDdERER1YbixIMWGpTgNnIiIqE4MNxZUJs+WslI9DDfNJCIiuimGGwsqrbLyCsVc44aIiOimbCLcrFq1CmFhYXB1dUX//v2RmpraoPetX78ekiTh/vvvt24DG8jqi/hxWIqIiOimVA83GzZsQFxcHBYtWoQDBw4gMjISsbGxyMvLq/d9p0+fxpw5czB48GCFWnpz5dZexI8FxURERDelerhZsWIFpkyZgkmTJiE8PByrV6+Gu7s71q5dW+d79Ho9xo0bhxdeeAEdOnSo9/MrKipQWFho9mUtpdbeW4pTwYmIiG5K1XBTWVmJ/fv3IyYmRn7OyckJMTExSElJqfN9L774IgICAvDYY4/d9Brx8fHw9vaWv0JDQy3S9tpYdViquhIou2I85rAUERFRnVQNN5cuXYJer0dgoPkf68DAQFy4cKHW9/zyyy/44IMP8N577zXoGvPnz0dBQYH8lZ2d3eR210ZvEKisNgCw0mwp00wpJ2fAzdfyn09ERGQnmtUa/kVFRXj00Ufx3nvvwd+/YXsr6XQ66HQ6K7cMKL22rxRgpZqbEtOQVCvASfXRRCIiIpularjx9/eHRqNBbm6u2fO5ubkICgqqcf7Jkydx+vRpjBo1Sn7OYDD2ljg7OyMzMxO33XabdRtdB9MaN5IE6JytED5YTExERNQgqnYBaLVa9O7dGwkJCfJzBoMBCQkJiI6OrnF+165dcfjwYaSlpclff/3rX3HXXXchLS3NqvU0NyPvK+WigSRJlr8Ap4ETERE1iOrDUnFxcZgwYQL69OmDfv36YeXKlSgpKcGkSZMAAOPHj0dISAji4+Ph6uqKHj16mL3fx8cHAGo8rzTrr3HDnhsiIqKGUD3cjBkzBhcvXsTChQtx4cIF9OzZEzt27JCLjLOysuDUDGpMFAs3nAZORERUL9XDDQDMmDEDM2bMqPW1xMTEet+7bt06yzeoEQI8dXhiSAd46qx0SzksRURE1CA2EW7sQaifO+aP6Ga9C3DTTCIiogax/fEeMuKmmURERA3CcNNcyAXFHJYiIiKqD8NNc1BVBlRc2xOLPTdERET1YrhpDky9Ns6ugM5L3bYQERHZOIab5uDGaeDWWCCQiIjIjjDcNAfHdhgffdup2w4iIqJmgOHG1hXnAbvfMR73n6puW4iIiJoBhhtb9/NrQFUpENIH6Hqv2q0hIiKyeQw3tuzqaWDfh8bj4QtZb0NERNQADDe2LHEpYKgCOtwFdBiidmuIiIiaBYYbW5WbDhxcbzwevlDdthARETUjDDe2atfLAATQ7a9ASC+1W0NERNRsMNzYouy9QOZWQHIChi1QuzVERETNCsONrRECSHjBeNxzLNCqs7rtISIiamYYbmzNyV3A6f8BGi0wZJ7arSEiImp2GG5sicFwvdem778An1B120NERNQMMdzYkozNQM5BQOsBDH5G7dYQERE1Sww3tkJffW2GFIDoGUALf3XbQ0RE1Ewx3NiKtM+AyycANz8gerrarSEiImq2GG5sgRDA/143Ht85B3D1Urc9REREzRjDjS248geQf8Y4Q6r3JLVbQ0RE1Kwx3NiC078YH0P6AFp3ddtCRETUzDHc2IIzycbHsIHqtoOIiMgOMNyoTYjrPTdhg9RtCxERkR1guFHb1dNA4TnAyQVo00/t1hARETV7DDdqk+tterHehoiIyAIYbtQm19twSIqIiMgSGG7UZuq5acdiYiIiIktguFHT1TNAQTbg5AyE9le7NURERHaB4UZNpl6b1lGAzkPdthAREdkJhhs1sd6GiIjI4hhu1CTX2zDcEBERWQrDjVrys437SUkaoC3rbYiIiCyF4UYtpiGp1j0BnaeqTSEiIrInDDdqOf0/4yOngBMREVkUw41aTpuKiQer2w4iIiI7w3CjhoJzwNVTgOQEtL1D7dYQERHZFYYbNZjqbYIjAVcvddtCRERkZxhu1MB6GyIiIqthuFED622IiIishuFGaYU5wJWTACTW2xAREVkBw43STPU2QbcDbj6qNoWIiMgeMdwozbTlAoekiIiIrILhRmlyuGExMRERkTUw3CipKBe4fBzGeptotVtDRERklxhulHTmWq9NYA/A3U/dthAREdkphhslyVPAB6nbDiIiIjvGcKMk1tsQERFZHcONUoovApcyjcdcmZiIiMhqGG6UYqq3CejOehsiIiIrYrhRStZu4yOHpIiIiKyK4UYpuUeMj8GR6raDiIjIzjHcKOXiUeNjQDd120FERGTnGG6UUHIZKLloPPbvom5biIiI7BzDjRIuZhgffdoCOg9120JERGTnGG6UkHct3LTikBQREZG1MdwowRRuWG9DRERkdQw3SmAxMRERkWIYbqxNiBuGpbqq2xYiIiIH4Kx2A+xeyUWg7AoACfDvrHZriIisSq/Xo6qqSu1mUDOl1Wrh5NT0fheGG2vLSzc++oYBWndVm0JEZC1CCFy4cAH5+flqN4WaMScnJ7Rv3x5arbZJn8NwY215pnqbcHXbQURkRaZgExAQAHd3d0iSpHaTqJkxGAw4f/48cnJy0LZt2yb9DjHcWJtpjZsA1tsQkX3S6/VysGnZsqXazaFmrFWrVjh//jyqq6vh4uLS6M9hQbG1mXpuuMYNEdkpU42NuzuH3qlpTMNRer2+SZ/DcGNNQrDnhogcBoeiqKks9TtkE+Fm1apVCAsLg6urK/r374/U1NQ6z33vvfcwePBg+Pr6wtfXFzExMfWer6qiHKC8AJA0QMtOareGiIjIIagebjZs2IC4uDgsWrQIBw4cQGRkJGJjY5GXl1fr+YmJiXjkkUfw008/ISUlBaGhobjnnntw7tw5hVveAKb1bfw6AC6u6raFiIisLiwsDCtXrlS7GQ5P9XCzYsUKTJkyBZMmTUJ4eDhWr14Nd3d3rF27ttbzP/vsM0ybNg09e/ZE165d8f7778NgMCAhIaHW8ysqKlBYWGj2pRh5ZWIOSRER2aKhQ4di9uzZFvu8vXv34vHHH7fY51HjqBpuKisrsX//fsTExMjPOTk5ISYmBikpKQ36jNLSUlRVVcHPz6/W1+Pj4+Ht7S1/hYaGWqTtDcINM4mImj0hBKqrqxt0bqtWrVhYbQNUDTeXLl2CXq9HYGCg2fOBgYG4cOFCgz5j7ty5aN26tVlAutH8+fNRUFAgf2VnZze53Q3GnhsiclBCCJRWVqvyJYRoUBsnTpyIpKQkvPnmm5AkCZIk4fTp00hMTIQkSdi+fTt69+4NnU6HX375BSdPnsTo0aMRGBgIDw8P9O3bFzt37jT7zD8PS0mShPfffx8PPPAA3N3d0alTJ2zZsqXedn3yySfo06cPPD09ERQUhLFjx9Yo1Thy5Ajuu+8+eHl5wdPTE4MHD8bJkyfl19euXYvu3btDp9MhODgYM2bMaNA9sRfNep2bpUuXYv369UhMTISra+01LTqdDjqdTuGW4dqeUlzAj4gcU1mVHuELv1fl2ukvxsJde/M/b2+++SaOHTuGHj164MUXXwRg7Hk5ffo0AGDevHlYvnw5OnToAF9fX2RnZ2PkyJF45ZVXoNPp8PHHH2PUqFHIzMxE27Zt67zOCy+8gGXLluG1117D22+/jXHjxuHMmTN1jjhUVVXhpZdeQpcuXZCXl4e4uDhMnDgR27ZtAwCcO3cOd955J4YOHYpdu3bBy8sLycnJcu/Su+++i7i4OCxduhQjRoxAQUEBkpOTb+UWNnuqhht/f39oNBrk5uaaPZ+bm4ugoKB637t8+XIsXboUO3fuREREhDWb2TgFZ4HKIsDJGfC7Te3WEBHRn3h7e0Or1cLd3b3Wvzkvvvgi7r77bvl7Pz8/REZGyt+/9NJL2LRpE7Zs2VJvz8jEiRPxyCOPAACWLFmCt956C6mpqfjLX/5S6/mTJ0+Wjzt06IC33noLffv2RXFxMTw8PLBq1Sp4e3tj/fr18kJ3nTtf37vw5ZdfxjPPPINZs2bJz/Xt2/dmt8OuqBputFotevfujYSEBNx///0AIBcH1/eLsmzZMrzyyiv4/vvv0adPH4Vae4tMQ1ItOwLOTdsjg4iouXFz0SD9xVjVrm0Jf/77UlxcjMWLF2Pr1q3IyclBdXU1ysrKkJWVVe/n3Pg/4C1atICXl1edM4IBYP/+/Vi8eDEOHjyIq1evwmAwAACysrIQHh6OtLQ0DB48uNYVfPPy8nD+/HkMHz78Vn5Uu6P6sFRcXBwmTJiAPn36oF+/fli5ciVKSkowadIkAMD48eMREhKC+Ph4AMCrr76KhQsX4vPPP0dYWJhcm+Ph4QEPDw/Vfo4a5GJi1tsQkeORJKlBQ0O2rEWLFmbfz5kzBz/++COWL1+Ojh07ws3NDX/7299QWVlZ7+f8OYRIkiQHlj8rKSlBbGwsYmNj8dlnn6FVq1bIyspCbGysfB03N7c6r1Xfa45E9d+8MWPG4OLFi1i4cCEuXLiAnj17YseOHXKRcVZWltn25++++y4qKyvxt7/9zexzFi1ahMWLFyvZ9PrJxcScKUVEZKu0Wm2Dl/pPTk7GxIkT8cADDwAw9uSY6nMs5ejRo7h8+TKWLl0qz+7dt2+f2TkRERH46KOPUFVVVSM4eXp6IiwsDAkJCbjrrrss2rbmRPVwAwAzZsyocxgqMTHR7HtL/yJZTV668ZHhhojIZoWFhWHPnj04ffo0PDw86izyBYBOnTrh66+/xqhRoyBJEhYsWFBnD0xjtW3bFlqtFm+//TamTp2K33//HS+99JLZOTNmzMDbb7+Nf/zjH5g/fz68vb2xe/du9OvXD126dMHixYsxdepUBAQEYMSIESgqKkJycjKeeuopi7bVlqm+iJ9dMhiAi5nGY65xQ0Rks+bMmQONRoPw8HB5CKguK1asgK+vLwYMGIBRo0YhNjYWvXr1smh7WrVqhXXr1mHjxo0IDw/H0qVLsXz5crNzWrZsiV27dqG4uBhDhgxB79698d5778m9OBMmTMDKlSvxzjvvoHv37rjvvvtw/Phxi7bT1kmioQsC2InCwkJ4e3ujoKAAXl5e1rnI1dPAm5GARgs8lwNobKKDjIjIKsrLy3Hq1Cm0b9++zmU5iBqivt+lW/n7zZ4bazCtb9OyE4MNERGRwhhurOHitZlSrLchIiJSHMONNZimgXPbBSIiIsUx3FgDN8wkIiJSDcONpRn0wKVjxmMOSxERESmO4cbSrp4GqssBZ1fAN0zt1hARETkchhtLM61M7N8ZcLLM/iZERETUcAw3lsaViYmIiFTFcGNppjVuuGEmERGRKhhuLI0bZhIROZSwsDCsXLlS/l6SJHzzzTd1nn/69GlIkoS0tLQmXddSn2OPuHyuJemrOVOKiMjB5eTkwNfX16KfOXHiROTn55uFptDQUOTk5MDf39+i17IHDDeWdPUUoK8EXNwB77Zqt4aIiFQQFBSkyHU0Go1i12puOCxlSaZi4lZdACfeWiJyYEIAlSXqfDVwP+g1a9agdevWMBgMZs+PHj0akydPBgCcPHkSo0ePRmBgIDw8PNC3b1/s3Lmz3s/987BUamoqoqKi4Orqij59+uC3334zO1+v1+Oxxx5D+/bt4ebmhi5duuDNN9+UX1+8eDE++ugjbN68GZIkQZIkJCYm1joslZSUhH79+kGn0yE4OBjz5s1DdXW1/PrQoUMxc+ZMPPvss/Dz80NQUBAWL15c78+zd+9e3H333fD394e3tzeGDBmCAwcOmJ2Tn5+PJ554AoGBgXB1dUWPHj3w3Xffya8nJydj6NChcHd3h6+vL2JjY3H16tV6r9sU7LmxJLmYmENSROTgqkqBJa3VufZz5wFti5ue9ve//x1PPfUUfvrpJwwfPhwAcOXKFezYsQPbtm0DABQXF2PkyJF45ZVXoNPp8PHHH2PUqFHIzMxE27Y376EvLi7Gfffdh7vvvhuffvopTp06hVmzZpmdYzAY0KZNG2zcuBEtW7bEr7/+iscffxzBwcF4+OGHMWfOHGRkZKCwsBAffvghAMDPzw/nz583+5xz585h5MiRmDhxIj7++GMcPXoUU6ZMgaurq1mA+eijjxAXF4c9e/YgJSUFEydOxMCBA3H33XfX+jMUFRVhwoQJePvttyGEwOuvv46RI0fi+PHj8PT0hMFgwIgRI1BUVIRPP/0Ut912G9LT06HRGJdDSUtLw/DhwzF58mS8+eabcHZ2xk8//QS9Xn/T+9dYDDeWdJF7ShERNRe+vr4YMWIEPv/8czncfPXVV/D398ddd90FAIiMjERkZKT8npdeegmbNm3Cli1bMGPGjJte4/PPP4fBYMAHH3wAV1dXdO/eHWfPnsWTTz4pn+Pi4oIXXnhB/r59+/ZISUnBl19+iYcffhgeHh5wc3NDRUVFvcNQ77zzDkJDQ/Gf//wHkiSha9euOH/+PObOnYuFCxfC6dqIQkREBBYtWgQA6NSpE/7zn/8gISGhznAzbNgws+/XrFkDHx8fJCUl4b777sPOnTuRmpqKjIwMdO7cGQDQoUMH+fxly5ahT58+eOedd+TnunfvftN71xQMN5Zk6rkJCFe3HUREanNxN/agqHXtBho3bhymTJmCd955BzqdDp999hn+8Y9/yEGguLgYixcvxtatW5GTk4Pq6mqUlZUhKyurQZ+fkZGBiIgIuLq6ys9FR0fXOG/VqlVYu3YtsrKyUFZWhsrKSvTs2bPBP4fpWtHR0ZAkSX5u4MCBKC4uxtmzZ+WepoiICLP3BQcHIy8vr87Pzc3NxfPPP4/ExETk5eVBr9ejtLRUvgdpaWlo06aNHGz+LC0tDX//+99v6WdpKoYbS6muBC4fNx5zjRsicnSS1KChIbWNGjUKQghs3boVffv2xf/+9z+88cYb8utz5szBjz/+iOXLl6Njx45wc3PD3/72N1RWVlqsDevXr8ecOXPw+uuvIzo6Gp6ennjttdewZ88ei13jRi4uLmbfS5JUo+7oRhMmTMDly5fx5ptvol27dtDpdIiOjpbvgZubW73Xu9nr1sCqV0u5chIwVANaT8C7jdqtISKiBnB1dcWDDz6Izz77DF988QW6dOmCXr16ya8nJydj4sSJeOCBB3D77bcjKCgIp0+fbvDnd+vWDYcOHUJ5ebn83O7du83OSU5OxoABAzBt2jRERUWhY8eOOHnypNk5Wq32pjUq3bp1Q0pKCsQNBdXJycnw9PREmzaN/7uUnJyMmTNnYuTIkejevTt0Oh0uXbokvx4REYGzZ8/i2LFjtb4/IiICCQkJjb5+YzDcWEpxHuDma5wpdUOXIBER2bZx48Zh69atWLt2LcaNG2f2WqdOnfD1118jLS0NBw8exNixY+vt5fizsWPHQpIkTJkyBenp6di2bRuWL19e4xr79u3D999/j2PHjmHBggXYu3ev2TlhYWE4dOgQMjMzcenSJVRVVdW41rRp05CdnY2nnnoKR48exebNm7Fo0SLExcXJw2yN0alTJ3zyySfIyMjAnj17MG7cOLPemCFDhuDOO+/EQw89hB9//BGnTp3C9u3bsWPHDgDA/PnzsXfvXkybNg2HDh3C0aNH8e6775oFJEtjuLGUDkOAZ08B4zer3RIiIroFw4YNg5+fHzIzMzF27Fiz11asWAFfX18MGDAAo0aNQmxsrFnPzs14eHjg22+/xeHDhxEVFYV///vfePXVV83OeeKJJ/Dggw9izJgx6N+/Py5fvoxp06aZnTNlyhR06dIFffr0QatWrZCcnFzjWiEhIdi2bRtSU1MRGRmJqVOn4rHHHsPzzz9/C3ejpg8++ABXr15Fr1698Oijj2LmzJkICAgwO+e///0v+vbti0ceeQTh4eF49tln5Z6mzp0744cffsDBgwfRr18/REdHY/PmzXB2tl5ljCREAxcEsBOFhYXw9vZGQUEBvLy81G4OEVGzV15ejlOnTqF9+/ZmhbNEt6q+36Vb+fvNnhsiIiKyKww3REREZFcYboiIiMiuMNwQERGRXWG4ISIii3Cw+SlkBZb6HWK4ISKiJjGteFtaWqpyS6i5M616bNp0s7G4/QIRETWJRqOBj4+PvD+Ru7u72f5GRA1hMBhw8eJFuLu7N3kNHIYbIiJqMtNu1fVtwEh0M05OTmjbtm2TwzHDDRERNZkkSQgODkZAQECtWwMQNYRWq23SVhEmDDdERGQxGo2myfUSRE3FgmIiIiKyKww3REREZFcYboiIiMiuOFzNjWmBoMLCQpVbQkRERA1l+rvdkIX+HC7cFBUVAQBCQ0NVbgkRERHdqqKiInh7e9d7jiQcbL1sg8GA8+fPw9PT0+KLTBUWFiI0NBTZ2dnw8vKy6GfbI96vW8d7dmt4v24d79mt4f26NU25X0IIFBUVoXXr1jedLu5wPTdOTk5o06aNVa/h5eXFX/JbwPt163jPbg3v163jPbs1vF+3prH362Y9NiYsKCYiIiK7wnBDREREdoXhxoJ0Oh0WLVoEnU6ndlOaBd6vW8d7dmt4v24d79mt4f26NUrdL4crKCYiIiL7xp4bIiIisisMN0RERGRXGG6IiIjIrjDcEBERkV1huLGQVatWISwsDK6urujfvz9SU1PVbpLN+PnnnzFq1Ci0bt0akiThm2++MXtdCIGFCxciODgYbm5uiImJwfHjx9VprA2Ij49H37594enpiYCAANx///3IzMw0O6e8vBzTp09Hy5Yt4eHhgYceegi5ubkqtVhd7777LiIiIuRFwaKjo7F9+3b5dd6r+i1duhSSJGH27Nnyc7xn5hYvXgxJksy+unbtKr/O+1W7c+fO4Z///CdatmwJNzc33H777di3b5/8ujX/7We4sYANGzYgLi4OixYtwoEDBxAZGYnY2Fjk5eWp3TSbUFJSgsjISKxatarW15ctW4a33noLq1evxp49e9CiRQvExsaivLxc4ZbahqSkJEyfPh27d+/Gjz/+iKqqKtxzzz0oKSmRz3n66afx7bffYuPGjUhKSsL58+fx4IMPqthq9bRp0wZLly7F/v37sW/fPgwbNgyjR4/GkSNHAPBe1Wfv3r34v//7P0RERJg9z3tWU/fu3ZGTkyN//fLLL/JrvF81Xb16FQMHDoSLiwu2b9+O9PR0vP766/D19ZXPseq//YKarF+/fmL69Ony93q9XrRu3VrEx8er2CrbBEBs2rRJ/t5gMIigoCDx2muvyc/l5+cLnU4nvvjiCxVaaHvy8vIEAJGUlCSEMN4fFxcXsXHjRvmcjIwMAUCkpKSo1Uyb4uvrK95//33eq3oUFRWJTp06iR9//FEMGTJEzJo1SwjB36/aLFq0SERGRtb6Gu9X7ebOnSsGDRpU5+vW/refPTdNVFlZif379yMmJkZ+zsnJCTExMUhJSVGxZc3DqVOncOHCBbP75+3tjf79+/P+XVNQUAAA8PPzAwDs378fVVVVZvesa9euaNu2rcPfM71ej/Xr16OkpATR0dG8V/WYPn067r33XrN7A/D3qy7Hjx9H69at0aFDB4wbNw5ZWVkAeL/qsmXLFvTp0wd///vfERAQgKioKLz33nvy69b+t5/hpokuXboEvV6PwMBAs+cDAwNx4cIFlVrVfJjuEe9f7QwGA2bPno2BAweiR48eAIz3TKvVwsfHx+xcR75nhw8fhoeHB3Q6HaZOnYpNmzYhPDyc96oO69evx4EDBxAfH1/jNd6zmvr3749169Zhx44dePfdd3Hq1CkMHjwYRUVFvF91+OOPP/Duu++iU6dO+P777/Hkk09i5syZ+OijjwBY/99+h9sVnKg5mT59On7//Xez8X2qqUuXLkhLS0NBQQG++uorTJgwAUlJSWo3yyZlZ2dj1qxZ+PHHH+Hq6qp2c5qFESNGyMcRERHo378/2rVrhy+//BJubm4qtsx2GQwG9OnTB0uWLAEAREVF4ffff8fq1asxYcIEq1+fPTdN5O/vD41GU6MyPjc3F0FBQSq1qvkw3SPev5pmzJiB7777Dj/99BPatGkjPx8UFITKykrk5+ebne/I90yr1aJjx47o3bs34uPjERkZiTfffJP3qhb79+9HXl4eevXqBWdnZzg7OyMpKQlvvfUWnJ2dERgYyHt2Ez4+PujcuTNOnDjB37E6BAcHIzw83Oy5bt26ycN51v63n+GmibRaLXr37o2EhAT5OYPBgISEBERHR6vYsuahffv2CAoKMrt/hYWF2LNnj8PePyEEZsyYgU2bNmHXrl1o37692eu9e/eGi4uL2T3LzMxEVlaWw96zPzMYDKioqOC9qsXw4cNx+PBhpKWlyV99+vTBuHHj5GPes/oVFxfj5MmTCA4O5u9YHQYOHFhjCYtjx46hXbt2ABT4t7/JJckk1q9fL3Q6nVi3bp1IT08Xjz/+uPDx8REXLlxQu2k2oaioSPz222/it99+EwDEihUrxG+//SbOnDkjhBBi6dKlwsfHR2zevFkcOnRIjB49WrRv316UlZWp3HJ1PPnkk8Lb21skJiaKnJwc+au0tFQ+Z+rUqaJt27Zi165dYt++fSI6OlpER0er2Gr1zJs3TyQlJYlTp06JQ4cOiXnz5glJksQPP/wghOC9aogbZ0sJwXv2Z88884xITEwUp06dEsnJySImJkb4+/uLvLw8IQTvV21SU1OFs7OzeOWVV8Tx48fFZ599Jtzd3cWnn34qn2PNf/sZbizk7bffFm3bthVarVb069dP7N69W+0m2YyffvpJAKjxNWHCBCGEcUrgggULRGBgoNDpdGL48OEiMzNT3UarqLZ7BUB8+OGH8jllZWVi2rRpwtfXV7i7u4sHHnhA5OTkqNdoFU2ePFm0a9dOaLVa0apVKzF8+HA52AjBe9UQfw43vGfmxowZI4KDg4VWqxUhISFizJgx4sSJE/LrvF+1+/bbb0WPHj2ETqcTXbt2FWvWrDF73Zr/9ktCCNH0/h8iIiIi28CaGyIiIrIrDDdERERkVxhuiIiIyK4w3BAREZFdYbghIiIiu8JwQ0RERHaF4YaIiIjsCsMNERER2RWGGyKyuqFDh2L27NlqN0MmhMDjjz8OPz8/SJKEtLQ0tZtUp7CwMKxcuVLtZhA1K85qN4CISGk7duzAunXrkJiYiA4dOsDf31/tJhGRBTHcEFGzpNfrIUkSnJxuvQPatKPzgAEDrNAyIlIbh6WIHMTQoUMxc+ZMPPvss/Dz80NQUBAWL14sv3769OkaQzT5+fmQJAmJiYkAgMTEREiShO+//x5RUVFwc3PDsGHDkJeXh+3bt6Nbt27w8vLC2LFjUVpaanb96upqzJgxA97e3vD398eCBQtw49Z2FRUVmDNnDkJCQtCiRQv0799fvi4ArFu3Dj4+PtiyZQvCw8Oh0+mQlZVV68+alJSEfv36QafTITg4GPPmzUN1dTUAYOLEiXjqqaeQlZUFSZIQFhZW5z375ZdfMHjwYLi5uSE0NBQzZ85ESUmJ/HpYWBheeuklPPLII2jRogVCQkKwatUqs8/IysrC6NGj4eHhAS8vLzz88MPIzc01O+fbb79F37594erqCn9/fzzwwANmr5eWlmLy5Mnw9PRE27ZtsWbNmjrbTEQAdwUnchBDhgwRXl5eYvHixeLYsWPio48+EpIkyTtonzp1SgAQv/32m/yeq1evCgDip59+EkJc3+H9jjvuEL/88os4cOCA6NixoxgyZIi45557xIEDB8TPP/8sWrZsKZYuXWp2bQ8PDzFr1ixx9OhR8emnnwp3d3ezXYL/9a9/iQEDBoiff/5ZnDhxQrz22mtCp9OJY8eOCSGE+PDDD4WLi4sYMGCASE5OFkePHhUlJSU1fs6zZ88Kd3d3MW3aNJGRkSE2bdok/P39xaJFi4QQQuTn54sXX3xRtGnTRuTk5Ii8vLxa79eJEydEixYtxBtvvCGOHTsmkpOTRVRUlJg4caJ8Trt27YSnp6eIj48XmZmZ4q233hIajUa+p3q9XvTs2VMMGjRI7Nu3T+zevVv07t1bDBkyRP6M7777Tmg0GrFw4UKRnp4u0tLSxJIlS8yu4efnJ1atWiWOHz8u4uPjhZOTkzh69GgD/qsTOSaGGyIHMWTIEDFo0CCz5/r27Svmzp0rhLi1cLNz5075nPj4eAFAnDx5Un7uiSeeELGxsWbX7tatmzAYDPJzc+fOFd26dRNCCHHmzBmh0WjEuXPnzNo3fPhwMX/+fCGEMdwAEGlpafX+nM8995zo0qWL2bVWrVolPDw8hF6vF0II8cYbb4h27drV+zmPPfaYePzxx82e+9///iecnJxEWVmZEMIYPP7yl7+YnTNmzBgxYsQIIYQQP/zwg9BoNCIrK0t+/ciRIwKASE1NFUIIER0dLcaNG1dnO9q1ayf++c9/yt8bDAYREBAg3n333XrbT+TIOCxF5EAiIiLMvg8ODkZeXl6TPicwMBDu7u7o0KGD2XN//tw77rgDkiTJ30dHR+P48ePQ6/U4fPgw9Ho9OnfuDA8PD/krKSkJJ0+elN+j1Wpr/Ax/lpGRgejoaLNrDRw4EMXFxTh79myDf8aDBw9i3bp1Zu2JjY2FwWDAqVOnzH6OG0VHRyMjI0NuS2hoKEJDQ+XXw8PD4ePjI5+TlpaG4cOH19uWG39mSZIQFBTUqP9uRI6CBcVEDsTFxcXse0mSYDAYAEAuzBU31MFUVVXd9HMkSar3cxuiuLgYGo0G+/fvh0ajMXvNw8NDPnZzczMLLdZUXFyMJ554AjNnzqzxWtu2bS12HTc3t5ue09T7S+RoGG6ICADQqlUrAEBOTg6ioqIAwKLrv+zZs8fs+927d6NTp07QaDSIioqCXq9HXl4eBg8e3KTrdOvWDf/9738hhJCDUHJyMjw9PdGmTZsGf06vXr2Qnp6Ojh071nve7t27a3zfrVs3uS3Z2dnIzs6We2/S09ORn5+P8PBwAMZemYSEBEyaNKnBbSOi+nFYiogAGHsQ7rjjDixduhQZGRlISkrC888/b7HPz8rKQlxcHDIzM/HFF1/g7bffxqxZswAAnTt3xrhx4zB+/Hh8/fXXOHXqFFJTUxEfH4+tW7fe0nWmTZuG7OxsPPXUUzh69Cg2b96MRYsWIS4u7pamjc+dOxe//vorZsyYgbS0NBw/fhybN2/GjBkzzM5LTk7GsmXLcOzYMaxatQobN26Uf66YmBjcfvvtGDduHA4cOIDU1FSMHz8eQ4YMQZ8+fQAAixYtwhdffIFFixYhIyMDhw8fxquvvnpLPzMRmWO4ISLZ2rVrUV1djd69e2P27Nl4+eWXLfbZ48ePR1lZGfr164fp06dj1qxZePzxx+XXP/zwQ4wfPx7PPPMMunTpgvvvvx979+695SGgkJAQbNu2DampqYiMjMTUqVPx2GOP3XJQi4iIQFJSEo4dO4bBgwcjKioKCxcuROvWrc3Oe+aZZ7Bv3z5ERUXh5ZdfxooVKxAbGwvAOHy0efNm+Pr64s4770RMTAw6dOiADRs2yO8fOnQoNm7ciC1btqBnz54YNmwYUlNTb6mtRGROEjcOsBMRUYOFhYVh9uzZNrW1BBGx54aIiIjsDMMNERER2RUOSxEREZFdYc8NERER2RWGGyIiIrIrDDdERERkVxhuiIiIyK4w3BAREZFdYbghIiIiu8JwQ0RERHaF4YaIiIjsyv8HTVaBFR4hroYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy 시각화\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.xlabel('number of epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend (['train acc', 'validation acc'])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "293ba87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:34:27.625955Z",
     "start_time": "2024-09-08T14:34:27.538561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57        48\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40        48\n",
      "   macro avg       0.17      0.07      0.09        48\n",
      "weighted avg       1.00      0.40      0.57        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.72        48\n",
      "           3       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.56        48\n",
      "   macro avg       0.25      0.14      0.18        48\n",
      "weighted avg       1.00      0.56      0.72        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.54      0.70        48\n",
      "           3       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.54        48\n",
      "   macro avg       0.14      0.08      0.10        48\n",
      "weighted avg       1.00      0.54      0.70        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50        48\n",
      "           6       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33        48\n",
      "   macro avg       0.17      0.06      0.08        48\n",
      "weighted avg       1.00      0.33      0.50        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.35      0.52        48\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35        48\n",
      "   macro avg       0.25      0.09      0.13        48\n",
      "weighted avg       1.00      0.35      0.52        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.74        48\n",
      "           7       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.58        48\n",
      "   macro avg       0.14      0.08      0.11        48\n",
      "weighted avg       1.00      0.58      0.74        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.65        48\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.48        48\n",
      "   macro avg       0.14      0.07      0.09        48\n",
      "weighted avg       1.00      0.48      0.65        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.52      0.68        48\n",
      "          93       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52        48\n",
      "   macro avg       0.25      0.13      0.17        48\n",
      "weighted avg       1.00      0.52      0.68        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.65        48\n",
      "           4       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.48        48\n",
      "   macro avg       0.14      0.07      0.09        48\n",
      "weighted avg       1.00      0.48      0.65        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.59        48\n",
      "           3       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.42        48\n",
      "   macro avg       0.17      0.07      0.10        48\n",
      "weighted avg       1.00      0.42      0.59        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61        48\n",
      "           1       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.44        48\n",
      "   macro avg       0.12      0.05      0.08        48\n",
      "weighted avg       1.00      0.44      0.61        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.35      0.52        48\n",
      "           4       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35        48\n",
      "   macro avg       0.20      0.07      0.10        48\n",
      "weighted avg       1.00      0.35      0.52        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "num_classes = val_target.shape[-1]  \n",
    "\n",
    "for i in range(num_classes) :\n",
    "    y_true = np.argmax(val_target[:, :, i], axis=-1).flatten()  \n",
    "    y_pred = np.argmax(pred[:, :, i], axis=-1).flatten()\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
