{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "107b53a8",
   "metadata": {},
   "source": [
    "## learning-AI : HARTH classification (DL)\n",
    "### The Human Activity Recognition Trondheim (HARTH)를 U-net을 통한 Encoder-Decoder 방식의 classification\n",
    "\n",
    "<br>\n",
    "\n",
    "- **임규연 (lky473736)**\n",
    "- 2024.09.06. ~ 2024.09.08.에 문서 작성\n",
    "- **dataset** : https://archive.ics.uci.edu/dataset/779/harth\n",
    "- **data abstract** : The Human Activity Recognition Trondheim (HARTH) dataset is a professionally-annotated dataset containing 22 subjects wearing two 3-axial accelerometers for around 2 hours in a free-living setting. The sensors were attached to the right thigh and lower back. The professional recordings and annotations provide a promising benchmark dataset for researchers to develop innovative machine learning approaches for precise HAR in free living.\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "\n",
    "## <span id='dl'><mark>DL</mark></span>\n",
    "    \n",
    "deep learning으로 HARTH을 classification한다. **kmat2019가 작성한 'U-net(1D-CNN) with Keras'를 참고하여 classification한다.**\n",
    "\n",
    "- **Reference**\n",
    "    - https://www.kaggle.com/code/kmat2019/u-net-1d-cnn-with-keras\n",
    "    - https://github.com/lky473736/learning-AI/blob/main/report/HARTH/U-net_classification_HARTH.ipynb\n",
    "    - https://github.com/lky473736/learning-AI/blob/main/insight/insight_4_U_net_on_ion_switching.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "baae97e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:25.774213Z",
     "start_time": "2024-09-08T14:04:25.769323Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, Reshape, Conv1D, BatchNormalization, Activation, AveragePooling1D, GlobalAveragePooling1D, Lambda, Input, Concatenate, Add, UpSampling1D, Multiply\n",
    "from keras.models import Model\n",
    "# objectives 작동 X -> losses로 변경\n",
    "from keras.losses import mean_squared_error\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau,LearningRateScheduler\n",
    "from keras.initializers import random_normal\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8dffdf69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.456226Z",
     "start_time": "2024-09-08T14:04:25.777484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y',\n",
      "       'thigh_z', 'label'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 408709 entries, 0 to 408708\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   timestamp  408709 non-null  object \n",
      " 1   back_x     408709 non-null  float64\n",
      " 2   back_y     408709 non-null  float64\n",
      " 3   back_z     408709 non-null  float64\n",
      " 4   thigh_x    408709 non-null  float64\n",
      " 5   thigh_y    408709 non-null  float64\n",
      " 6   thigh_z    408709 non-null  float64\n",
      " 7   label      408709 non-null  int64  \n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 24.9+ MB\n",
      "None\n",
      "\n",
      "Index(['timestamp', 'back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y',\n",
      "       'thigh_z', 'label'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418989 entries, 0 to 418988\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   timestamp  418989 non-null  object \n",
      " 1   back_x     418989 non-null  float64\n",
      " 2   back_y     418989 non-null  float64\n",
      " 3   back_z     418989 non-null  float64\n",
      " 4   thigh_x    418989 non-null  float64\n",
      " 5   thigh_y    418989 non-null  float64\n",
      " 6   thigh_z    418989 non-null  float64\n",
      " 7   label      418989 non-null  int64  \n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 25.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    원래 모든 harth 디렉토리의 데이터파일을 병합한 데이터셋을 사용하려고 했으나, \n",
    "    records의 양이 많아 한 epoch 당 10분의 학습시간이 걸린다.\n",
    "    따라서, S006.csv은 train set으로,\n",
    "    S008.csv는 test set으로 둔다. \n",
    "'''\n",
    "\n",
    "df_train = pd.read_csv(\"../../data/harth/S006.csv\")\n",
    "df_test = pd.read_csv(\"../../data/harth/S008.csv\")\n",
    "\n",
    "print (df_train.columns)\n",
    "print (df_train.info())\n",
    "print ()\n",
    "print (df_test.columns)\n",
    "print (df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5ece2086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.524203Z",
     "start_time": "2024-09-08T14:04:27.458274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6   1   3   7   4   5   8 130  13  14]\n",
      "[  6   1   3   7   4   5  13 130 140  14]\n",
      "[4 0 1 5 2 3 6 9 7 8]\n",
      "[4 0 1 5 2 3 6 8 9 7]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    info()에서 본 df가 결측치가 없음을 확인했으니, 결측치 처리는 pass\n",
    "'''\n",
    "\n",
    "# class 확인 및 label encoding 실시\n",
    "\n",
    "print (df_train['label'].unique())\n",
    "print (df_test['label'].unique())\n",
    "\n",
    "# labelencoding을 통하여 각 label을 0-based 및 순서대로 구성\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['label'] = label_encoder.fit_transform(df_train['label'])\n",
    "df_test['label'] = label_encoder.fit_transform(df_test['label'])\n",
    "\n",
    "print (df_train['label'].unique())\n",
    "print (df_test['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "940c5e80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.681672Z",
     "start_time": "2024-09-08T14:04:27.527381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "4    15000\n",
      "0    15000\n",
      "1    15000\n",
      "5    15000\n",
      "2    15000\n",
      "3    15000\n",
      "6    15000\n",
      "9    15000\n",
      "7    15000\n",
      "8    15000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "label\n",
      "4    15000\n",
      "0    15000\n",
      "1    15000\n",
      "5    15000\n",
      "2    15000\n",
      "3    15000\n",
      "6    15000\n",
      "9    15000\n",
      "7    15000\n",
      "8    15000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    oversampling은 함수로 구현한다. 원래는 SMOTE를 사용하려고 하였다.\n",
    "    SMOTE (Synthetic Minority Over-sampling Technique)는 적은 수의 \n",
    "    클래스 사이에서 새로운 가상 records를 구성하는 것이다.\n",
    "    하지만, 랜덤으로 위치를 다시 uniting하기 때문에 시계열 데이터에는 적합하지 않아 직접 구현한다.\n",
    "'''\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE()\n",
    "# harth_input_resampled, harth_target_resampled = smote.fit_resample(harth_input, \n",
    "#                                                                    harth_target)\n",
    "# print (harth_target_resampled.value_counts())\n",
    "# print (harth_input_resampled.shape, harth_target_resampled.shape)\n",
    "\n",
    "# class 별로 데이터 추출 -> 복제하는 방식\n",
    "    \n",
    "# 만약 15000개보다 샘플이 적음 -> replace == True로 복제\n",
    "# 만약 15000개보다 샘플이 많음 -> 복제\n",
    "    \n",
    "def oversampling(df, target_col, max_size) :\n",
    "    # 결과를 저장할 리스트 \n",
    "    dfs = []\n",
    "    \n",
    "    for label in df[target_col].unique() :\n",
    "        class_df = df[df[target_col] == label]\n",
    "        \n",
    "        if len(class_df) < max_size :\n",
    "            # 샘플 수가 max_size보다 적으면 데이터를 복제하여 max_size로 만듦\n",
    "            sampled_df = class_df.sample(max_size, replace=True, random_state=42)\n",
    "        else :\n",
    "            # 샘플 수가 max_size보다 많으면 앞부분부터 max_size만큼 선택함\n",
    "            sampled_df = class_df.head(max_size)\n",
    "        \n",
    "        # 리스트에 추가\n",
    "        dfs.append(sampled_df)\n",
    "    \n",
    "    # 리스트에 저장된 데이터프레임들을 합침\n",
    "    df_resampled = pd.concat(dfs).reset_index(drop=True)\n",
    "    \n",
    "    return df_resampled\n",
    "\n",
    "df_train_resampled = oversampling(df_train, 'label', max_size=15000)\n",
    "df_test_resampled = oversampling(df_train, 'label', max_size=15000)\n",
    "print (df_train_resampled['label'].value_counts())\n",
    "print ()\n",
    "print (df_test_resampled['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9871fc8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.694607Z",
     "start_time": "2024-09-08T14:04:27.683841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      timestamp    back_x    back_y    back_z   thigh_x  \\\n",
      "0       2019-01-12 00:00:00.000 -0.760242  0.299570  0.468570 -5.092732   \n",
      "1       2019-01-12 00:00:00.010 -0.530138  0.281880  0.319987  0.900547   \n",
      "2       2019-01-12 00:00:00.020 -1.170922  0.186353 -0.167010 -0.035442   \n",
      "3       2019-01-12 00:00:00.030 -0.648772  0.016579 -0.054284 -1.554248   \n",
      "4       2019-01-12 00:00:00.040 -0.355071 -0.051831 -0.113419 -0.547471   \n",
      "...                         ...       ...       ...       ...       ...   \n",
      "149995  2019-01-12 00:54:55.410 -0.651213  0.181842  0.266343  0.563873   \n",
      "149996  2019-01-12 00:55:21.380 -0.533637  0.048316  0.446973 -0.991452   \n",
      "149997  2019-01-12 00:55:26.360 -1.064464  0.250127  0.788185 -1.994850   \n",
      "149998  2019-01-12 00:55:27.450 -0.335641 -0.199129  0.221672 -0.892103   \n",
      "149999  2019-01-12 00:54:54.610 -0.706449  0.052887  0.540791 -0.852804   \n",
      "\n",
      "         thigh_y   thigh_z  label  \n",
      "0      -0.298644  0.709439      4  \n",
      "1       0.286944  0.340309      4  \n",
      "2      -0.078423 -0.515212      4  \n",
      "3      -0.950978 -0.221140      4  \n",
      "4       0.140903 -0.653782      4  \n",
      "...          ...       ...    ...  \n",
      "149995 -0.237077 -0.906965      8  \n",
      "149996 -0.323780  0.387773      8  \n",
      "149997  0.030172  0.737239      8  \n",
      "149998  0.452392  1.028806      8  \n",
      "149999  0.167461  0.312494      8  \n",
      "\n",
      "[150000 rows x 8 columns]                       timestamp    back_x    back_y    back_z   thigh_x  \\\n",
      "0       2019-01-12 00:00:00.000 -0.760242  0.299570  0.468570 -5.092732   \n",
      "1       2019-01-12 00:00:00.010 -0.530138  0.281880  0.319987  0.900547   \n",
      "2       2019-01-12 00:00:00.020 -1.170922  0.186353 -0.167010 -0.035442   \n",
      "3       2019-01-12 00:00:00.030 -0.648772  0.016579 -0.054284 -1.554248   \n",
      "4       2019-01-12 00:00:00.040 -0.355071 -0.051831 -0.113419 -0.547471   \n",
      "...                         ...       ...       ...       ...       ...   \n",
      "149995  2019-01-12 00:54:55.410 -0.651213  0.181842  0.266343  0.563873   \n",
      "149996  2019-01-12 00:55:21.380 -0.533637  0.048316  0.446973 -0.991452   \n",
      "149997  2019-01-12 00:55:26.360 -1.064464  0.250127  0.788185 -1.994850   \n",
      "149998  2019-01-12 00:55:27.450 -0.335641 -0.199129  0.221672 -0.892103   \n",
      "149999  2019-01-12 00:54:54.610 -0.706449  0.052887  0.540791 -0.852804   \n",
      "\n",
      "         thigh_y   thigh_z  label  \n",
      "0      -0.298644  0.709439      4  \n",
      "1       0.286944  0.340309      4  \n",
      "2      -0.078423 -0.515212      4  \n",
      "3      -0.950978 -0.221140      4  \n",
      "4       0.140903 -0.653782      4  \n",
      "...          ...       ...    ...  \n",
      "149995 -0.237077 -0.906965      8  \n",
      "149996 -0.323780  0.387773      8  \n",
      "149997  0.030172  0.737239      8  \n",
      "149998  0.452392  1.028806      8  \n",
      "149999  0.167461  0.312494      8  \n",
      "\n",
      "[150000 rows x 8 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    이전에 oversampling 전에 했었던 작업. \\n'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 둘 다 모양을 맞추기 위해 400000까지 cut\n",
    "\n",
    "print (df_train_resampled, df_test_resampled)\n",
    "\n",
    "# df_train = df_train.iloc[:400000]\n",
    "# df_test = df_test.iloc[:400000]\n",
    "\n",
    "# df_train.shape, df_test.shape \n",
    "\n",
    "'''\n",
    "    이전에 oversampling 전에 했었던 작업. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "94cf4891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.721504Z",
     "start_time": "2024-09-08T14:04:27.696731Z"
    }
   },
   "outputs": [],
   "source": [
    "# reshape를 통해 전체 열을 3D ndarray로 재구성\n",
    "\n",
    "train_input = df_train_resampled[['back_x', 'back_y', \n",
    "                        'back_z', 'thigh_x', \n",
    "                        'thigh_y', 'thigh_z']].values.reshape(-1, 100, 6)\n",
    "train_input_mean = train_input.mean()\n",
    "train_input_sigma = train_input.std()\n",
    "train_input = (train_input - train_input_mean) / train_input_sigma\n",
    "\n",
    "test_input = df_test_resampled[['back_x', 'back_y', \n",
    "                        'back_z', 'thigh_x', \n",
    "                        'thigh_y', 'thigh_z']].values.reshape(-1, 500, 6)\n",
    "test_input = (test_input - train_input_mean) / train_input_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b2d638bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.742022Z",
     "start_time": "2024-09-08T14:04:27.723621Z"
    }
   },
   "outputs": [],
   "source": [
    "# label을 target으로 두고, one-hot encoding 진행\n",
    "\n",
    "train_target = pd.get_dummies(df_train_resampled[\"label\"]).values.reshape(-1, 100, len(df_train_resampled['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2c69ea85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.753657Z",
     "start_time": "2024-09-08T14:04:27.743735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input:(1200, 100, 6), val_input:(300, 100, 6), train_target:(1200, 100, 10), val_target:(300, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "# val set 구축\n",
    "\n",
    "idx = np.arange(train_input.shape[0])\n",
    "train_idx, val_idx = train_test_split(idx, \n",
    "                                      random_state=111, \n",
    "                                      test_size=0.2)\n",
    "# idx를 섞어서 편향 문제를 방지\n",
    "\n",
    "val_input = train_input[val_idx]\n",
    "train_input = train_input[train_idx]\n",
    "val_target = train_target[val_idx]\n",
    "train_target = train_target[train_idx]\n",
    "\n",
    "print(\"train_input:{}, val_input:{}, train_target:{}, val_target:{}\".format(train_input.shape, val_input.shape, train_target.shape, val_target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43b843",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "```ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 5, 256), (None, 4, 192)]``` 로 인하여 기존 소스코드 로직에 해가 가지 않을 정도로만 수정한다.\n",
    "\n",
    "- Unet 메소드에 upsampling 후 크기가 맞지 않아 concatenate가 되지 않는 문제 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "33312089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.760830Z",
     "start_time": "2024-09-08T14:04:27.756693Z"
    }
   },
   "outputs": [],
   "source": [
    "def cbr(x, out_layer, kernel, stride, dilation):\n",
    "    x = Conv1D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5806ef57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.769310Z",
     "start_time": "2024-09-08T14:04:27.766535Z"
    }
   },
   "outputs": [],
   "source": [
    "def se_block(x_in, layer_n):\n",
    "    x = GlobalAveragePooling1D()(x_in)\n",
    "    x = Dense(layer_n // 8, activation=\"relu\")(x)\n",
    "    x = Dense(layer_n, activation=\"sigmoid\")(x)\n",
    "    x_out = Multiply()([x_in, x])\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cb32321a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.774880Z",
     "start_time": "2024-09-08T14:04:27.771479Z"
    }
   },
   "outputs": [],
   "source": [
    "def resblock(x_in, layer_n, kernel, dilation, use_se=True):\n",
    "    x = cbr(x_in, layer_n, kernel, 1, dilation)\n",
    "    x = cbr(x, layer_n, kernel, 1, dilation)\n",
    "    if use_se:\n",
    "        x = se_block(x, layer_n)\n",
    "    x = Add()([x_in, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "81dc7367",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.785490Z",
     "start_time": "2024-09-08T14:04:27.777447Z"
    }
   },
   "outputs": [],
   "source": [
    "def Unet(input_shape=(100, 6)):\n",
    "    layer_n = 64\n",
    "    kernel_size = 7\n",
    "    depth = 2\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    ########## encoder \n",
    "    x = cbr(input_layer, layer_n, kernel_size, 1, 1)  \n",
    "    # shape: (None, 100, 64)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n, kernel_size, 1)\n",
    "    out_0 = x\n",
    "\n",
    "    x = cbr(x, layer_n*2, kernel_size, 5, 1)  \n",
    "    # shape: (None, 20, 128)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n*2, kernel_size, 1)\n",
    "    out_1 = x\n",
    "\n",
    "    x = cbr(x, layer_n*3, kernel_size, 5, 1)  \n",
    "    # shape: (None, 4, 192)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n*3, kernel_size, 1)\n",
    "    out_2 = x\n",
    "\n",
    "    ########## Decoder\n",
    "    x = UpSampling1D(size=5)(x)  # upsample to (None, 20, 192)\n",
    "    x = Concatenate()([x, out_1])  # concatenate with out_1 (None, 20, 128)\n",
    "    x = Conv1D(layer_n*2, kernel_size=1, padding=\"same\")(x)  \n",
    "    x = cbr(x, layer_n*2, kernel_size, 1, 1) \n",
    "    # shape: (None, 20, 128)\n",
    "\n",
    "    x = UpSampling1D(size=5)(x)  # upsample to (None, 100, 128)\n",
    "    x = Concatenate()([x, out_0])  # concatenate with out_0 (None, 100, 64)\n",
    "    x = Conv1D(layer_n, kernel_size=1, padding=\"same\")(x) \n",
    "    x = cbr(x, layer_n, kernel_size, 1, 1) \n",
    "    # shape: (None, 100, 64)\n",
    "\n",
    "    ######### Dense\n",
    "    num_classes = len(df_train_resampled['label'].unique())\n",
    "    x = Conv1D(num_classes, kernel_size=1, \n",
    "               strides=1, padding=\"same\")(x)\n",
    "    out = Activation(\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=out)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "72ddadb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.790536Z",
     "start_time": "2024-09-08T14:04:27.787598Z"
    }
   },
   "outputs": [],
   "source": [
    "def augmentations(input_data, target_data):\n",
    "    #flip\n",
    "    if np.random.rand() < 0.5:    \n",
    "        input_data = input_data[::-1]\n",
    "        target_data = target_data[::-1]\n",
    "\n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "54a81474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.797455Z",
     "start_time": "2024-09-08T14:04:27.792412Z"
    }
   },
   "outputs": [],
   "source": [
    "def Datagen(input_dataset, target_dataset, batch_size, is_train=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    idx_1 = np.arange(len(input_dataset))\n",
    "    np.random.shuffle(idx_1)\n",
    "\n",
    "    while True:\n",
    "        for i in range(len(input_dataset)):\n",
    "            input_data = input_dataset[idx_1[i]]\n",
    "            target_data = target_dataset[idx_1[i]]\n",
    "\n",
    "            if is_train:\n",
    "                input_data, target_data = augmentations(input_data, target_data)\n",
    "                \n",
    "            x.append(input_data)\n",
    "            y.append(target_data)\n",
    "            count += 1\n",
    "            \n",
    "            if count == batch_size:\n",
    "                x=np.array(x, dtype=np.float32)\n",
    "                y=np.array(y, dtype=np.float32)\n",
    "                inputs = x\n",
    "                targets = y       \n",
    "                x = []\n",
    "                y = []\n",
    "                count=0\n",
    "                yield inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "012c9fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.805634Z",
     "start_time": "2024-09-08T14:04:27.800078Z"
    }
   },
   "outputs": [],
   "source": [
    "# class macroF1(Callback):\n",
    "#     def __init__(self, model, inputs, targets):\n",
    "#         self.model = model\n",
    "#         self.inputs = inputs\n",
    "#         self.targets = np.argmax(targets, axis=2).reshape(-1)\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs):\n",
    "#         # 각 에포크가 끝날 때마다 검증 데이터로 매크로 F1 스코어를 계산하여 출력\n",
    "#         pred = np.argmax(self.model.predict(self.inputs), axis=2).reshape(-1)\n",
    "#         f1_val = f1_score(self.targets, pred, average=\"macro\")\n",
    "#         print(\"val_f1_macro_score: \", f1_val)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class macroF1(Callback):\n",
    "    def __init__(self, inputs, targets):\n",
    "        super(macroF1, self).__init__()\n",
    "        self.inputs = inputs\n",
    "        self.targets = np.argmax(targets, axis=2).reshape(-1)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        predictions = self.model.predict(self.inputs) \n",
    "        pred = np.argmax(predictions, axis=2).reshape(-1)\n",
    "\n",
    "        # Calculate the macro F1 score\n",
    "        f1_val = f1_score(self.targets, pred, average=\"macro\")\n",
    "        \n",
    "        # Add the F1 score to logs\n",
    "        logs['val_f1_macro_score'] = f1_val\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} - val_f1_macro_score: {f1_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2b201271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.811307Z",
     "start_time": "2024-09-08T14:04:27.807430Z"
    }
   },
   "outputs": [],
   "source": [
    "# def model_fit(model, train_inputs, train_targets, val_inputs, val_targets, n_epoch, batch_size=32):\n",
    "#     # 모델을 학습시키기 위한 함수\n",
    "#     hist = model.fit_generator(\n",
    "#         Datagen(train_inputs, train_targets, batch_size, is_train=True),\n",
    "#         steps_per_epoch=len(train_inputs) // batch_size,\n",
    "#         epochs=n_epoch,\n",
    "#         validation_data=Datagen(val_inputs, val_targets, batch_size),\n",
    "#         validation_steps=len(val_inputs) // batch_size,\n",
    "#         callbacks=[lr_schedule, macroF1(model, val_inputs, val_targets)],\n",
    "#         shuffle=False,\n",
    "#         verbose=1\n",
    "#     )\n",
    "#     return hist\n",
    "\n",
    "'''\n",
    "    fit_generator가 정상적으로 작동하지 않아, 일부 수정함\n",
    "'''\n",
    "\n",
    "def model_fit(model, train_inputs, train_targets, val_inputs, val_targets, n_epoch, batch_size=32):\n",
    "    # 모델을 학습시키기 위한 함수\n",
    "    hist = model.fit(\n",
    "        train_inputs, train_targets,\n",
    "        batch_size=batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=(val_inputs, val_targets),\n",
    "        callbacks=[lr_schedule, macroF1(val_inputs, val_targets)],\n",
    "        shuffle=True, \n",
    "        verbose=1\n",
    "    )\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2c9bc2ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:04:27.817185Z",
     "start_time": "2024-09-08T14:04:27.813902Z"
    }
   },
   "outputs": [],
   "source": [
    "def lrs(epoch):\n",
    "    if epoch<35:\n",
    "        lr = learning_rate\n",
    "    elif epoch<50:\n",
    "        lr = learning_rate/10\n",
    "    else:\n",
    "        lr = learning_rate/100\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "aa3510bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:09:48.448464Z",
     "start_time": "2024-09-08T14:04:27.820126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5753 - loss:\n",
      "Epoch 1 - val_f1_macro_score: 0.2898\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 152ms/step - accuracy: 0.5800 - loss: 1.3398 - val_accuracy: 0.3990 - val_loss: 1.7583 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.2898\n",
      "Epoch 2/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/stepp - accuracy: 0.9436 - loss: 0.\n",
      "Epoch 2 - val_f1_macro_score: 0.3267\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.9437 - loss: 0.2949 - val_accuracy: 0.4021 - val_loss: 2.0934 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.3267\n",
      "Epoch 3/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/stepp - accuracy: 0.9656 - loss: 0.\n",
      "Epoch 3 - val_f1_macro_score: 0.3322\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.9657 - loss: 0.1853 - val_accuracy: 0.3753 - val_loss: 2.2702 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.3322\n",
      "Epoch 4/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9774 - loss: \n",
      "Epoch 4 - val_f1_macro_score: 0.3760\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.9773 - loss: 0.1202 - val_accuracy: 0.4233 - val_loss: 1.8855 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.3760\n",
      "Epoch 5/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9763 - loss: 0\n",
      "Epoch 5 - val_f1_macro_score: 0.6845\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.9764 - loss: 0.1265 - val_accuracy: 0.7140 - val_loss: 1.3326 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.6845\n",
      "Epoch 6/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9729 - loss: 0\n",
      "Epoch 6 - val_f1_macro_score: 0.7199\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.9726 - loss: 0.1275 - val_accuracy: 0.7586 - val_loss: 0.7218 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.7199\n",
      "Epoch 7/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9472 - loss: 0.\n",
      "Epoch 7 - val_f1_macro_score: 0.6645\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.9474 - loss: 0.2104 - val_accuracy: 0.6900 - val_loss: 1.0288 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.6645\n",
      "Epoch 8/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/stepp - accuracy: 0.9801 - loss: 0\n",
      "Epoch 8 - val_f1_macro_score: 0.7440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - accuracy: 0.9801 - loss: 0.0964 - val_accuracy: 0.7603 - val_loss: 0.7732 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.7440\n",
      "Epoch 9/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9779 - loss: 0\n",
      "Epoch 9 - val_f1_macro_score: 0.8778\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9780 - loss: 0.1021 - val_accuracy: 0.8790 - val_loss: 0.3361 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.8778\n",
      "Epoch 10/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/stepp - accuracy: 0.9768 - loss: 0\n",
      "Epoch 10 - val_f1_macro_score: 0.8824\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - accuracy: 0.9768 - loss: 0.0969 - val_accuracy: 0.8786 - val_loss: 0.3208 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.8824\n",
      "Epoch 11/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/stepp - accuracy: 0.9838 - loss: 0\n",
      "Epoch 11 - val_f1_macro_score: 0.9530\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.9839 - loss: 0.0737 - val_accuracy: 0.9612 - val_loss: 0.1398 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9530\n",
      "Epoch 12/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/stepp - accuracy: 0.9882 - loss: 0.\n",
      "Epoch 12 - val_f1_macro_score: 0.9508\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.9881 - loss: 0.0562 - val_accuracy: 0.9494 - val_loss: 0.1762 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9508\n",
      "Epoch 13/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9846 - loss: 0\n",
      "Epoch 13 - val_f1_macro_score: 0.9612\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 0.9846 - loss: 0.0717 - val_accuracy: 0.9628 - val_loss: 0.1395 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9612\n",
      "Epoch 14/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/stepp - accuracy: 0.9946 - loss: 0.\n",
      "Epoch 14 - val_f1_macro_score: 0.9793\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.9946 - loss: 0.0399 - val_accuracy: 0.9808 - val_loss: 0.0860 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9793\n",
      "Epoch 15/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/stepp - accuracy: 0.9800 - loss: 0\n",
      "Epoch 15 - val_f1_macro_score: 0.8408\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.9801 - loss: 0.0643 - val_accuracy: 0.8441 - val_loss: 0.4587 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.8408\n",
      "Epoch 16/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/stepp - accuracy: 0.9927 - loss: 0\n",
      "Epoch 16 - val_f1_macro_score: 0.9161\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.9926 - loss: 0.0404 - val_accuracy: 0.9151 - val_loss: 0.2522 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9161\n",
      "Epoch 17/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/stepp - accuracy: 0.9900 - loss: 0\n",
      "Epoch 17 - val_f1_macro_score: 0.8389\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.9899 - loss: 0.0457 - val_accuracy: 0.8422 - val_loss: 0.5607 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.8389\n",
      "Epoch 18/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/stepp - accuracy: 0.9712 - loss\n",
      "Epoch 18 - val_f1_macro_score: 0.9518\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - accuracy: 0.9712 - loss: 0.1022 - val_accuracy: 0.9521 - val_loss: 0.1531 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9518\n",
      "Epoch 19/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/stepp - accuracy: 0.9766 - loss: \n",
      "Epoch 19 - val_f1_macro_score: 0.8467\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - accuracy: 0.9768 - loss: 0.0911 - val_accuracy: 0.8694 - val_loss: 0.7286 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.8467\n",
      "Epoch 20/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/stepp - accuracy: 0.9900 - loss: 0\n",
      "Epoch 20 - val_f1_macro_score: 0.8819\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - accuracy: 0.9900 - loss: 0.0441 - val_accuracy: 0.8889 - val_loss: 0.4413 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.8819\n",
      "Epoch 21/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/stepp - accuracy: 0.9890 - loss: 0\n",
      "Epoch 21 - val_f1_macro_score: 0.9842\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - accuracy: 0.9891 - loss: 0.0607 - val_accuracy: 0.9859 - val_loss: 0.0399 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9842\n",
      "Epoch 22/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/stepp - accuracy: 0.9981 - loss: 0\n",
      "Epoch 22 - val_f1_macro_score: 0.9773\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.9980 - loss: 0.0180 - val_accuracy: 0.9780 - val_loss: 0.0683 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9773\n",
      "Epoch 23/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/stepp - accuracy: 0.9925 - loss: 0\n",
      "Epoch 23 - val_f1_macro_score: 0.9856\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - accuracy: 0.9923 - loss: 0.0334 - val_accuracy: 0.9876 - val_loss: 0.0643 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/stepp - accuracy: 0.9892 - loss: \n",
      "Epoch 24 - val_f1_macro_score: 0.9814\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - accuracy: 0.9893 - loss: 0.0449 - val_accuracy: 0.9821 - val_loss: 0.0483 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9814\n",
      "Epoch 25/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/stepp - accuracy: 0.9941 - loss: \n",
      "Epoch 25 - val_f1_macro_score: 0.9656\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - accuracy: 0.9940 - loss: 0.0301 - val_accuracy: 0.9660 - val_loss: 0.1095 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9656\n",
      "Epoch 26/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/stepp - accuracy: 0.9843 - loss: 0\n",
      "Epoch 26 - val_f1_macro_score: 0.8295\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - accuracy: 0.9844 - loss: 0.0540 - val_accuracy: 0.8185 - val_loss: 0.6884 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.8295\n",
      "Epoch 27/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/stepp - accuracy: 0.9917 - loss:\n",
      "Epoch 27 - val_f1_macro_score: 0.9941\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - accuracy: 0.9917 - loss: 0.0346 - val_accuracy: 0.9950 - val_loss: 0.0380 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9941\n",
      "Epoch 28/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/stepp - accuracy: 0.9942 - loss: \n",
      "Epoch 28 - val_f1_macro_score: 0.9925\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - accuracy: 0.9942 - loss: 0.0380 - val_accuracy: 0.9931 - val_loss: 0.0426 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9925\n",
      "Epoch 29/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/stepp - accuracy: 0.9983 - loss:\n",
      "Epoch 29 - val_f1_macro_score: 0.9658\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - accuracy: 0.9983 - loss: 0.0147 - val_accuracy: 0.9651 - val_loss: 0.1225 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9658\n",
      "Epoch 30/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/stepp - accuracy: 0.9977 - loss: 0\n",
      "Epoch 30 - val_f1_macro_score: 0.9949\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - accuracy: 0.9977 - loss: 0.0162 - val_accuracy: 0.9958 - val_loss: 0.0294 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9949\n",
      "Epoch 31/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/stepp - accuracy: 0.9987 - loss: \n",
      "Epoch 31 - val_f1_macro_score: 0.9895\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - accuracy: 0.9986 - loss: 0.0115 - val_accuracy: 0.9904 - val_loss: 0.0432 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9895\n",
      "Epoch 32/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9951 - loss: 0\n",
      "Epoch 32 - val_f1_macro_score: 0.9943\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9951 - loss: 0.0257 - val_accuracy: 0.9952 - val_loss: 0.0358 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9943\n",
      "Epoch 33/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/stepp - accuracy: 0.9953 - loss: \n",
      "Epoch 33 - val_f1_macro_score: 0.9909\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.9953 - loss: 0.0268 - val_accuracy: 0.9922 - val_loss: 0.0260 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9909\n",
      "Epoch 34/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/stepp - accuracy: 0.9939 - loss: 0\n",
      "Epoch 34 - val_f1_macro_score: 0.9812\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.9938 - loss: 0.0255 - val_accuracy: 0.9819 - val_loss: 0.0560 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9812\n",
      "Epoch 35/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/stepp - accuracy: 0.9875 - loss: \n",
      "Epoch 35 - val_f1_macro_score: 0.9914\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - accuracy: 0.9877 - loss: 0.0356 - val_accuracy: 0.9922 - val_loss: 0.0366 - learning_rate: 5.0000e-04 - val_f1_macro_score: 0.9914\n",
      "Epoch 36/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/stepp - accuracy: 0.9934 - loss: 0\n",
      "Epoch 36 - val_f1_macro_score: 0.9931\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.9935 - loss: 0.0267 - val_accuracy: 0.9939 - val_loss: 0.0295 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9931\n",
      "Epoch 37/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/stepp - accuracy: 0.9997 - loss: 0\n",
      "Epoch 37 - val_f1_macro_score: 0.9936\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - accuracy: 0.9997 - loss: 0.0088 - val_accuracy: 0.9944 - val_loss: 0.0278 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9936\n",
      "Epoch 38/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/stepp - accuracy: 0.9993 - loss: 0\n",
      "Epoch 38 - val_f1_macro_score: 0.9944\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.9993 - loss: 0.0089 - val_accuracy: 0.9952 - val_loss: 0.0289 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9944\n",
      "Epoch 39/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/stepp - accuracy: 0.9966 - loss: 0\n",
      "Epoch 39 - val_f1_macro_score: 0.9916\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - accuracy: 0.9967 - loss: 0.0155 - val_accuracy: 0.9931 - val_loss: 0.0306 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9916\n",
      "Epoch 40/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/stepp - accuracy: 0.9990 - loss: 0\n",
      "Epoch 40 - val_f1_macro_score: 0.9943\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - accuracy: 0.9990 - loss: 0.0093 - val_accuracy: 0.9952 - val_loss: 0.0296 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9943\n",
      "Epoch 41/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/stepp - accuracy: 0.9985 - loss: 0\n",
      "Epoch 41 - val_f1_macro_score: 0.9942\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - accuracy: 0.9985 - loss: 0.0116 - val_accuracy: 0.9950 - val_loss: 0.0286 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9942\n",
      "Epoch 42/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/stepp - accuracy: 0.9987 - loss: 0\n",
      "Epoch 42 - val_f1_macro_score: 0.9945\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.9987 - loss: 0.0103 - val_accuracy: 0.9953 - val_loss: 0.0286 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9945\n",
      "Epoch 43/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/stepp - accuracy: 0.9990 - loss: 0\n",
      "Epoch 43 - val_f1_macro_score: 0.9951\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - accuracy: 0.9989 - loss: 0.0098 - val_accuracy: 0.9959 - val_loss: 0.0278 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9951\n",
      "Epoch 44/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/stepp - accuracy: 0.9980 - loss: 0\n",
      "Epoch 44 - val_f1_macro_score: 0.9951\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - accuracy: 0.9980 - loss: 0.0093 - val_accuracy: 0.9960 - val_loss: 0.0267 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9951\n",
      "Epoch 45/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/stepp - accuracy: 0.9990 - loss: 0.\n",
      "Epoch 45 - val_f1_macro_score: 0.9956\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.9990 - loss: 0.0090 - val_accuracy: 0.9964 - val_loss: 0.0264 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9956\n",
      "Epoch 46/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/stepp - accuracy: 0.9996 - loss:\n",
      "Epoch 46 - val_f1_macro_score: 0.9956\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - accuracy: 0.9996 - loss: 0.0067 - val_accuracy: 0.9964 - val_loss: 0.0269 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/stepp - accuracy: 0.9976 - loss: 0\n",
      "Epoch 47 - val_f1_macro_score: 0.9955\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - accuracy: 0.9976 - loss: 0.0111 - val_accuracy: 0.9963 - val_loss: 0.0278 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9955\n",
      "Epoch 48/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/stepp - accuracy: 0.9993 - loss: 0\n",
      "Epoch 48 - val_f1_macro_score: 0.9955\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.9993 - loss: 0.0064 - val_accuracy: 0.9963 - val_loss: 0.0279 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9955\n",
      "Epoch 49/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/stepp - accuracy: 0.9999 - loss: \n",
      "Epoch 49 - val_f1_macro_score: 0.9955\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 0.9998 - loss: 0.0050 - val_accuracy: 0.9963 - val_loss: 0.0270 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9955\n",
      "Epoch 50/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/stepp - accuracy: 0.9998 - loss: 0.\n",
      "Epoch 50 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.9998 - loss: 0.0049 - val_accuracy: 0.9961 - val_loss: 0.0275 - learning_rate: 5.0000e-05 - val_f1_macro_score: 0.9954\n",
      "Epoch 51/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/stepp - accuracy: 0.9994 - loss: 0\n",
      "Epoch 51 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.9993 - loss: 0.0067 - val_accuracy: 0.9961 - val_loss: 0.0275 - learning_rate: 5.0000e-06 - val_f1_macro_score: 0.9954\n",
      "Epoch 52/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/stepp - accuracy: 0.9990 - loss: 0\n",
      "Epoch 52 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.9990 - loss: 0.0072 - val_accuracy: 0.9961 - val_loss: 0.0275 - learning_rate: 5.0000e-06 - val_f1_macro_score: 0.9954\n",
      "Epoch 53/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/stepp - accuracy: 0.9998 - loss: 0\n",
      "Epoch 53 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - accuracy: 0.9998 - loss: 0.0050 - val_accuracy: 0.9961 - val_loss: 0.0274 - learning_rate: 5.0000e-06 - val_f1_macro_score: 0.9954\n",
      "Epoch 54/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/stepp - accuracy: 0.9965 - loss: \n",
      "Epoch 54 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - accuracy: 0.9965 - loss: 0.0189 - val_accuracy: 0.9961 - val_loss: 0.0275 - learning_rate: 5.0000e-06 - val_f1_macro_score: 0.9954\n",
      "Epoch 55/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/stepp - accuracy: 0.9991 - loss: 0\n",
      "Epoch 55 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.9991 - loss: 0.0062 - val_accuracy: 0.9962 - val_loss: 0.0277 - learning_rate: 5.0000e-06 - val_f1_macro_score: 0.9954\n",
      "Epoch 56/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/stepp - accuracy: 0.9979 - loss: \n",
      "Epoch 56 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - accuracy: 0.9979 - loss: 0.0101 - val_accuracy: 0.9961 - val_loss: 0.0278 - learning_rate: 5.0000e-06 - val_f1_macro_score: 0.9954\n",
      "Epoch 57/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/stepp - accuracy: 0.9963 - loss: \n",
      "Epoch 57 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 0.9964 - loss: 0.0167 - val_accuracy: 0.9962 - val_loss: 0.0277 - learning_rate: 5.0000e-06 - val_f1_macro_score: 0.9954\n",
      "Epoch 58/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/stepp - accuracy: 0.9989 - loss: 0\n",
      "Epoch 58 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.9989 - loss: 0.0111 - val_accuracy: 0.9962 - val_loss: 0.0277 - learning_rate: 5.0000e-06 - val_f1_macro_score: 0.9954\n",
      "Epoch 59/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/stepp - accuracy: 0.9992 - loss: 0\n",
      "Epoch 59 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - accuracy: 0.9992 - loss: 0.0063 - val_accuracy: 0.9962 - val_loss: 0.0278 - learning_rate: 5.0000e-06 - val_f1_macro_score: 0.9954\n",
      "Epoch 60/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/stepp - accuracy: 0.9989 - loss: 0\n",
      "Epoch 60 - val_f1_macro_score: 0.9954\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 0.9962 - val_loss: 0.0276 - learning_rate: 5.0000e-06 - val_f1_macro_score: 0.9954\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = Unet()\n",
    "#print(model.summary())\n",
    "\n",
    "learning_rate=0.0005\n",
    "n_epoch=60\n",
    "batch_size=32\n",
    "\n",
    "lr_schedule = LearningRateScheduler(lrs)\n",
    "\n",
    "#regressor\n",
    "#model.compile(loss=\"mean_squared_error\", \n",
    "#              optimizer=Adam(lr=learning_rate),\n",
    "#              metrics=[\"mean_absolute_error\"])\n",
    "\n",
    "#classifier\n",
    "model.compile(loss=categorical_crossentropy, \n",
    "              optimizer=Adam(learning_rate=learning_rate), \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "hist = model_fit(model, train_input, train_target, val_input, val_target, n_epoch, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "90a91e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:11:02.475560Z",
     "start_time": "2024-09-08T14:11:01.592685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "SCORE_oldmetric:  0.9966725728498582\n",
      "SCORE_newmetric:  0.9951357875189869\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax((model.predict(val_input)+model.predict(val_input[:,::-1,:])[:,::-1,:])/2, axis=2).reshape(-1)\n",
    "gt = np.argmax(val_target, axis=2).reshape(-1)\n",
    "print(\"SCORE_oldmetric: \", cohen_kappa_score(gt, pred, weights=\"quadratic\"))\n",
    "print(\"SCORE_newmetric: \", f1_score(gt, pred, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
