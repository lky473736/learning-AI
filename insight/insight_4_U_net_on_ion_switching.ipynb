{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b647c0",
   "metadata": {},
   "source": [
    "## learning-AI101 : insight 4\n",
    "### U-net (encoder to decoder) 구조를 이용한 number of opening ion channel classification 분석\n",
    "\n",
    "<br>\n",
    "\n",
    "- **임규연 (lky473736)**\n",
    "- 2024.08.16. ~ 2024.08.20. 문서 작성\n",
    "- **dataset** : https://www.kaggle.com/competitions/liverpool-ion-switching/data?select=test.csv\n",
    "- **kaggle** : https://www.kaggle.com/competitions/liverpool-ion-switching/data?select=test.csv\n",
    "- **data abstract** : you will be predicting the number of open_channels present, based on electrophysiological signal data.\n",
    "\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9453505",
   "metadata": {},
   "source": [
    "본 데이터셋에 대하여 설명해보자면, 예전에 \"Liverpool Ion Switching\"이라는 대회에서 제공하였으며, 이온 채널의 개폐 상태를 예측하는 것이 목표이다. 전기 신호 데이터를 분석하여 특정 시간에 이온 채널이 몇개가 열려 있는지를 예측해야 하며, 입력 데이터는 전기 신호 값인 **'signal'**, 출력 데이터는 0~10개의 **'open_channels'** 이다. \n",
    "\n",
    "따라서 이는 **다중 클래스 classification**을 이용하여 해결이 가능하다. 결국엔 0~10까지의 정수를 prediction하는 것일테니, 11개의 클래스 중 하나를 뽑는 분류 문제이다. \n",
    "\n",
    "그 당시, 유저 **K_MAT은 이를 U-net 구조와 1D-CNN을 이용하여 구현하**였으며, public score를 0.91까지 끌어올렸다. version 1~4 중 version 4에서의 소스 코드 (https://www.kaggle.com/code/kmat2019/u-net-1d-cnn-with-keras) 를 이 insight에서 분석 후에, 추후 report directory에서 내 방식대로 ML classification, DL classification할 계획이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374e3fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:04.958979Z",
     "start_time": "2024-08-20T10:28:04.953856Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, Reshape, Conv1D, BatchNormalization, Activation, AveragePooling1D, GlobalAveragePooling1D, Lambda, Input, Concatenate, Add, UpSampling1D, Multiply\n",
    "from keras.models import Model\n",
    "# objectives 작동 X -> losses로 변경\n",
    "from keras.losses import mean_squared_error\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau,LearningRateScheduler\n",
    "from keras.initializers import random_normal\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee13bbe1",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "### 기존 코드 분석 및 U-net에 대한 정의\n",
    "\n",
    "- reference : https://joungheekim.github.io/2020/09/28/paper-review/\n",
    "<br>\n",
    "\n",
    "- 여기서부터 https://www.kaggle.com/code/kmat2019/u-net-1d-cnn-with-keras 에 소스 코드를 여기에 붙여 넣어서 분석한다.\n",
    "- 현재 이 코드에서는 1D-CNN을 통해 time-series data를 분석하고 있다. \n",
    "- U-net 구조는 **auto-encoder** 기반 모델이며, encoder (down-sampling)와 decoder (up-sampling) 부분으로 나뉘어진다. \n",
    "    - encoder를 통해 data의 중요한 feature을 압축한다. 압축된 정보를 latent space라고 일컫는다. (context vector 등 부르는 말은 다양하다.)\n",
    "    - 중간에 latent space에서 다시 decoder를 통해 원래 사이즈로 복원한다.\n",
    "\n",
    "<img src='https://i.imgur.com/2MUbGYf.png' width='500px'>\n",
    "\n",
    "- 왼쪽 영역, **즉 encoder 부분을 contracting path, decoder 부분을 bridge라 부른다.**\n",
    "- **contracting path의 각 level은 encoder block으로 이루어진다.** encoder block엔 conv block이 속해있다.\n",
    "    - conv block : conv, relu, batch normalization\n",
    "    - encoder block : conv block + pooling\n",
    "    \n",
    "- **decoder의 각 level은 decoder block으로 이루어진다.**\n",
    "    - decoder block : convtranspose, concatenate, convblock (encoder와 반대 logic으로, 원래와 같은 크기가 되도록 함)\n",
    "    \n",
    "    \n",
    "<br>\n",
    "\n",
    "- U-net 구성\n",
    "    - **encoder**\n",
    "        - 데이터를 압축하여 important feature를 extraction\n",
    "        - 연속적인 합성곱과 풀링 연산으로 이루어짐 (CNN에서 합성곱층과 풀링층을 몇개씩 나란히 쓰는 것처럼)\n",
    "    - **decoder**\n",
    "        - encoder에서 추출된 feature를 사용하여 원래 해상도로 복원함\n",
    "        - upsampling, 합성곱 연산으로 복원함\n",
    "    - **skip connection (latent space)**\n",
    "        - encoder에서 각 단계에서 추출된 important feature으로 구성된 feature map을 decoder와 대응하는 단계 (latent space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72fed62b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.269181Z",
     "start_time": "2024-08-20T10:28:04.961868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000000 entries, 0 to 4999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   time           float64\n",
      " 1   signal         float64\n",
      " 2   open_channels  int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 114.4 MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   time    float64\n",
      " 1   signal  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 30.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data/ion_switching/train.csv\")\n",
    "df_test = pd.read_csv(\"./data/ion_switching/test.csv\")\n",
    "\n",
    "print (df_train.info())\n",
    "print ()\n",
    "print (df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff0a35",
   "metadata": {},
   "source": [
    "- df_train에는 훈련 데이터, df_test에는 테스트 데이터가 저장되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df434a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.324814Z",
     "start_time": "2024-08-20T10:28:06.271163Z"
    }
   },
   "outputs": [],
   "source": [
    "train_input = df_train[\"signal\"].values.reshape(-1, 4000, 1)\n",
    "train_input_mean = train_input.mean()\n",
    "train_input_sigma = train_input.std()\n",
    "train_input = (train_input - train_input_mean) / train_input_sigma\n",
    "\n",
    "test_input = df_test[\"signal\"].values.reshape(-1, 10000, 1)\n",
    "test_input = (test_input - train_input_mean) / train_input_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c9c14",
   "metadata": {},
   "source": [
    "- 위 셀에서 reshape를 통해 signal 열을 3D ndarray로 재구성하였다. 여기서 4000은 타임 스텝이다. 이것이 train_input이 된다. (X_train)\n",
    "- train_input을 정규화한다. 정규화하는 식은 Z-score normalization 방식을 따르고 있으며, 표준편차 및 평균을 구하여 표준정규분포로 정규화하고 있다.\n",
    "- test input 또한 마찬가지이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6d001b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.457354Z",
     "start_time": "2024-08-20T10:28:06.328304Z"
    }
   },
   "outputs": [],
   "source": [
    "train_target = pd.get_dummies(df_train[\"open_channels\"]).values.reshape(-1, 4000, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f1700",
   "metadata": {},
   "source": [
    "- open_channels 열을 target으로 두었다. 여기서 get_dummies 메소드를 이용하여 one-hot encoding을 진행하였으며, 11개의 클래스를 나타내는 배열로 변환하였다.\n",
    "- 4000개의 타임 스텝으로 구성하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529e5423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.518653Z",
     "start_time": "2024-08-20T10:28:06.459259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input:(1000, 4000, 1), val_input:(250, 4000, 1), train_target:(1000, 4000, 11), val_target:(250, 4000, 11)\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(train_input.shape[0])\n",
    "train_idx, val_idx = train_test_split(idx, \n",
    "                                      random_state=111, \n",
    "                                      test_size=0.2)\n",
    "\n",
    "val_input = train_input[val_idx]\n",
    "train_input = train_input[train_idx]\n",
    "val_target = train_target[val_idx]\n",
    "train_target = train_target[train_idx]\n",
    "\n",
    "print(\"train_input:{}, val_input:{}, train_target:{}, val_target:{}\".format(train_input.shape, val_input.shape, train_target.shape, val_target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec4fca",
   "metadata": {},
   "source": [
    "- idx로 train_input 크기만큼의 배열을 만들었고, 이를 하는 이유는 train set, test set을 구성할 때 records를 섞어 편향 문제를 방지하기 위함이다.\n",
    "- train set : val set = 8 : 2\n",
    "\n",
    "아래부터는 U-net을 구성하기 위한 함수를 정의한다. 간단한 개요를 작성해보자면 아래와 같다.\n",
    "\n",
    "- cbr : 인코더와 디코더에서 모델의 표현력, 즉 특징 추출 + 비선형성 추가를 돕는 layers를 만드는 함수. 모든 합성곱 연산에서 cbr 사용.\n",
    "- se_block : Squeeze and Excitation (SE)을 정의하는 함수\n",
    "- resblock : ResNet을 정의하는 함수\n",
    "- Unet : 전체 U-Net 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "911200a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.524152Z",
     "start_time": "2024-08-20T10:28:06.520729Z"
    }
   },
   "outputs": [],
   "source": [
    "def cbr(x, out_layer, kernel, stride, dilation):\n",
    "    x = Conv1D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3c7bd5",
   "metadata": {},
   "source": [
    "- Conv1D -> BatchNormalization -> relu를 통하여 비선형성을 추가하며, 각 단계에서 important feature를 추출하는 역할을 하고 있다.\n",
    "- encoder : 중요한 특징 추출 + 추상적인 표현 학습 (pooling) \n",
    "- decoder : cbr이 upsampling된 데이터에 적용 + 똑같이 중요한 특징 추출 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed831d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.529527Z",
     "start_time": "2024-08-20T10:28:06.526297Z"
    }
   },
   "outputs": [],
   "source": [
    "def se_block(x_in, layer_n):\n",
    "    x = GlobalAveragePooling1D()(x_in)\n",
    "    x = Dense(layer_n // 8, activation=\"relu\")(x)\n",
    "    x = Dense(layer_n, activation=\"sigmoid\")(x)\n",
    "    x_out = Multiply()([x_in, x])\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143e2c9",
   "metadata": {},
   "source": [
    "- reference 1 : https://ech97.tistory.com/entry/seblock\n",
    "- reference 2 : https://deep-learning-study.tistory.com/539\n",
    "\n",
    "<br> \n",
    "\n",
    "- squeeze and excitation 블록을 정의하고 있다. 각 채널별로 가중치를 부여하여 feature map의 각 채널에 곱한다. \n",
    "- squeeze (압축)\n",
    "     - 각 채널을 1차원으로 만드는 역할이다. (**global average pooling 1D**)\n",
    "- excitation (재조정)\n",
    "     - squeeze에서 생성된 1차원 벡터를 normalization하여 가중치를 부여한다.\n",
    "     - 본 코드에서는 layer_n // 8을 통하여 채널을 축소하였는데, 이때 8은 hyperparamter이다.\n",
    "- 본 함수는 채널 간 중요도를 학습하여 중요한 채널에 집중할 수 있게끔 돕는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1425f079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.534523Z",
     "start_time": "2024-08-20T10:28:06.531314Z"
    }
   },
   "outputs": [],
   "source": [
    "def resblock(x_in, layer_n, kernel, dilation, use_se=True):\n",
    "    x = cbr(x_in, layer_n, kernel, 1, dilation)\n",
    "    x = cbr(x, layer_n, kernel, 1, dilation)\n",
    "    if use_se:\n",
    "        x = se_block(x, layer_n)\n",
    "    x = Add()([x_in, x])\n",
    "    return x  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e041b66",
   "metadata": {},
   "source": [
    "- 두번의 cbr 연산 후의 출력을 입력과 더하고 있다. 이는 아마도 **vanishing gradient problem**을 해결하기 위함이 아닐까 싶다. \n",
    "- 왜냐하면, 여러 층을 거친 result를 입력과 더하는 방식이니 결국엔 입력과 이전 정보의 합을 통하여 출력값이 너무 작아지는 문제를 방지할 수 있을 것이다. \n",
    "- 결국 skip connection을 통하여 ($y = F(x) + x$) 합을 이룰 것이고, 이를 반환하는 함수이다.\n",
    "- 역전파 과정에서의 gradient의 flow를 보자.\n",
    "    - 일반 network \n",
    "        - $\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x} = \\frac{\\partial L}{\\partial F(x)} \\cdot \\frac{\\partial F(x)}{\\partial x}$\n",
    "        - 여기서 L이 의미하는 바는 손실함수인데, 만약 $\\frac{\\partial F(x)}{\\partial x}$이 작다면. 기울기가 매우 작아진다.\n",
    "    - resblock\n",
    "        - $\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x} = \\frac{\\partial L}{\\partial y} \\cdot \\left( \\frac{\\partial F(x)}{\\partial x} + 1 \\right)$\n",
    "        - 결국에 **1**이라는 상수가 항상 더해져 기울기가 완전히 소실되는 문제를 피하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73672277",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.548420Z",
     "start_time": "2024-08-20T10:28:06.536984Z"
    }
   },
   "outputs": [],
   "source": [
    "def Unet(input_shape=(None, 1)):\n",
    "    layer_n = 64\n",
    "    kernel_size = 7\n",
    "    depth = 2\n",
    "\n",
    "    input_layer = Input(input_shape)    \n",
    "    input_layer_1 = AveragePooling1D(5)(input_layer)\n",
    "    input_layer_2 = AveragePooling1D(25)(input_layer)\n",
    "    \n",
    "    ########## Encoder\n",
    "    x = cbr(input_layer, layer_n, kernel_size, 1, 1)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n, kernel_size, 1)\n",
    "    out_0 = x\n",
    "\n",
    "    x = cbr(x, layer_n * 2, kernel_size, 5, 1)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n * 2, kernel_size, 1)\n",
    "    out_1 = x\n",
    "\n",
    "    x = Concatenate()([x, input_layer_1])\n",
    "    x = cbr(x, layer_n * 3, kernel_size, 5, 1)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n * 3, kernel_size, 1)\n",
    "    out_2 = x\n",
    "\n",
    "    x = Concatenate()([x, input_layer_2])\n",
    "    x = cbr(x, layer_n * 4, kernel_size, 5, 1)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n * 4, kernel_size, 1)\n",
    "    \n",
    "    ########### Decoder\n",
    "    x = UpSampling1D(5)(x)\n",
    "    x = Concatenate()([x, out_2])\n",
    "    x = cbr(x, layer_n * 3, kernel_size, 1, 1)\n",
    "\n",
    "    x = UpSampling1D(5)(x)\n",
    "    x = Concatenate()([x, out_1])\n",
    "    x = cbr(x, layer_n * 2, kernel_size, 1, 1)\n",
    "\n",
    "    x = UpSampling1D(5)(x)\n",
    "    x = Concatenate()([x, out_0])\n",
    "    x = cbr(x, layer_n, kernel_size, 1, 1)    \n",
    "\n",
    "    # Classifier Layer\n",
    "    x = Conv1D(11, kernel_size=kernel_size, strides=1, padding=\"same\")(x)\n",
    "    out = Activation(\"softmax\")(x)\n",
    "    \n",
    "    model = Model(input_layer, out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30281a",
   "metadata": {},
   "source": [
    "- 위 함수에서 U-Net 모델 자체를 정의한다. \n",
    "- encoder \n",
    "    - cbr과 resblock을 사용하여 깊은 층에서 feature learning\n",
    "    - 각 단계에서의 중간 feature map인 out_0, out_1, out_2를 따로 변수로 빼서, decoder에서 사용한다. \n",
    "- decoder\n",
    "    - **UpSampling1D**를 사용하여 차원을 확장하였다. 그리고 out_0, out_1, out_2와 결합하였다.\n",
    "    - 결합한 걸 다시 cbr하여 이전의 정보를 복원하였다.\n",
    "- 마지막엔 softmax activation function으로 각 클래스에 대하여 확률을 계산하였다. (나중에 argmax을 통한 연산이 나올 것이라고 예상해본다.)\n",
    "\n",
    "이 이후에는 데이터 증강, generater, macroF1 클래스, fitting 함수, lrs가 작성되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6d1a97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.556591Z",
     "start_time": "2024-08-20T10:28:06.553347Z"
    }
   },
   "outputs": [],
   "source": [
    "def augmentations(input_data, target_data):\n",
    "    #flip\n",
    "    if np.random.rand() < 0.5:    \n",
    "        input_data = input_data[::-1]\n",
    "        target_data = target_data[::-1]\n",
    "\n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5fc848",
   "metadata": {},
   "source": [
    "- data augmentation을 진행한다. 보통은 이미지 학습에서 사용하는 tech인줄 알았는데, 이런 time-series에서 사용할 줄은 몰랐다.\n",
    "- 입력 데이터를 random.rand()을 이용하여 뒤집는다. 데이터를 변형하여 학습을 더욱 강화하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efa84ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.565089Z",
     "start_time": "2024-08-20T10:28:06.559183Z"
    }
   },
   "outputs": [],
   "source": [
    "def Datagen(input_dataset, target_dataset, batch_size, is_train=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    idx_1 = np.arange(len(input_dataset))\n",
    "    np.random.shuffle(idx_1)\n",
    "\n",
    "    while True:\n",
    "        for i in range(len(input_dataset)):\n",
    "            input_data = input_dataset[idx_1[i]]\n",
    "            target_data = target_dataset[idx_1[i]]\n",
    "\n",
    "            if is_train:\n",
    "                input_data, target_data = augmentations(input_data, target_data)\n",
    "                \n",
    "            x.append(input_data)\n",
    "            y.append(target_data)\n",
    "            count += 1\n",
    "            \n",
    "            if count == batch_size:\n",
    "                x=np.array(x, dtype=np.float32)\n",
    "                y=np.array(y, dtype=np.float32)\n",
    "                inputs = x\n",
    "                targets = y       \n",
    "                x = []\n",
    "                y = []\n",
    "                count=0\n",
    "                yield inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d5c0ad",
   "metadata": {},
   "source": [
    "- 위 함수는 배치 단위로 데이터를 생성하는 generater의 역할을 하고 있다. input_data, target_data를 augmentations 함수를 사용하여 데이터 증강을 적용하고 있다.\n",
    "- 지정된 배치 단위로 ndarray를 만들어 inputs과 targets를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25dc38f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.572121Z",
     "start_time": "2024-08-20T10:28:06.567639Z"
    }
   },
   "outputs": [],
   "source": [
    "class macroF1(Callback):\n",
    "    def __init__(self, model, inputs, targets):\n",
    "        self.model = model\n",
    "        self.inputs = inputs\n",
    "        self.targets = np.argmax(targets, axis=2).reshape(-1)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        # 각 에포크가 끝날 때마다 검증 데이터로 매크로 F1 스코어를 계산하여 출력\n",
    "        pred = np.argmax(self.model.predict(self.inputs), axis=2).reshape(-1)\n",
    "        f1_val = f1_score(self.targets, pred, average=\"macro\")\n",
    "        print(\"val_f1_macro_score: \", f1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e4e74",
   "metadata": {},
   "source": [
    "- 케라스의 내장 클래스인 **Callback**을 상속받은 것을 확인 가능하며, 이는 model fitting 중에 validation data를 이용하여 f1 score을 계산하여 출력하는 것을 확인 가능하다.\n",
    "- 역시나 argmax을 통하여 가장 높은 확률을 가진 class를 pred에 넣고, f1_score 메소드를 이용해 f1 score을 측정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93e3ae9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.579403Z",
     "start_time": "2024-08-20T10:28:06.574806Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_fit(model, train_inputs, train_targets, val_inputs, val_targets, n_epoch, batch_size=32):\n",
    "    # 모델을 학습시키기 위한 함수\n",
    "    hist = model.fit_generator(\n",
    "        Datagen(train_inputs, train_targets, batch_size, is_train=True),\n",
    "        steps_per_epoch=len(train_inputs) // batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=Datagen(val_inputs, val_targets, batch_size),\n",
    "        validation_steps=len(val_inputs) // batch_size,\n",
    "        callbacks=[lr_schedule, macroF1(model, val_inputs, val_targets)],\n",
    "        shuffle=False,\n",
    "        verbose=1\n",
    "    )\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc2c85",
   "metadata": {},
   "source": [
    "- 말 그대로, 모델을 학습한다.\n",
    "- fit_generator를 두어 큰 데이터에 대한 학습이 용이하게 하였다. 학습 중간에 학습율 조정을 위해 lr_schedule callback을 두었다.\n",
    "    - **fit_generator는 사실 권장되는 방법이 아니다.** tensorflow 2.5.0 버전까지만 사용이 가능하며, 2.6.0 이상에서 권장되는 방법은 그저 fit 메소드 하나다.\n",
    "    - 현재 사용하는 tensorflow 버전은 2.4.0이라 본 코드가 동작되는 것이다.\n",
    "- macroF1 callback을 통하여 매 학습 시 f1 score 계산을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d96d5860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T10:28:06.585509Z",
     "start_time": "2024-08-20T10:28:06.582308Z"
    }
   },
   "outputs": [],
   "source": [
    "def lrs(epoch):\n",
    "    if epoch<35:\n",
    "        lr = learning_rate\n",
    "    elif epoch<50:\n",
    "        lr = learning_rate/10\n",
    "    else:\n",
    "        lr = learning_rate/100\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a6ad8",
   "metadata": {},
   "source": [
    "- lrs를 통하여 학습율을 조정한다. epoch에 따라서 learning_rate에 연산을 가해 조정하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54cc543a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:05:53.370790Z",
     "start_time": "2024-08-20T10:43:10.713877Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_35766/3759982232.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model.fit_generator(\n",
      "2024-08-20 19:43:11.477930: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - ETA: 0s - loss: 1.4860 - accuracy: 0.4641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 19:44:44.328110: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 552ms/step\n",
      "val_f1_macro_score:  0.0360673573788344\n",
      "31/31 [==============================] - 104s 3s/step - loss: 1.4860 - accuracy: 0.4641 - val_loss: 2.6236 - val_accuracy: 0.1959 - lr: 5.0000e-04\n",
      "Epoch 2/60\n",
      "8/8 [==============================] - 6s 691ms/steposs: 1.0791 - \n",
      "val_f1_macro_score:  0.08903828171990068\n",
      "31/31 [==============================] - 100s 3s/step - loss: 1.0791 - accuracy: 0.5877 - val_loss: 7.5935 - val_accuracy: 0.3069 - lr: 5.0000e-04\n",
      "Epoch 3/60\n",
      "8/8 [==============================] - 5s 616ms/steposs: 0.9192 - \n",
      "val_f1_macro_score:  0.03463572660246789\n",
      "31/31 [==============================] - 91s 3s/step - loss: 0.9192 - accuracy: 0.6405 - val_loss: 13.9496 - val_accuracy: 0.2243 - lr: 5.0000e-04\n",
      "Epoch 4/60\n",
      "8/8 [==============================] - 5s 595ms/steposs: 0.8869 - \n",
      "val_f1_macro_score:  0.035160121010793015\n",
      "31/31 [==============================] - 96s 3s/step - loss: 0.8869 - accuracy: 0.6471 - val_loss: 19.3717 - val_accuracy: 0.2263 - lr: 5.0000e-04\n",
      "Epoch 5/60\n",
      "8/8 [==============================] - 5s 605ms/steposs: 0.8634 - \n",
      "val_f1_macro_score:  0.043902870105479656\n",
      "31/31 [==============================] - 93s 3s/step - loss: 0.8634 - accuracy: 0.6650 - val_loss: 6.2177 - val_accuracy: 0.2561 - lr: 5.0000e-04\n",
      "Epoch 6/60\n",
      "8/8 [==============================] - 6s 742ms/steposs: 0.7105 - \n",
      "val_f1_macro_score:  0.11178507597674746\n",
      "31/31 [==============================] - 99s 3s/step - loss: 0.7105 - accuracy: 0.7297 - val_loss: 10.7807 - val_accuracy: 0.3804 - lr: 5.0000e-04\n",
      "Epoch 7/60\n",
      "8/8 [==============================] - 5s 593ms/steposs: 0.6345 - \n",
      "val_f1_macro_score:  0.0867932061049965\n",
      "31/31 [==============================] - 92s 3s/step - loss: 0.6345 - accuracy: 0.7558 - val_loss: 6.9623 - val_accuracy: 0.2918 - lr: 5.0000e-04\n",
      "Epoch 8/60\n",
      "8/8 [==============================] - 6s 709ms/steposs: 0.6818 - \n",
      "val_f1_macro_score:  0.052111743819546356\n",
      "31/31 [==============================] - 109s 4s/step - loss: 0.6818 - accuracy: 0.7419 - val_loss: 9.2829 - val_accuracy: 0.2236 - lr: 5.0000e-04\n",
      "Epoch 9/60\n",
      "8/8 [==============================] - 6s 754ms/steposs: 0.6919 - \n",
      "val_f1_macro_score:  0.07563819490839778\n",
      "31/31 [==============================] - 101s 3s/step - loss: 0.6919 - accuracy: 0.7409 - val_loss: 8.9262 - val_accuracy: 0.2884 - lr: 5.0000e-04\n",
      "Epoch 10/60\n",
      "8/8 [==============================] - 4s 492ms/steposs: 0.6098 - \n",
      "val_f1_macro_score:  0.10919849779213782\n",
      "31/31 [==============================] - 88s 3s/step - loss: 0.6098 - accuracy: 0.7678 - val_loss: 9.2981 - val_accuracy: 0.3659 - lr: 5.0000e-04\n",
      "Epoch 11/60\n",
      "8/8 [==============================] - 4s 495ms/steposs: 0.5353 - \n",
      "val_f1_macro_score:  0.07381205716440571\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.5353 - accuracy: 0.7973 - val_loss: 7.5052 - val_accuracy: 0.2950 - lr: 5.0000e-04\n",
      "Epoch 12/60\n",
      "8/8 [==============================] - 4s 477ms/steposs: 0.5298 - \n",
      "val_f1_macro_score:  0.107207291227914\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.5298 - accuracy: 0.7966 - val_loss: 6.6707 - val_accuracy: 0.3550 - lr: 5.0000e-04\n",
      "Epoch 13/60\n",
      "8/8 [==============================] - 4s 492ms/steposs: 0.5298 - \n",
      "val_f1_macro_score:  0.10211531533447818\n",
      "31/31 [==============================] - 78s 3s/step - loss: 0.5298 - accuracy: 0.8090 - val_loss: 4.3858 - val_accuracy: 0.3007 - lr: 5.0000e-04\n",
      "Epoch 14/60\n",
      "8/8 [==============================] - 4s 506ms/steposs: 0.5659 - \n",
      "val_f1_macro_score:  0.05115343087970088\n",
      "31/31 [==============================] - 86s 3s/step - loss: 0.5659 - accuracy: 0.7899 - val_loss: 10.0886 - val_accuracy: 0.2045 - lr: 5.0000e-04\n",
      "Epoch 15/60\n",
      "8/8 [==============================] - 4s 524ms/steposs: 0.4677 - \n",
      "val_f1_macro_score:  0.08152005984960116\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.4677 - accuracy: 0.8288 - val_loss: 6.1838 - val_accuracy: 0.2833 - lr: 5.0000e-04\n",
      "Epoch 16/60\n",
      "8/8 [==============================] - 4s 525ms/steposs: 0.4303 - \n",
      "val_f1_macro_score:  0.10626221152220787\n",
      "31/31 [==============================] - 81s 3s/step - loss: 0.4303 - accuracy: 0.8402 - val_loss: 4.5218 - val_accuracy: 0.2989 - lr: 5.0000e-04\n",
      "Epoch 17/60\n",
      "8/8 [==============================] - 4s 509ms/steposs: 0.4697 - \n",
      "val_f1_macro_score:  0.1529895471706801\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.4697 - accuracy: 0.8318 - val_loss: 2.7465 - val_accuracy: 0.3728 - lr: 5.0000e-04\n",
      "Epoch 18/60\n",
      "8/8 [==============================] - 4s 515ms/steposs: 0.4776 - \n",
      "val_f1_macro_score:  0.41797365903560474\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.4776 - accuracy: 0.8223 - val_loss: 2.2792 - val_accuracy: 0.4599 - lr: 5.0000e-04\n",
      "Epoch 19/60\n",
      "8/8 [==============================] - 4s 519ms/steposs: 0.4330 - \n",
      "val_f1_macro_score:  0.45425526487502044\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.4330 - accuracy: 0.8400 - val_loss: 1.5882 - val_accuracy: 0.4930 - lr: 5.0000e-04\n",
      "Epoch 20/60\n",
      "8/8 [==============================] - 4s 521ms/steposs: 0.3877 - \n",
      "val_f1_macro_score:  0.41208741027111057\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.3877 - accuracy: 0.8556 - val_loss: 1.4088 - val_accuracy: 0.6491 - lr: 5.0000e-04\n",
      "Epoch 21/60\n",
      "8/8 [==============================] - 4s 516ms/steposs: 0.4067 - \n",
      "val_f1_macro_score:  0.5814591597193303\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.4067 - accuracy: 0.8615 - val_loss: 1.4370 - val_accuracy: 0.6897 - lr: 5.0000e-04\n",
      "Epoch 22/60\n",
      "8/8 [==============================] - 4s 508ms/steposs: 0.3915 - \n",
      "val_f1_macro_score:  0.7818263383872225\n",
      "31/31 [==============================] - 78s 3s/step - loss: 0.3915 - accuracy: 0.8590 - val_loss: 0.3951 - val_accuracy: 0.8514 - lr: 5.0000e-04\n",
      "Epoch 23/60\n",
      "8/8 [==============================] - 4s 520ms/steposs: 0.3180 - \n",
      "val_f1_macro_score:  0.715121105152951\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.3180 - accuracy: 0.8895 - val_loss: 0.4787 - val_accuracy: 0.8090 - lr: 5.0000e-04\n",
      "Epoch 24/60\n",
      "8/8 [==============================] - 4s 529ms/steposs: 0.3125 - \n",
      "val_f1_macro_score:  0.7127496126517001\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.3125 - accuracy: 0.8897 - val_loss: 0.4768 - val_accuracy: 0.8142 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "8/8 [==============================] - 4s 503ms/steposs: 0.3245 - \n",
      "val_f1_macro_score:  0.5242470544898462\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.3245 - accuracy: 0.8837 - val_loss: 1.1321 - val_accuracy: 0.6909 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "8/8 [==============================] - 4s 525ms/steposs: 0.3672 - \n",
      "val_f1_macro_score:  0.7164018230123719\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.3672 - accuracy: 0.8739 - val_loss: 0.5217 - val_accuracy: 0.8064 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "8/8 [==============================] - 4s 493ms/steposs: 0.2897 - \n",
      "val_f1_macro_score:  0.796542628077228\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2897 - accuracy: 0.8988 - val_loss: 0.3621 - val_accuracy: 0.8604 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "8/8 [==============================] - 4s 506ms/steposs: 0.2882 - \n",
      "val_f1_macro_score:  0.8121902085025607\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2882 - accuracy: 0.8968 - val_loss: 0.3441 - val_accuracy: 0.8684 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "8/8 [==============================] - 4s 500ms/steposs: 0.2655 - \n",
      "val_f1_macro_score:  0.7928396949359352\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.2655 - accuracy: 0.9054 - val_loss: 0.3601 - val_accuracy: 0.8574 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "8/8 [==============================] - 4s 491ms/steposs: 0.2492 - \n",
      "val_f1_macro_score:  0.7405617541720377\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2492 - accuracy: 0.9129 - val_loss: 0.4151 - val_accuracy: 0.8578 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "8/8 [==============================] - 4s 509ms/steposs: 0.2318 - \n",
      "val_f1_macro_score:  0.7058753438099282\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2318 - accuracy: 0.9219 - val_loss: 0.4365 - val_accuracy: 0.8203 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/60\n",
      "8/8 [==============================] - 4s 522ms/steposs: 0.2214 - \n",
      "val_f1_macro_score:  0.6527946917007532\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2214 - accuracy: 0.9247 - val_loss: 0.6331 - val_accuracy: 0.7893 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "8/8 [==============================] - 4s 512ms/steposs: 0.2311 - \n",
      "val_f1_macro_score:  0.8517661516084584\n",
      "31/31 [==============================] - 81s 3s/step - loss: 0.2311 - accuracy: 0.9202 - val_loss: 0.2847 - val_accuracy: 0.8957 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "8/8 [==============================] - 4s 519ms/steposs: 0.5017 - \n",
      "val_f1_macro_score:  0.21008941385935181\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.5017 - accuracy: 0.8339 - val_loss: 19.5369 - val_accuracy: 0.4786 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "8/8 [==============================] - 4s 514ms/steposs: 0.3556 - \n",
      "val_f1_macro_score:  0.48222247370521126\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.3556 - accuracy: 0.8669 - val_loss: 1.1230 - val_accuracy: 0.6872 - lr: 5.0000e-04\n",
      "Epoch 36/60\n",
      "8/8 [==============================] - 4s 514ms/steposs: 0.2595 - \n",
      "val_f1_macro_score:  0.7456383442584897\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2595 - accuracy: 0.9094 - val_loss: 0.4172 - val_accuracy: 0.8342 - lr: 5.0000e-05\n",
      "Epoch 37/60\n",
      "8/8 [==============================] - 4s 507ms/steposs: 0.2466 - \n",
      "val_f1_macro_score:  0.796573988833267\n",
      "31/31 [==============================] - 78s 3s/step - loss: 0.2466 - accuracy: 0.9157 - val_loss: 0.3204 - val_accuracy: 0.8754 - lr: 5.0000e-05\n",
      "Epoch 38/60\n",
      "8/8 [==============================] - 4s 530ms/steposs: 0.2305 - \n",
      "val_f1_macro_score:  0.8219123147351465\n",
      "31/31 [==============================] - 78s 3s/step - loss: 0.2305 - accuracy: 0.9234 - val_loss: 0.2741 - val_accuracy: 0.8974 - lr: 5.0000e-05\n",
      "Epoch 39/60\n",
      "8/8 [==============================] - 4s 530ms/steposs: 0.2191 - \n",
      "val_f1_macro_score:  0.8458648813554729\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2191 - accuracy: 0.9277 - val_loss: 0.2456 - val_accuracy: 0.9116 - lr: 5.0000e-05\n",
      "Epoch 40/60\n",
      "8/8 [==============================] - 4s 517ms/steposs: 0.2210 - \n",
      "val_f1_macro_score:  0.863508531504745\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2210 - accuracy: 0.9263 - val_loss: 0.2516 - val_accuracy: 0.9103 - lr: 5.0000e-05\n",
      "Epoch 41/60\n",
      "8/8 [==============================] - 4s 517ms/steposs: 0.2167 - \n",
      "val_f1_macro_score:  0.8718082851213538\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.2167 - accuracy: 0.9284 - val_loss: 0.2410 - val_accuracy: 0.9162 - lr: 5.0000e-05\n",
      "Epoch 42/60\n",
      "8/8 [==============================] - 4s 519ms/steposs: 0.2096 - \n",
      "val_f1_macro_score:  0.8790033509368016\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.2096 - accuracy: 0.9315 - val_loss: 0.2386 - val_accuracy: 0.9177 - lr: 5.0000e-05\n",
      "Epoch 43/60\n",
      "8/8 [==============================] - 4s 516ms/steposs: 0.2099 - \n",
      "val_f1_macro_score:  0.8785194233950882\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2099 - accuracy: 0.9313 - val_loss: 0.2310 - val_accuracy: 0.9192 - lr: 5.0000e-05\n",
      "Epoch 44/60\n",
      "8/8 [==============================] - 4s 519ms/steposs: 0.2086 - \n",
      "val_f1_macro_score:  0.8785754923387716\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2086 - accuracy: 0.9312 - val_loss: 0.2323 - val_accuracy: 0.9179 - lr: 5.0000e-05\n",
      "Epoch 45/60\n",
      "8/8 [==============================] - 4s 507ms/steposs: 0.2049 - \n",
      "val_f1_macro_score:  0.877272770552404\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.2049 - accuracy: 0.9328 - val_loss: 0.2295 - val_accuracy: 0.9190 - lr: 5.0000e-05\n",
      "Epoch 46/60\n",
      "8/8 [==============================] - 4s 521ms/steposs: 0.2000 - \n",
      "val_f1_macro_score:  0.8745761709604808\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.2000 - accuracy: 0.9348 - val_loss: 0.2243 - val_accuracy: 0.9218 - lr: 5.0000e-05\n",
      "Epoch 47/60\n",
      "8/8 [==============================] - 4s 508ms/steposs: 0.1995 - \n",
      "val_f1_macro_score:  0.8753654806111524\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.1995 - accuracy: 0.9353 - val_loss: 0.2404 - val_accuracy: 0.9137 - lr: 5.0000e-05\n",
      "Epoch 48/60\n",
      "8/8 [==============================] - 4s 522ms/steposs: 0.2003 - \n",
      "val_f1_macro_score:  0.8774450849448548\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.2003 - accuracy: 0.9341 - val_loss: 0.2166 - val_accuracy: 0.9240 - lr: 5.0000e-05\n",
      "Epoch 49/60\n",
      "8/8 [==============================] - 4s 513ms/steposs: 0.1960 - \n",
      "val_f1_macro_score:  0.8758267135297001\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.1960 - accuracy: 0.9360 - val_loss: 0.2377 - val_accuracy: 0.9151 - lr: 5.0000e-05\n",
      "Epoch 50/60\n",
      "8/8 [==============================] - 4s 509ms/steposs: 0.1936 - \n",
      "val_f1_macro_score:  0.8737696037456669\n",
      "31/31 [==============================] - 81s 3s/step - loss: 0.1936 - accuracy: 0.9370 - val_loss: 0.2241 - val_accuracy: 0.9200 - lr: 5.0000e-05\n",
      "Epoch 51/60\n",
      "8/8 [==============================] - 4s 524ms/steposs: 0.1932 - \n",
      "val_f1_macro_score:  0.8764713816678745\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.1932 - accuracy: 0.9377 - val_loss: 0.2284 - val_accuracy: 0.9177 - lr: 5.0000e-06\n",
      "Epoch 52/60\n",
      "8/8 [==============================] - 4s 514ms/steposs: 0.1940 - \n",
      "val_f1_macro_score:  0.8792872623982497\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.1940 - accuracy: 0.9367 - val_loss: 0.2188 - val_accuracy: 0.9219 - lr: 5.0000e-06\n",
      "Epoch 53/60\n",
      "8/8 [==============================] - 4s 530ms/steposs: 0.1927 - \n",
      "val_f1_macro_score:  0.881321629309559\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.1927 - accuracy: 0.9374 - val_loss: 0.2260 - val_accuracy: 0.9203 - lr: 5.0000e-06\n",
      "Epoch 54/60\n",
      "8/8 [==============================] - 4s 515ms/steposs: 0.1903 - \n",
      "val_f1_macro_score:  0.8811036191748862\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.1903 - accuracy: 0.9384 - val_loss: 0.2269 - val_accuracy: 0.9201 - lr: 5.0000e-06\n",
      "Epoch 55/60\n",
      "8/8 [==============================] - 4s 522ms/steposs: 0.1912 - \n",
      "val_f1_macro_score:  0.8808438641224199\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.1912 - accuracy: 0.9383 - val_loss: 0.2142 - val_accuracy: 0.9248 - lr: 5.0000e-06\n",
      "Epoch 56/60\n",
      "8/8 [==============================] - 4s 526ms/steposs: 0.1930 - \n",
      "val_f1_macro_score:  0.8817268447981622\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.1930 - accuracy: 0.9371 - val_loss: 0.2191 - val_accuracy: 0.9225 - lr: 5.0000e-06\n",
      "Epoch 57/60\n",
      "8/8 [==============================] - 5s 582ms/steposs: 0.1917 - \n",
      "val_f1_macro_score:  0.882628010769968\n",
      "31/31 [==============================] - 89s 3s/step - loss: 0.1917 - accuracy: 0.9378 - val_loss: 0.2212 - val_accuracy: 0.9221 - lr: 5.0000e-06\n",
      "Epoch 58/60\n",
      "8/8 [==============================] - 4s 502ms/steposs: 0.1899 - \n",
      "val_f1_macro_score:  0.8819742587664592\n",
      "31/31 [==============================] - 80s 3s/step - loss: 0.1899 - accuracy: 0.9386 - val_loss: 0.2172 - val_accuracy: 0.9242 - lr: 5.0000e-06\n",
      "Epoch 59/60\n",
      "8/8 [==============================] - 4s 487ms/steposs: 0.1904 - \n",
      "val_f1_macro_score:  0.8818138799150318\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.1904 - accuracy: 0.9387 - val_loss: 0.2123 - val_accuracy: 0.9266 - lr: 5.0000e-06\n",
      "Epoch 60/60\n",
      "8/8 [==============================] - 4s 487ms/steposs: 0.1923 - \n",
      "val_f1_macro_score:  0.88214313438026\n",
      "31/31 [==============================] - 79s 3s/step - loss: 0.1923 - accuracy: 0.9372 - val_loss: 0.2280 - val_accuracy: 0.9195 - lr: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = Unet()\n",
    "#print(model.summary())\n",
    "\n",
    "learning_rate=0.0005\n",
    "n_epoch=60\n",
    "batch_size=32\n",
    "\n",
    "lr_schedule = LearningRateScheduler(lrs)\n",
    "\n",
    "#regressor\n",
    "#model.compile(loss=\"mean_squared_error\", \n",
    "#              optimizer=Adam(lr=learning_rate),\n",
    "#              metrics=[\"mean_absolute_error\"])\n",
    "\n",
    "#classifier\n",
    "model.compile(loss=categorical_crossentropy, \n",
    "              optimizer=Adam(lr=learning_rate), \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "hist = model_fit(model, train_input, train_target, val_input, val_target, n_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "067ccbbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:06:02.775938Z",
     "start_time": "2024-08-20T12:05:53.373244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 533ms/step\n",
      "8/8 [==============================] - 4s 541ms/step\n",
      "SCORE_oldmetric:  0.9941988168308229\n",
      "SCORE_newmetric:  0.8845282496397201\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax((model.predict(val_input)+model.predict(val_input[:,::-1,:])[:,::-1,:])/2, axis=2).reshape(-1)\n",
    "gt = np.argmax(val_target, axis=2).reshape(-1)\n",
    "print(\"SCORE_oldmetric: \", cohen_kappa_score(gt, pred, weights=\"quadratic\"))\n",
    "print(\"SCORE_newmetric: \", f1_score(gt, pred, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
